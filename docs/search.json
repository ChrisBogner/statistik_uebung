[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "",
    "text": "Vorwort\nIn dieser Veranstaltung werden wir folgende Werkzeuge verwenden:\nILIAS: die Online-Lernplattform der UzK. Sie sollten alle bereits registriert sein.\nCampuswire: die Chatplattform dient der allgemeinen Kommunikation und der Selbstorganisation des Lernens. Verwenden Sie diese, um Fragen mit Ihren Kommilitonen*innen und mir zu diskutieren. Sie sollten eine Einladungsmail zu Campuswire erhalten haben."
  },
  {
    "objectID": "01-einfuehrung.html",
    "href": "01-einfuehrung.html",
    "title": "1  Die Übung",
    "section": "",
    "text": "Note\n\n\n\n\nDaten für Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchführen\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#lernziele-des-kurses",
    "href": "01-einfuehrung.html#lernziele-des-kurses",
    "title": "1  Der Kurs",
    "section": "Lernziele des Kurses",
    "text": "Lernziele des Kurses\n\n\n\n\n\n\nNote\n\n\n\n\nDaten für Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchführen\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "1  Die Übung",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPünktlichkeit bei Präsenz- und Zoomsitzungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenüber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen 😄"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Çetinkaya-Rundel, Mine, and Johanna Hardin. 2021. Introduction to\nModern Statistics. https://openintro-ims.netlify.app/.\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression.\nSpringer. http://link.springer.com/book/10.1007/978-3-642-01837-4.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A\nLanguage for Data Analysis and\nGraphics.” Journal of Computational and\nGraphical Statistics 5 (3): 299–314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive:\nStatistical Inference via Data Science.\nhttps://moderndive.com/.\n\n\nKnuth, D. E. 1984. “Literate Programming.”\nThe Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for\nData Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science (2e). https://r4ds.hadley.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R\nMarkdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/.\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner’s Guide to\nR. Springer."
  },
  {
    "objectID": "01-erste-schritte.html",
    "href": "01-erste-schritte.html",
    "title": "1  Erste Schritte in R",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nAttache Paket: 'kableExtra'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "01-erste-schritte.html#was-ist",
    "href": "01-erste-schritte.html#was-ist",
    "title": "1  Erste Schritte in R",
    "section": "1.1 Was ist ?",
    "text": "1.1 Was ist ?\nR ist eine Programmiersprache für Datenanalyse und statistische Modellierung. Es ist frei verfügbar (open source software) und neben Python einer der am meisten benutzten Programmiersprachen zur Datenanalyse und -visualisierung. R wurde von Ross Ihaka und Robert Gentleman 1996 veröffentlicht (Ihaka and Gentleman 1996). Es gibt für R eine Vielzahl von Zusatzpaketen, die die Funktionalität und die Einsatzmöglichkeiten enorm erweitern.\nSie können R für Ihren Computer auf der offiziellen R-Seite https://www.r-project.org/ herunterladen und installieren. Eine kurze Anleitung finden Sie auf ILIAS, zusammen mit der Liste der Pakete, die wir in diesem Kurs brachen werden. Zusätzlich können Sie sich hier ein Video zur Installation ansehen.\nAuf der offiziellen R-Seite finden Sie auch zusätzliche Pakete, und zwar unter CRAN (The Comprehensive R Archive Network). Manche Pakete sind auf den CRAN-Seiten thematische in sogen. CRAN Task Views gegliedert. Für den Umweltbereich sind folgende Paketsammlungen besonders relevant:\n\nEnvironmetrics: Analyse von Umweltdaten\nMultivariate: Multivariate Statistik\nSpatial: Analyse von räumlichen Daten\nTimeSeries: Zeitreihenanalyse\n\nZu Beginn des Kurses werden wir jedoch nicht auf Ihren lokalen Rechnern arbeiten, sondern auf den bereits eingerichteten Uni-Rechnern in den EDV-Räumen. Daher biete ich zu diesem frühen Zeitpunkt im Kurs keine Unterstützung bei der Installation von R auf Ihren Privatrechnern. Für die ganz Ungeduldigen gibt es hier eine kurze Einleitung zur Installation."
  },
  {
    "objectID": "01-erste-schritte.html#was-ist-rstudio",
    "href": "01-erste-schritte.html#was-ist-rstudio",
    "title": "1  Erste Schritte in R",
    "section": "1.2 Was ist RStudio?",
    "text": "1.2 Was ist RStudio?\nRStudio Desktop ist eine Entwicklungsumgebung für R. Wichtig: RStudio wird erst nach R installiert und ergibt ohne R keinen Sinn. Sie können die open source Version kostenlos für Ihren Rechner hier herunterladen, falls Sie sich entscheiden, (später) R auf Ihrem Rechner zu installieren. Es gibt eine live Einführung in RStudio im Kurs. Zusätzlich können Sie hier ein Video dazu ansehen.\nDie Oberfläche von RStudio ist in vier Bereiche unterteilt (Abbildung 1.1).\n\n\n\nAbbildung 1.1: Aufbau von RStudio\n\n\nSie sollten auch auf Ihrem eigenen Rechner einen Ordner für die Veranstaltung anlegen und darin jeweils einen Ordner für Folien, Daten und Notebooks."
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff",
    "href": "01-erste-schritte.html#lesestoff",
    "title": "1  Erste Schritte in R",
    "section": "1.3 Lesestoff",
    "text": "1.3 Lesestoff\nKapitel 1.1 und 1.2 in Ismay and Kim (2021)."
  },
  {
    "objectID": "01-erste-schritte.html#aufgaben",
    "href": "01-erste-schritte.html#aufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.4 Aufgaben",
    "text": "1.4 Aufgaben\n\nBitte speichern Sie Ihr Skript regelmäßig ab!\n\n\n1.4.1 R als Taschenrechner\nR ist ein großer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die üblichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie später Daten in R einlesen möchten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.4.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles Mögliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verfügung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen können in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: Die linke Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erhält eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungültige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen können (fast) frei gewählt werden. Sie müssen mit einem Buchstaben beginnen und dürfen keine Sonderzeichen enthalten. Bei längeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.4.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie können im Übrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden Länge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHäufig wollen wir für unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.4.4 Objekte ansprechen\nUm das “Innenleben” der Objekte in R anzusprechen, gibt es verschieden Möglichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren möchte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir können auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen müssen in Anführungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anführungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.4.5 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat möchte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst möchte er sich einen Überblick über seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\n\nArs Mensaausgaben\n \n  \n    Wochentag \n    Ausgaben (€) \n  \n \n\n  \n    Montag \n    2,57 \n  \n  \n    Dienstag \n    2,90 \n  \n  \n    Mittwoch \n    2,73 \n  \n  \n    Donnerstag \n    3,23 \n  \n  \n    Freitag \n    3,90 \n  \n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Betrag?\nWie viel hätte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hätte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwählen!\n\nLeider hat Ar sich beim Übertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 € statt 2,90 € ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verändern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.6 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\n\nArs Mensaausgaben, cont.\n \n  \n    Wochentag \n    Amount spent (€) \n  \n \n\n  \n    Montag, 9. März \n    2,57 \n  \n  \n    Dienstag, 10. März \n    2,90 \n  \n  \n    Mittwoch, 11. März \n    2,73 \n  \n  \n    Donnerstag, 12. März \n    3,23 \n  \n  \n    Freitag, 13. März \n    3,90 \n  \n  \n    Montag, 16. März \n    NA \n  \n\n\n\n\n\nWie ändert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthält. Rufen Sie dazu die Hilfe auf, i.e. ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend.\n\n\n\n1.4.7 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nämlich um echte Datensätze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab('Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)') +\n  ylab('Lebenserwartung bei der Geburt (Jahre)') +\n  labs(title = 'Daten von Gapminder für das Jahr 2007')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e. ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgröße dargestellt?\nWie würden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "href": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "title": "1  Erste Schritte in R",
    "section": "1.6 Ihre Arbeit einreichen",
    "text": "1.6 Ihre Arbeit einreichen\n\nSpeichern Sie Ihre .Rmd Datei ab.\nLaden Sie die Datei auf ILIAS in Ihrer Übungsgruppe in der dazugehörigen Übung hoch.\nNach der Abgabe erhalten Sie die Musterlösung.\nVergleichen Sie Ihre Lösung selbstständig mit der Musterlösung.\nStellen Sie entweder in Campuswire (im #class-chat) oder in der nächsten Sitzung Fragen, falls Sie bei den Aufgaben etwas nicht verstanden haben und die Musterlösung es nicht aufklären konnte.\n\n\n\nBeachten Sie die Frist für das Hochladen der Hausaufgaben!"
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff-1",
    "href": "01-erste-schritte.html#lesestoff-1",
    "title": "1  Erste Schritte in R",
    "section": "1.7 Lesestoff",
    "text": "1.7 Lesestoff\nr4ds, Kapitel 4 (Wickham, Çetinkaya-Rundel, and Grolemund 2023)\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5 (3): 299–314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "02-rmarkdown.html",
    "href": "02-rmarkdown.html",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "",
    "text": "Wichtigkeit der Reproduzierbarkeit erklären\nBegriff literate programming definieren\nAufbau einer RMarkdown-Datei erklären\nEinen einfachen ersten reproduzierbaren Bericht selbst schreiben"
  },
  {
    "objectID": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "href": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist",
    "text": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation für dieses Thema empfehle ich das Video von Prof. Roger Peng der John Hopkins Bloogmerg School of Public Health."
  },
  {
    "objectID": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "href": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.2 Literate Programming Idee von Donald Knuth",
    "text": "2.2 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugehörige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zurück. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erklären, was man den Computer machen lassen möchte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verständlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt für viele (unentdeckte und unnötige) Fehler und Frust."
  },
  {
    "objectID": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "href": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.3 Reproduzierbare Berichte mit R Markdown",
    "text": "2.3 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und ermöglicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Präsentationsfolien usw.\nEs wird Sie vielleicht überraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein “literarisch” programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell für lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code ermöglichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endgültiges Dokument umgewandelt werden. Diesen Prozess nennt man knit."
  },
  {
    "objectID": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "href": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.4 Ein neues R Notebook erstellen",
    "text": "2.4 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine grüne Plus oben links und wählen Sie R Notebook aus. Sie können es erst einmal bei untitled belassen (Abbildung 2.1).\n\n\n\nAbbildung 2.1: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enthält das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenkürzel und Tipps. Danach können Sie den Text unterhalb des Headers löschen."
  },
  {
    "objectID": "02-rmarkdown.html#header",
    "href": "02-rmarkdown.html#header",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten müssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einrückungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterführende Literatur). Wir bleiben bei einem einfachen Header ohne Einrückungen (Abbildung Figure 2.2).\nUm einen neuen R-Chunk hinzuzufügen, klicken Sie auf das kleine grüne C+ oben rechts oder verwenden Sie das Tastenkürzel Str+Alt+i.\n\n\n\nFigure 2.2: Einen neuen R Chunk hinzufügen\n\n\nText kann einfach unterhalb des Headers und außerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente für den Text finden Sie hier. R Markdown unterstützt mathematische Notation in Latex-Stil. Eine Einführung in Latex würde an dieser Stelle aber zu weit führen.\nDas R Notebook hat den Vorteil, dass man über den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie müssen also nicht knitten. Falls Sie es doch möchten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal “geknittetes” Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, müssen Sie im Header output: html_notebbok einstellen (Abbildung (fig:rmarkdown-file?))."
  },
  {
    "objectID": "02-rmarkdown.html#wichtigste-regeln-für-reproduzierbarkeit",
    "href": "02-rmarkdown.html#wichtigste-regeln-für-reproduzierbarkeit",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.6 Wichtigste Regeln für Reproduzierbarkeit",
    "text": "2.6 Wichtigste Regeln für Reproduzierbarkeit\nEin weiteres Video von Prof. Peng widmet sich den wichtigsten Regeln für Reproduzierbarkeit."
  },
  {
    "objectID": "02-rmarkdown.html#lesestoff",
    "href": "02-rmarkdown.html#lesestoff",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.7 Lesestoff",
    "text": "2.7 Lesestoff\nIntro zu Kapitel 2 (Basics), Kapitel 3.2.1 und 3.2.2 in Xie, Allaire, and Grolemund (2021)"
  },
  {
    "objectID": "02-rmarkdown.html#weiterführende-literatur",
    "href": "02-rmarkdown.html#weiterführende-literatur",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.8 Weiterführende Literatur",
    "text": "2.8 Weiterführende Literatur\nr4ds, Kapitel 27 (Wickham, Çetinkaya-Rundel, and Grolemund 2023)"
  },
  {
    "objectID": "02-rmarkdown.html#aufgaben",
    "href": "02-rmarkdown.html#aufgaben",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.9 Aufgaben",
    "text": "2.9 Aufgaben\n\n2.9.1 Erstes Notebook\n\nErstellen Sie ein R Notebook.\nFügen Sie Layoutelemente hinzu:\n\nÜberschrift\nUnterüberschrift\nkursiver Text\nein Exponent: R2\nein Mathematikelement: \\(x^2\\)\neine Liste\n\n\nNutzen Sie die unter Kapitel 2.5 verlinkte Liste der Layoutelemente.\n\n\n2.9.2 Erste Schritte als Notebook\n\nEditieren Sie das R Notebook der ersten Session.\nGliedern Sie Ihr Notebook mit passenden Layoutelementen.\nFügen Sie mehr Erklärungstext zu den einzelnen Abschnitten.\n\n\n\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "01-erste-schritte.html#gemeinsame-aufgaben",
    "href": "01-erste-schritte.html#gemeinsame-aufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.4 Gemeinsame Aufgaben",
    "text": "1.4 Gemeinsame Aufgaben\n\nBitte speichern Sie Ihr Skript regelmäßig ab!\n\n\n1.4.1 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat möchte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst möchte er sich einen Überblick über seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\nArs Mensaausgaben\n\n\nWochentag\nAusgaben (€)\n\n\n\n\nMontag\n2,57\n\n\nDienstag\n2,90\n\n\nMittwoch\n2,73\n\n\nDonnerstag\n3,23\n\n\nFreitag\n3,90\n\n\n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Betrag?\nWie viel hätte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hätte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwählen!\n\nLeider hat Ar sich beim Übertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 € statt 2,90 € ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verändern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.2 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\nArs Mensaausgaben, cont.\n\n\nWochentag\nAmount spent (€)\n\n\n\n\nMontag, 9. März\n2,57\n\n\nDienstag, 10. März\n2,90\n\n\nMittwoch, 11. März\n2,73\n\n\nDonnerstag, 12. März\n3,23\n\n\nFreitag, 13. März\n3,90\n\n\nMontag, 16. März\nNA\n\n\n\n\n\n\n\nWie ändert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthält. Rufen Sie dazu die Hilfe auf, i.e. ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend."
  },
  {
    "objectID": "01-erste-schritte.html#hausaufgaben",
    "href": "01-erste-schritte.html#hausaufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.5 Hausaufgaben",
    "text": "1.5 Hausaufgaben\n\n1.5.1 R als Taschenrechner\nR ist ein großer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die üblichen Rechenregeln wie z. B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie später Daten in R einlesen möchten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.5.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles Mögliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verfügung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen können in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings die Pfeilrichtung entscheidend! x <- 42 bedeutet: Die rechte Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, ergibt die Zuweisung keinen Sinn und man erhält eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungültige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen können (fast) frei gewählt werden. Sie müssen mit einem Buchstaben beginnen und dürfen keine Sonderzeichen enthalten. Bei längeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z. B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.5.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z. B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie können im Übrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden Länge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHäufig wollen wir für unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.5.4 Objekte ansprechen\nUm das “Innenleben” der Objekte in R anzusprechen, gibt es verschiedene Möglichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z. B. die dritte Komponente extrahieren möchte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir können auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen müssen in Anführungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anführungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.5.5 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nämlich um echte Datensätze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)', \n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i. e. ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgröße dargestellt?\nWie würden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "02-rmarkdown.html#sec-header",
    "href": "02-rmarkdown.html#sec-header",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten müssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einrückungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterführende Literatur). Wir bleiben bei einem einfachen Header ohne Einrückungen (Abbildung 2.2).\nUm einen neuen R-Chunk hinzuzufügen, klicken Sie auf das kleine grüne C+ oben rechts oder verwenden Sie das Tastenkürzel Str+Alt+i.\n\n\n\nAbbildung 2.2: Einen neuen R Chunk hinzufügen\n\n\nText kann einfach unterhalb des Headers und außerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente für den Text finden Sie hier. R Markdown unterstützt mathematische Notation in Latex-Stil. Eine Einführung in Latex würde an dieser Stelle aber zu weit führen.\nDas R Notebook hat den Vorteil, dass man über den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie müssen also nicht knitten. Falls Sie es doch möchten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal “geknittetes” Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, müssen Sie im Header output: html_notebbok einstellen (Abbildung 2.2)."
  },
  {
    "objectID": "20-aufgabensammlung.html",
    "href": "20-aufgabensammlung.html",
    "title": "Appendix A — Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele Vögel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFühren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "03-ggplot.html",
    "href": "03-ggplot.html",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "",
    "text": "Aufbau des Aufrufs der Funktion ggplot() kennen\nfünf wichtigste Grafiktypen kennen und einsetzten"
  },
  {
    "objectID": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "href": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.1 Aufbau eines Darstellungsbefehls",
    "text": "3.1 Aufbau eines Darstellungsbefehls\nDas Paket ggplot2 ist ein sehr mächtiges Visualisierungswerkzeug. Der Name steht für “the grammar of graphics”. Das bedeutet, dass man mithilfe von verschiedenen Funktionen in ggplot2 seine Grafik Schritt für Schritt aufbaut, wie einen (grammatikalisch korrekten) Satz. In aller Kürze bedeutet das:\n\nEine statistische Grafik ist eine Zuordnung (mapping) von Variablen in einem Datensatz (data) zu (ästhetischen) Attributen (aes) von geometrischen Objekten (geom).\n\nWir müssen also für die Darstellung von Daten R Folgendes mitteilen:\n\ndata: der Datensatz, der die Variablen enthält, die wir darstellen möchten.\naes: (ästhetische) Attribute für die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z. B. die \\(x\\)- und \\(y\\)-Koordinaten, Farbe, Form und Größe der geometrischen Objekte.\ngeom: geometrische Objekte, die dargestellt werden sollen, z. B. Punkte, Linien, Boxen, Balken/Säulen etc.\n\nWir laden zunächst die nötigen Bibliotheken.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nAnschließend filtern wir den Datensatz gapminder, um nur die Daten aus dem Jahr 2007 zu behalten. Der Code filter(year == 2007) bedeutet, dass wir nur die Zeilen aus dem Datensatz behalten wollen, in denen in der Variable year 2007 steht.\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nWir überzeugen uns davon, dass es geklappt hat 😄. Blättern Sie durch den Datensatz und überprüfen Sie die Werte in der Variablen year.\n\ngapminder2007"
  },
  {
    "objectID": "03-ggplot.html#punktdiagramm",
    "href": "03-ggplot.html#punktdiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Punktdiagramm",
    "text": "3.2 Punktdiagramm\nEin typischer Befehl zur Visualisierung würde also so aussehen:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n{width== “90%”}\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap\nauf die y-Achse die Variable lifeExp\nfärbe ein mithilfe der Variablen continent\nbestimme die Größe der Symbole mithilfe der Variablen pop\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe als auch für die Größe der Symbole, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z.B. sind die Beschriftungen der beiden Achsen so nichtssagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Kopf (US$)', y = 'Lebenserwartung (Jahre)',\n       color = 'Kontinent', size = 'Bevölkerung')\n\n{width== “90%”}"
  },
  {
    "objectID": "03-ggplot.html#weitere-geoms",
    "href": "03-ggplot.html#weitere-geoms",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.3 Weitere geoms",
    "text": "3.3 Weitere geoms\nDas geom_point() produziert ein Streudiagramm, auch XY-Diagramm (scatter plot). Weiter wichtige Grafiktypen sind:\n\ngeom_line(): Linien\ngeom_bar(): Balken"
  },
  {
    "objectID": "03-ggplot.html#scatter",
    "href": "03-ggplot.html#scatter",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (Kontinent)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe continent als auch für die Größe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#histogramm",
    "href": "03-ggplot.html#histogramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Histogramm",
    "text": "3.5 Histogramm\nWie ist das GDP im Jahre 2007 in Afrika und Europa verteilt? Dazu nutzen wir das Histogramm und filtern die Daten vorher entsprechend. Als Ästhetik eignet sich hier fill besser als color.\n\nafrica_europe <- gapminder2007 %>% \n  filter(continent %in% c('Africa', 'Europe'))\n\nggplot(africa_europe, mapping = aes(x = gdpPercap, fill = continent)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "03-ggplot.html#boxplot",
    "href": "03-ggplot.html#boxplot",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.6 Boxplot",
    "text": "3.6 Boxplot\nWie ist das GDP im Jahre 2007 auf verschiedenen Kontinenten verteilt? Ein Histogramm mit allen Kontinenten würde schnell sehr unübersichtlich werden. Das geht mit einem Boxplot besser.\n\nggplot(gapminder2007, mapping = aes(x = continent, y = gdpPercap)) +\n  geom_boxplot()"
  },
  {
    "objectID": "03-ggplot.html#säulendiagramm",
    "href": "03-ggplot.html#säulendiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Säulendiagramm",
    "text": "3.5 Säulendiagramm\nWie viele Einträge gibt es pro Kontinent? Das Säulendiagramm zählt für uns die Einträge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine Häufigkeitstabelle enthalten würde.\n\nggplot(data = gapminder, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "03-ggplot.html#lesestoff",
    "href": "03-ggplot.html#lesestoff",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.6 Lesestoff",
    "text": "3.6 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "03-ggplot.html#aufgaben",
    "href": "03-ggplot.html#aufgaben",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.7 Aufgaben",
    "text": "3.7 Aufgaben\n\n3.7.1 Darstellung von großen Zahlen\nWir verändern die Grafik aus Kapitel 3.2 so, dass die Symbole nach der Größe der Einwohnerzahl skaliert werden. Dazu benutzen wir ein neues Argument in der Funktion aes(size = pop):\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\n\n\nDie Einwohnerzahlen sind sehr groß. Daher stellt R sie in der sogen. wissenschaftlichen Notation dar. Dabei steht z. B. e+08 für \\(10^8\\). Das heißt 2.5e+08 sind 250000000 Einwohner.\nBeschriften Sie die Legende für die Größe der Symbole richtig, indem Sie size = 'Einwohnerzahl' in der Funktion labs() hinzufügen.\n\n\n3.7.2 Grafiken richtig beschriften\nBis auf die Grafik in Kapitel 3.4 fehlen bei den Grafiken oben ordentliche Achsenbeschriftungen und Titel für die Legenden. Ergänzen Sie den Code entsprechend."
  },
  {
    "objectID": "03-ggplot.html#ihre-arbeit-einreichen",
    "href": "03-ggplot.html#ihre-arbeit-einreichen",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.8 Ihre Arbeit einreichen",
    "text": "3.8 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "03-ggplot.html#streudiagramm",
    "href": "03-ggplot.html#streudiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (Kontinent)\nbestimme die Größe der Symbole mithilfe der Variablen pop (Einwohnerzahl)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe continent als auch für die Größe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       size = 'Einwohnerzahl',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#line",
    "href": "03-ggplot.html#line",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen für Frankreich und Deutschland heraus. Weil wir jetzt zwei Länder haben möchten, muss beim Filtern ein Vektor mit Ländernamen angegeben werden und statt == der Operator %in%. Wir werden später noch ausführlich auf diese Operatoren zurückkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "03-ggplot.html#sec-scatter",
    "href": "03-ggplot.html#sec-scatter",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz gapminder2007 (data = gapminder2007) und\nOrdne folgende Attribute zu:\n\nauf die \\(x\\)-Achse die Variable gdpPercap (x = gdpPercap) (Bruttoinlandsprodukt)\nauf die \\(y\\)-Achse die Variable lifeExp (y = lifeExp) (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (color = continent).\n\nStelle das Ganze als geometrisches Objekt Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch erstellt wird. Merke: color innerhalb der Funktion aes() erstellt die Legende automatisch.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichtssagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#sec-line",
    "href": "03-ggplot.html#sec-line",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen für Frankreich und Deutschland heraus. Weil wir jetzt zwei Länder haben möchten, muss beim Filtern ein Vektor mit Ländernamen angegeben werden und statt == der Operator %in%. Wir werden später noch ausführlich auf diese Operatoren zurückkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "20-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "href": "20-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.2 Einführung in die Darstellung von Daten",
    "text": "A.2 Einführung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen Flossenlänge flipper_length_mm auf der \\(x\\)-Achse und der Variablen Körpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFärben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung 🤓."
  },
  {
    "objectID": "03-ggplot.html#balkendiagramm",
    "href": "03-ggplot.html#balkendiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Balkendiagramm",
    "text": "3.5 Balkendiagramm\nWie viele Länder gibt es pro Kontinent im Jahr 2007? Das Balkendiagramm zählt für uns die Einträge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine Häufigkeitstabelle enthalten würde.\n\nggplot(data = gapminder2007, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "04-einlesen.html",
    "href": "04-einlesen.html",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "",
    "text": "Daten aus Textdateien in R einlesen\nDie $-Notation\nAnsprechen eines Eintrags im tibble\nDaten als Textdateien aus R speichern"
  },
  {
    "objectID": "04-einlesen.html#lesestoff",
    "href": "04-einlesen.html#lesestoff",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.6 Lesestoff",
    "text": "4.6 Lesestoff\nKapitel 4.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "04-einlesen.html#aufgaben",
    "href": "04-einlesen.html#aufgaben",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.7 Aufgaben",
    "text": "4.7 Aufgaben"
  },
  {
    "objectID": "04-einlesen.html#ihre-arbeit-einreichen",
    "href": "04-einlesen.html#ihre-arbeit-einreichen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.10 Ihre Arbeit einreichen",
    "text": "4.10 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "05-explorative-kategorial.html",
    "href": "05-explorative-kategorial.html",
    "title": "5  Exploration von kategorialen Daten",
    "section": "",
    "text": "Den Pipe-Operator %>%nutzen\nKategoriale Variablen in Faktor umwandeln\nKategoriale Variablen darstellen\nNeue Variablen mit mutate() erstellen\nHäufigkeits- und Kontingenztabellen erstellen"
  },
  {
    "objectID": "05-explorative-kategorial.html#lesestoff",
    "href": "05-explorative-kategorial.html#lesestoff",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.2 Lesestoff",
    "text": "5.2 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "05-explorative-kategorial.html#aufgaben",
    "href": "05-explorative-kategorial.html#aufgaben",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.3 Aufgaben",
    "text": "5.3 Aufgaben\n\n5.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus Kapitel 5.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n5.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ändern Sie die finale Grafik in Kapitel 5.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie ändert sich die Position der Ländernamen?\n\n\n\n5.3.3 Tutorium\nBearbeiten Sie das Tutorium “Einführung in Daten: 1 - Die Sprache der Daten”. Sie können entweder die deutsche Übersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "href": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.4 Ihre Arbeit einreichen",
    "text": "5.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "href": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.1 Daten aus Textdateien in R einlesen",
    "text": "4.1 Daten aus Textdateien in R einlesen\nUm Daten aus Textdateien (z.B. aus .csv, .txt, .dat) in R zu importieren (i.e. einzulesen) werden wir die Bibliothek readr aus tidyverse benutzen. Wir laden erst einmal tidyverse.\n\nlibrary(tidyverse)\n\nWir gehen davon aus, dass die Daten im Ordner Daten gespeichert sind. Falls Ihre Daten an einem anderen Ort abgelegt sind, müssen Sie den Pfad beim Einlesen entsprechend anpassen.\nUm die Daten zu laden, gibt es in der Bibliothek readr verschiedene Funktionen, die alle mit read_ beginnen. Die allgemeinste davon ist read_delim. Darin kann man explizit einstellen, mit welchem Zeichen (z. B. Komma, Strichpunkt etc.) die einzelnen Spalten in der zu importierenden Datei getrennt sind. In der Datei, die wir einlesen, ist das Trennungszeichen ;. Das müssen Sie aber bei jeder Datei, die Sie einlesen, nachsehen.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2023-10-08.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEin kurzer Blick auf den Datensatz, den Sie aus der ersten Sitzung der Vorlesung erkennen sollten 😄. Es sind die Daten zur Mobilität in Europa aus eurostat, heruntergeladen am 08.10.2023 und vorgefiltert. Die Daten beinhalten die Anzhal der “Personenkraftwagen je 1 000 Einwohner”, online Datencode: ROAD_EQS_CARHAB.\n\ncar_numbers\n\n\n\n  \n\n\n\nDas Ergebnis des Einlesens mit read_ Funktionen ist immer ein tibble."
  },
  {
    "objectID": "04-einlesen.html#einzlene-variablen-ansprechen",
    "href": "04-einlesen.html#einzlene-variablen-ansprechen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzlene Variablen ansprechen",
    "text": "4.2 Einzlene Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen Nutzen, um die Variable anzusprechen. Z. B. könnten wir die Variable geo so ansprechen:\n\ncars$geo\n\n [1] \"Albania\"         \"Albania\"         \"Austria\"         \"Austria\"        \n [5] \"Belgium\"         \"Belgium\"         \"Bulgaria\"        \"Bulgaria\"       \n [9] \"Croatia\"         \"Croatia\"         \"Cyprus\"          \"Cyprus\"         \n[13] \"Czechia\"         \"Czechia\"         \"Denmark\"         \"Denmark\"        \n[17] \"Estonia\"         \"Estonia\"         \"Finland\"         \"Finland\"        \n[21] \"France\"          \"France\"          \"Germany\"         \"Germany\"        \n[25] \"Greece\"          \"Greece\"          \"Hungary\"         \"Hungary\"        \n[29] \"Iceland\"         \"Iceland\"         \"Ireland\"         \"Ireland\"        \n[33] \"Italy\"           \"Italy\"           \"Kosovo\"          \"Kosovo\"         \n[37] \"Latvia\"          \"Latvia\"          \"Liechtenstein\"   \"Liechtenstein\"  \n[41] \"Lithuania\"       \"Lithuania\"       \"Luxembourg\"      \"Luxembourg\"     \n[45] \"Malta\"           \"Malta\"           \"Montenegro\"      \"Montenegro\"     \n[49] \"Netherlands\"     \"Netherlands\"     \"North Macedonia\" \"North Macedonia\"\n[53] \"Norway\"          \"Norway\"          \"Poland\"          \"Poland\"         \n[57] \"Portugal\"        \"Portugal\"        \"Romania\"         \"Romania\"        \n[61] \"Serbia\"          \"Serbia\"          \"Slovakia\"        \"Slovakia\"       \n[65] \"Slovenia\"        \"Slovenia\"        \"Spain\"           \"Spain\"          \n[69] \"Sweden\"          \"Sweden\"          \"Switzerland\"     \"Switzerland\"    \n[73] \"Türkiye\"         \"Türkiye\"         \"United Kingdom\"  \"United Kingdom\" \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 Einträge (Länder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen mehrere Spalten in einem tibble",
    "text": "4.3 Ansprechen mehrere Spalten in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nämlich zwei Indizes: einen Index für die Zeile und einen Index für die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Österreich. Wir können auch ganze Spalten (Variablen) ansprechen. Dafür wird der erste Index (für Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Einträge gemeint sind. So können wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es ähnlich. Wir lassen den Index für die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurück. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "04-einlesen.html#ein-tibble-erstellen",
    "href": "04-einlesen.html#ein-tibble-erstellen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.4 Ein tibble erstellen",
    "text": "4.4 Ein tibble erstellen\nUm ein tibble zu erstellen, nutzen wir die Funktion tibble() und zählen auf, welche Variablen wir dort haben möchten.\n\ncar_numbers_short <- tibble(Land = car_numbers$geo, Zeit = car_numbers$time)\n\nIn dem Datensatz car_numbers_short haben wir jetzt die beiden Variablen geo und time aus dem Datensatz car_numbers als tibble abgespeichert."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-r-speichern",
    "href": "04-einlesen.html#daten-aus-r-speichern",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.5 Daten aus R speichern",
    "text": "4.5 Daten aus R speichern\nWir speichern dieses tibble als Textdatei. Dafür nutzen wir die Funktion write_delim(), die ebenfalls in der Bibliothek readr in tidyverse vorhanden ist. Achten Sie darauf, dass write_delim() nur tibble speichern kann. Wenn Sie einen Vektor (eine einzelne Variable) abspeichern möchten, dann wandeln Sie diesen zuerst in ein tibble um.\n\nwrite_delim(x = car_numbers_short, file = 'Daten/geo.csv', delim = ';')"
  },
  {
    "objectID": "05-explorative-kategorial.html#mobilität-in-europa",
    "href": "05-explorative-kategorial.html#mobilität-in-europa",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.1 Mobilität in Europa",
    "text": "5.1 Mobilität in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. Zunächst laden wir wie immer die nötigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n5.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen können, welche verschiedenen Merkmalsausprägungen die Variable enthält. Zur Erinnerung: Merkmalsausprägungen sind die theoretisch möglichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsächlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse für eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen Merkmalsausprägungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heißt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Übergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben könnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unübersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schön strukturiert, wird er häufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verändern oder löschen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhält man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fügt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun können wir R auch fragen, welche verschiedenen Merkmalsausprägungen (levels) diese Variable enthält:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"         \"Austria\"         \"Belgium\"         \"Bulgaria\"       \n [5] \"Croatia\"         \"Cyprus\"          \"Czechia\"         \"Denmark\"        \n [9] \"Estonia\"         \"Finland\"         \"France\"          \"Germany\"        \n[13] \"Greece\"          \"Hungary\"         \"Iceland\"         \"Ireland\"        \n[17] \"Italy\"           \"Kosovo\"          \"Latvia\"          \"Liechtenstein\"  \n[21] \"Lithuania\"       \"Luxembourg\"      \"Malta\"           \"Montenegro\"     \n[25] \"Netherlands\"     \"North Macedonia\" \"Norway\"          \"Poland\"         \n[29] \"Portugal\"        \"Romania\"         \"Serbia\"          \"Slovakia\"       \n[33] \"Slovenia\"        \"Spain\"           \"Sweden\"          \"Switzerland\"    \n[37] \"Türkiye\"         \"United Kingdom\" \n\n\nDie einzelnen Merkmalsausprägungen sind die verschiedenen Länder. Der Datensatz enthält 38 unterschiedliche Länder.\n\n\n5.1.2 Balkendiagramm mit geom_col()\nWir möchten die Daten als Balkendiagramm darstellen. Das Ziel ist eine ähnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafür müssen wir zuerst eine neue Variable erstellen, die wir zum Einfärben der Jahre nutzen können. Dazu benötigen wir eine zusätzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heißt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum Einfärben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern überschreibt (verändert) die vorhandene Variable time_year. Das ist möglich und gängige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im Kapitel Kapitel 3 haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der Einträge in einer Variablen auszählen und diese als Balkendiagramm darstellen. Das möchten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht für columns, also Säulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nötig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmäßig ein Stapelbalkendiagramm darstellt (stacked bar plot ). Möchte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie Ländernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall überdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehängt wird. Sie heißt theme(). Der Parameter, der für die Gestaltung der \\(x\\)-Achse zuständig ist, heißt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen Länder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\nWarning: Removed 3 rows containing missing values (geom_col)."
  },
  {
    "objectID": "04-einlesen.html#eine-grafik-speichern",
    "href": "04-einlesen.html#eine-grafik-speichern",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.6 Eine Grafik speichern",
    "text": "4.6 Eine Grafik speichern"
  },
  {
    "objectID": "04-einlesen.html#einzelne-variablen-ansprechen",
    "href": "04-einlesen.html#einzelne-variablen-ansprechen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzelne Variablen ansprechen",
    "text": "4.2 Einzelne Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen nutzen, um die Variable anzusprechen. Z. B. könnten wir die Variable geo so ansprechen:\n\ncar_numbers$geo\n\n [1] \"Albania\"                \"Albania\"                \"Austria\"               \n [4] \"Austria\"                \"Belgium\"                \"Belgium\"               \n [7] \"Bosnia and Herzegovina\" \"Bosnia and Herzegovina\" \"Bulgaria\"              \n[10] \"Bulgaria\"               \"Croatia\"                \"Croatia\"               \n[13] \"Cyprus\"                 \"Cyprus\"                 \"Czechia\"               \n[16] \"Czechia\"                \"Denmark\"                \"Denmark\"               \n[19] \"Estonia\"                \"Estonia\"                \"Finland\"               \n[22] \"Finland\"                \"France\"                 \"France\"                \n[25] \"Germany\"                \"Germany\"                \"Greece\"                \n[28] \"Greece\"                 \"Hungary\"                \"Hungary\"               \n[31] \"Iceland\"                \"Iceland\"                \"Ireland\"               \n[34] \"Ireland\"                \"Italy\"                  \"Italy\"                 \n[37] \"Kosovo\"                 \"Kosovo\"                 \"Latvia\"                \n[40] \"Latvia\"                 \"Liechtenstein\"          \"Liechtenstein\"         \n[43] \"Lithuania\"              \"Lithuania\"              \"Luxembourg\"            \n[46] \"Luxembourg\"             \"Malta\"                  \"Malta\"                 \n[49] \"Montenegro\"             \"Montenegro\"             \"Netherlands\"           \n[52] \"Netherlands\"            \"North Macedonia\"        \"North Macedonia\"       \n[55] \"Norway\"                 \"Norway\"                 \"Poland\"                \n[58] \"Poland\"                 \"Portugal\"               \"Portugal\"              \n[61] \"Romania\"                \"Romania\"                \"Slovakia\"              \n[64] \"Slovakia\"               \"Slovenia\"               \"Slovenia\"              \n[67] \"Spain\"                  \"Spain\"                  \"Sweden\"                \n[70] \"Sweden\"                 \"Switzerland\"            \"Switzerland\"           \n[73] \"Türkiye\"                \"Türkiye\"                \"United Kingdom\"        \n[76] \"United Kingdom\"        \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 Einträge (Länder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "href": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.8 Die Umfrage aus der ersten Sitzung",
    "text": "4.8 Die Umfrage aus der ersten Sitzung\nLesen Sie die Datei ‘Umfrage_2023_kurz.csv’ ein (sie ist auf ILIAS zu finden). Sie enthält die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage ‘Haben Sie schon mal einen Statistikkurs besucht?’\n\nWie viele Einträge enthält der Datensatz?\nWie viele Variablen enthält der Datensatz?\nSind die Variablen numerisch oder kategorial? Wurden die Variablen auch so von R eingelesen?\nErklären Sie jede Variable. Welche Information enthält sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungefähr)?"
  },
  {
    "objectID": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "href": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.2 Lending Club – Peer-to-Peer-Kredite",
    "text": "5.2 Lending Club – Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen über eine Plattform ermöglicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouse…\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  <fct> Verified, Not Verified, Source Verifi…\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,…\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     <fct> moving, debt_consolidation, other, de…\n$ application_type                 <fct> individual, individual, individual, i…\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87…\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      <fct> Current, Current, Current, Current, C…\n$ initial_listing_status           <fct> whole, whole, fractional, whole, whol…\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,…\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,…\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569…\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.…\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n5.2.1 Häufigkeitstabelle\nWir erstellen eine Häufigkeitstabelle der Variable homeownership. Dazu müssen wir die einzelnen Merkmalswerte auszählen lassen. Das übernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership für die Vorlesung verändert wurde. Es ist nämlich störend, wenn die Merkmalsausprägungen mit Großbuchstaben geschrieben werden. Außerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir ändern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu überschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Änderungen in einem Aufruf zu mutate() durchführen darf. Zuerst macht die Funktion tolower() aus den Großbuchstaben Kleinbuchstaben, danach änder die Funktion fct_relevel() die Reihenfolge der Merkmalsausprägungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n5.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nämlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall möchte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen Fälle, nämlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy 🤓.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die Einträge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die einträge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige ästhetische Griffe ist das jetzt das Gleiche wie in der Vorlesung 😄."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble",
    "text": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nämlich zwei Indizes: einen Index für die Zeile und einen Index für die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Österreich. Wir können auch ganze Spalten (Variablen) ansprechen. Dafür wird der erste Index (für Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Einträge gemeint sind. So können wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es ähnlich. Wir lassen den Index für die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurück. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen Oberflächen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante Datensätze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Übung lernen Sie das Paket haven kennen, dass solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschäftigen uns mit dem Datensatz “Politbarometer 2021”. Die Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen für das ZDF durchgeführt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind für Lehre und Forschung frei. Sie müssen Sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter “Downloads” (rechts oben) den Datensatz “ZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MB” herunter. Dafür werden Sie sich einmalig (und kostenlos) anmelden müssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem “Daten”-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei “ZA7856_v1-0-0.dta” finden. Das ist der eigentliche Datensatz.\n\nDatensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich für die Übung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthält der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der “Tabelle 1: Variablenkorrespondenzliste Politbarometer 2021” gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren ändern. Gehen Sie durch den Code Zeile für Zeile durch und erklären Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenüber dem ursprünglichen Datensatz gesis verändert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse für Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Übung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie müssen vorher natürlich diese Bibliothek mit library() laden.\n\n\n\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir müssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der Merkmalsausprägungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmäßig so, wie diese im Datensatz erscheinen. Das ist für die Bundesländer ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den Bundesländern ausgeprägt ist. Dafür sehen wir uns die Antworten auf die Frage “Wie stark interessieren Sie sich für Politik, …”. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der Merkmalsausprägungen ist unlogisch. Das müssen wir ändern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht für keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der Merkmalsausprägungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den Bundesländern. Ist das Interesse der Bürger ähnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen Häufigkeiten heran. Was macht der nachfolgende Code. Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nächste Schritt ist es, die relativen Häufigkeiten (Anteile) für jedes Bundesland auszurechnen, um die obige Frage zu beantworten. Erklären Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurück zu unserer Frage: Ist das Interesse der Bürger in allen Bundesländern ähnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafür können Sie folgende Code-Fragmente ergänzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +\n  labs(___)\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner’s Guide to R. Springer."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html",
    "href": "30-lab-02-intro-to-data.html",
    "title": "8  Lab 02: Pünktlichkeit von Flügen",
    "section": "",
    "text": "Das ist die deutsche Übersetzung des “OpenIntro Labs for R and tidyverse” 2. Intro to data. Es ist Teil des Buches von Çetinkaya-Rundel et al., Introduction to Modern Statistics, lizenziert unter CC-BY-SA 3.0. Übersetzt mit www.DeepL.com/Translator, bearbeitet und ergänzt von C. Bogner und L. Dedeke.\nManche definieren Statistik als das Gebiet, das sich darauf konzentriert, Informationen in Wissen zu verwandeln. Der erste Schritt in diesem Prozess ist die Zusammenfassung und Beschreibung der Rohinformationen - der Daten. In dieser Übung untersuchen wir Flüge, insbesondere eine Zufallsstichprobe von Inlandsflügen, die im Jahr 2013 von den drei großen Flughäfen in New York City abgeflogen sind. Wir werden einfache grafische und numerische Zusammenfassungen der Daten zu diesen Flügen erstellen und die Verspätungszeiten untersuchen. Da es sich um einen großen Datensatz handelt, werden Sie nebenbei auch die unverzichtbaren Fertigkeiten der Datenverarbeitung und -unterteilung erlernen."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#mobilität-in-europa",
    "href": "30-lab-02-intro-to-data.html#mobilität-in-europa",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.1 Mobilität in Europa",
    "text": "6.1 Mobilität in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. Zunächst laden wir wie immer die nötigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n6.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen können, welche verschiedenen Merkmalsausprägungen die Variable enthält. Zur Erinnerung: Merkmalsausprägungen sind die theoretisch möglichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsächlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse für eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen Merkmalsausprägungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heißt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Übergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben könnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unübersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schön strukturiert, wird er häufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verändern oder löschen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhält man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fügt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun können wir R auch fragen, welche verschiedenen Merkmalsausprägungen (levels) diese Variable enthält:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"         \"Austria\"         \"Belgium\"         \"Bulgaria\"       \n [5] \"Croatia\"         \"Cyprus\"          \"Czechia\"         \"Denmark\"        \n [9] \"Estonia\"         \"Finland\"         \"France\"          \"Germany\"        \n[13] \"Greece\"          \"Hungary\"         \"Iceland\"         \"Ireland\"        \n[17] \"Italy\"           \"Kosovo\"          \"Latvia\"          \"Liechtenstein\"  \n[21] \"Lithuania\"       \"Luxembourg\"      \"Malta\"           \"Montenegro\"     \n[25] \"Netherlands\"     \"North Macedonia\" \"Norway\"          \"Poland\"         \n[29] \"Portugal\"        \"Romania\"         \"Serbia\"          \"Slovakia\"       \n[33] \"Slovenia\"        \"Spain\"           \"Sweden\"          \"Switzerland\"    \n[37] \"Türkiye\"         \"United Kingdom\" \n\n\nDie einzelnen Merkmalsausprägungen sind die verschiedenen Länder. Der Datensatz enthält 38 unterschiedliche Länder.\n\n\n6.1.2 Balkendiagramm mit geom_col()\nWir möchten die Daten als Balkendiagramm darstellen. Das Ziel ist eine ähnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafür müssen wir zuerst eine neue Variable erstellen, die wir zum Einfärben der Jahre nutzen können. Dazu benötigen wir eine zusätzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heißt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum Einfärben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern überschreibt (verändert) die vorhandene Variable time_year. Das ist möglich und gängige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im Kapitel ?sec-ggplot haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der Einträge in einer Variablen auszählen und diese als Balkendiagramm darstellen. Das möchten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht für columns, also Säulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nötig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmäßig ein Stapelbalkendiagramm darstellt (stacked bar plot ). Möchte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie Ländernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall überdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehängt wird. Sie heißt theme(). Der Parameter, der für die Gestaltung der \\(x\\)-Achse zuständig ist, heißt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen Länder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\nWarning: Removed 3 rows containing missing values (geom_col)."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "href": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.2 Lending Club – Peer-to-Peer-Kredite",
    "text": "6.2 Lending Club – Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen über eine Plattform ermöglicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouse…\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  <fct> Verified, Not Verified, Source Verifi…\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,…\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     <fct> moving, debt_consolidation, other, de…\n$ application_type                 <fct> individual, individual, individual, i…\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87…\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      <fct> Current, Current, Current, Current, C…\n$ initial_listing_status           <fct> whole, whole, fractional, whole, whol…\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,…\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,…\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569…\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.…\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n6.2.1 Häufigkeitstabelle\nWir erstellen eine Häufigkeitstabelle der Variable homeownership. Dazu müssen wir die einzelnen Merkmalswerte auszählen lassen. Das übernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership für die Vorlesung verändert wurde. Es ist nämlich störend, wenn die Merkmalsausprägungen mit Großbuchstaben geschrieben werden. Außerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir ändern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu überschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Änderungen in einem Aufruf zu mutate() durchführen darf. Zuerst macht die Funktion tolower() aus den Großbuchstaben Kleinbuchstaben, danach änder die Funktion fct_relevel() die Reihenfolge der Merkmalsausprägungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n6.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nämlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall möchte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen Fälle, nämlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy 🤓.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die Einträge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die einträge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige ästhetische Griffe ist das jetzt das Gleiche wie in der Vorlesung 😄."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#aufgaben",
    "href": "30-lab-02-intro-to-data.html#aufgaben",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.3 Aufgaben",
    "text": "6.3 Aufgaben\n\n6.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus Section 6.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n6.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ändern Sie die finale Grafik in Section 6.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie ändert sich die Position der Ländernamen?\n\n\n\n6.3.3 Tutorium\nBearbeiten Sie das Tutorium “Einführung in Daten: 1 - Die Sprache der Daten”. Sie können entweder die deutsche Übersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "href": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.4 Ihre Arbeit einreichen",
    "text": "6.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen."
  },
  {
    "objectID": "100-aufgabensammlung.html",
    "href": "100-aufgabensammlung.html",
    "title": "Appendix A — Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009a). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele Vögel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFühren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "href": "100-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.2 Einführung in die Darstellung von Daten",
    "text": "A.2 Einführung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen Flossenlänge flipper_length_mm auf der \\(x\\)-Achse und der Variablen Körpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFärben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung 🤓."
  },
  {
    "objectID": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen Oberflächen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante Datensätze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Übung lernen Sie das Paket haven kennen, das solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschäftigen uns mit dem Datensatz “Politbarometer 2021”. Das Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen für das ZDF durchgeführt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind für Lehre und Forschung frei. Sie müssen sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter “Downloads/Datasets” (rechts oben) den Datensatz “ZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MB” herunter. Dafür werden Sie sich einmalig (und kostenlos) anmelden müssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem “Daten”-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei “ZA7856_v1-0-0.dta” finden. Das ist der eigentliche Datensatz.\n\nDen Datensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich für die Übung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthält der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der “Tabelle 1: Variablenkorrespondenzliste Politbarometer 2021” gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren ändern. Gehen Sie durch den Code Zeile für Zeile durch, und erklären Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenüber dem ursprünglichen Datensatz gesis verändert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse für Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Übung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie müssen vorher natürlich diese Bibliothek mit library() laden.\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir müssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der Merkmalsausprägungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmäßig so, wie diese im Datensatz erscheinen. Das ist für die Bundesländer ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den Bundesländern ausgeprägt ist. Dafür sehen wir uns die Antworten auf die Frage “Wie stark interessieren Sie sich für Politik, …”. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der Merkmalsausprägungen ist unlogisch. Das müssen wir ändern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht für keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der Merkmalsausprägungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den Bundesländern. Ist das Interesse der Bürger ähnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen Häufigkeiten heran. Was macht der nachfolgende Code? Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nächste Schritt ist es, die relativen Häufigkeiten (Anteile) für jedes Bundesland auszurechnen, um die obige Frage zu beantworten. Erklären Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurück zu unserer Frage: Ist das Interesse der Bürger in allen Bundesländern ähnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafür können Sie folgende Code-Fragmente ergänzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  labs(___) +\n  theme_minimal()\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#erste-schritte",
    "href": "30-lab-02-intro-to-data.html#erste-schritte",
    "title": "11  Lab 02: Pünktlichkeit von Flügen",
    "section": "11.1 Erste Schritte",
    "text": "11.1 Erste Schritte\n\n11.1.1 Pakete laden\nIn dieser Übung werden wir die Daten mithilfe der Paketsammlung tidyverse untersuchen und visualisieren. Die Daten befinden sich im Begleitpaket für OpenIntro-Übungen, openintro.\nLassen Sie uns die Pakete laden.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n\n11.1.2 Erstellen eines reproduzierbaren Berichts\nDenken Sie daran, dass wir R Markdown verwenden werden, um reproduzierbare Berichte zu erstellen. Gehen Sie in RStudio zu New File -> R Markdown… Wählen Sie dann From Template und wählen Sie dann Lab Report for OpenIntro Statistics Labs aus der Liste der Vorlagen. Oder verfahren Sie so, wie wir es in den Übungen gelernt haben New File -> R Notebook… Beide Varianten sind in Ordnung. Wenn Sie die Variante mit R Markdown wählen, gibt es keinen Button “Preview”, sondern Sie müssen das Dokument “knitten” über den Button mit dem Wollknäuel.\nSehen Sie sich das folgende Video an, in dem beschrieben wird, wie Sie mit der Erstellung dieser Berichte für dieses und alle zukünftigen Labs beginnen können:\nGrundlegendes zu R Markdown mit einer OpenIntro-Übung \n\n\n11.1.3 Die Daten\nDas Bureau of Transportation Statistics (BTS) ist eine Statistikbehörde, die zur Research and Innovative Technology Administration (RITA) gehört. Wie der Name schon sagt, sammelt das BTS Verkehrsdaten und stellt sie zur Verfügung, wie z. B. die Flugdaten, mit denen wir in diesem Labor arbeiten werden.\nAls Erstes werden wir uns den Datensatz nycflights ansehen. Geben Sie Folgendes in Ihre Konsole ein, um die Daten zu laden:\n\ndata(nycflights)\n\nDer Datensatz nycflights, der in Ihrem Arbeitsbereich angezeigt wird, ist eine Datenmatrix oder Datentabelle, wobei jede Zeile eine Beobachtung und jede Spalte eine Variable darstellt. In R wird dieses Datenformat als Dataframe bezeichnet, ein Begriff, der in den Übungen immer wieder verwendet wird. Bei diesem Datensatz ist jede Beobachtung ein einzelner Flug.\nUm die Namen der Variablen anzuzeigen, geben Sie den Befehl\n\nnames(nycflights)\n\nDies gibt die Namen der Variablen in diesem Datenrahmen zurück. Das Codebuch (Beschreibung der Variablen) kann über die Hilfedatei abgerufen werden:\n\n?nycflights\n\nEine der Variablen bezieht sich auf die Fluggesellschaft des Fluges, die nach folgendem System kodiert wird.\n\ncarrier (Fluggesellschaft): Zweibuchstabiges Kürzel der Fluggesellschaft.\n\n9E: Endeavor Air Inc.\nAA: American Airlines Inc.\nAS: Alaska Airlines Inc.\nB6: JetBlue Airways\nDL: Delta Air Lines Inc.\nEV: ExpressJet Fluggesellschaften Inc.\nF9: Frontier Airlines Inc.\nFL: AirTran Airways Corporation\nHA: Hawaiian Airlines Inc.\nMQ: Envoy Air\nOO: SkyWest Airlines Inc.\nUA: United Air Lines Inc.\nUS: US Airways Inc.\nVX: Virgin America\nWN: Southwest Airlines Co.\nYV: Mesa Airlines Inc.\n\n\nDenken Sie daran, dass Sie die Funktion glipmse() nutzen können, um einen Überblick über die Daten zu erhalten und somit deren Inhalt besser zu verstehen.\n\nglimpse(nycflights)\n\nDer Datensatz nycflights ist eine riesige Fundgrube an Informationen. Lassen Sie uns über einige Fragen nachdenken, die wir mit diesen Daten beantworten wollen:\n\nWie verspätet waren die Flüge nach Los Angeles?\nWie unterscheiden sich die Abflugverspätungen je nach Monat?\nWelcher der drei großen Flughäfen in New York hat den besten Prozentsatz an pünktlichen Abflügen?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#analyse",
    "href": "30-lab-02-intro-to-data.html#analyse",
    "title": "11  Lab 02: Pünktlichkeit von Flügen",
    "section": "11.2 Analyse",
    "text": "11.2 Analyse\n\n11.2.1 Bericht\nUm Ihre Analyse in einem reproduzierbaren Bericht festzuhalten, können Sie die allgemeine Vorlage für Berichte aus dem Paket openintro anpassen. Sehen Sie sich das Video oben an, um zu erfahren, wie das geht.\n\n\n11.2.2 Abflugverspätungen\nBeginnen wir damit, die Verteilung der Abflugverspätungen aller Flüge mit einem Histogramm zu untersuchen.\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram()\n\nMit dieser Funktion wird die Variable dep_delay aus dem Dataframe nycflights auf der \\(x\\)-Achse dargestellt. Sie definiert auch ein geom (kurz für geometrisches Objekt), das die Art der Darstellung beschreibt, die Sie erzeugen werden.\nHistogramme eignen sich im Allgemeinen sehr gut, um die Form der Verteilung einer einzelnen numerischen Variablen zu sehen, aber diese Form kann sich ändern, je nachdem, wie die Daten auf die verschiedenen Bins aufgeteilt sind. Sie können die zu verwendende Bin-Breite einfach festlegen:\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)\n\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 150)\n\n\n\nSchauen Sie sich diese drei Histogramme genau an. Wie lassen sie sich vergleichen? Sind in einem Histogramm Merkmale zu erkennen, die in einem anderen verdeckt sind?\n\n\nWenn Sie nur die Verspätungen von Flügen nach Los Angeles anzeigen möchten, müssen Sie zunächst die Daten nach Flügen mit diesem Ziel filter()n (dest == \"LAX\") und dann ein Histogramm der Abflugverspätungen nur dieser Flüge erstellen.\n\nlax_flights <- nycflights %>%\n  filter(dest == \"LAX\")\nggplot(data = lax_flights, aes(x = dep_delay)) +\n  geom_histogram()\n\nLassen Sie uns diese beiden Befehle entschlüsseln (OK, es sieht vielleicht nach vier Zeilen aus, aber die ersten beiden physischen Codezeilen sind tatsächlich Teil desselben Befehls. Es ist üblich, nach %>% einen Zeilenumbruch einzufügen, um die Lesbarkeit zu verbessern).\n\nBefehl 1: Nehmen Sie den Dataframe nycflights, filter()n Sie nach Flügen zum LAX und speichern Sie das Ergebnis als neuen Datenrahmen namens lax_flights.\n\n== bedeutet “wenn es gleich ist mit”.\nLAX steht in Anführungszeichen, da es sich um eine Zeichenkette handelt.\n\nBefehl 2: Im Grunde derselbe ggplot-Aufruf wie bei der Erstellung eines Histogramms, nur dass hier das kleinere Dataframe für Flüge mit Ziel LAX anstelle aller Flüge verwendet wird.\n\n\nLogische Operatoren: Das Filtern nach bestimmten Beobachtungen (z. B. Flüge von einem bestimmten Flughafen) ist in Dataframes oft von Interesse, wenn wir Beobachtungen mit bestimmten Merkmalsausprägungen getrennt vom Rest der Daten untersuchen möchten. Zu diesem Zweck können Sie die Filterfunktion und eine Reihe von logischen Operatoren verwenden. Die am häufigsten verwendeten logischen Operatoren für die Datenanalyse sind die folgenden:\n\n== bedeutet “gleich”\n!= bedeutet “nicht gleich”\n> oder < bedeutet “größer als” oder “kleiner als”.\n>= oder <= bedeutet “größer als oder gleich” oder “kleiner als oder gleich”.\n\n\nSie können auch numerische Zusammenfassungen für diese Flüge erhalten:\n\nlax_flights %>%\n  summarise(mean_dd   = mean(dep_delay), \n            median_dd = median(dep_delay), \n            n         = n())\n\nBeachten Sie, dass Sie in der Funktion summarise() eine Liste mit drei verschiedenen numerischen Zusammenfassungen erstellt haben, an denen Sie interessiert waren. Die Namen dieser Elemente sind benutzerdefiniert, wie mean_dd, median_dd, n, und Sie können diese Namen nach Belieben anpassen (verwenden Sie nur keine Leerzeichen in Ihren Namen). Für die Berechnung dieser zusammenfassenden Statistiken müssen Sie auch die Funktionsaufrufe kennen. Beachten Sie, dass n() den Stichprobenumfang angibt.\n\nZusammenfassende Statistiken aka statistische Lage- und Streumaße: Einige nützliche Funktionsaufrufe für zusammenfassende Statistiken für eine einzelne numerische Variable sind wie folgt:\n\nMittelwert: mean()\nMedian: median()\nStandardabweichung: sd()\nVarianz: var()\nInterquartilabstand: IQR()\nKleinster Wert: min()\nGrößter Wert: max()\n\nBeachten Sie, dass jede dieser Funktionen einen einzelnen Vektor als Argument annimmt und einen einzelnen Wert zurückgibt.\n\nSie können auch nach mehreren Kriterien filtern. Angenommen, Sie sind an Flügen nach San Francisco (SFO) im Februar interessiert:\n\nsfo_feb_flights <- nycflights %>%\n  filter(dest == \"SFO\", month == 2)\n\nBeachten Sie, dass Sie die Bedingungen durch Kommas trennen können, wenn Sie Flüge sowohl nach SFO als auch im Februar suchen. Wenn Sie entweder an Flügen nach SFO oder an Flügen im Februar interessiert sind, können Sie das | anstelle des Kommas verwenden.\n\n\nErstellen Sie ein neues Dataframe, das Flüge nach SFO im Februar enthält, und speichern Sie diesen Datenrahmen als sfo_feb_flights. Wie viele Flüge erfüllen diese Kriterien?\nBeschreiben Sie die Verteilung der Ankunftsverspätungen arr_delay dieser Flüge anhand eines Histogramms und geeigneter zusammenfassender Statistiken. Tipp: Die von Ihnen verwendete zusammenfassende Statistik sollte von der Form der Verteilung abhängen.\n\n\nEine weitere nützliche Methode ist die schnelle Berechnung von zusammenfassenden Statistiken für verschiedene Gruppen in Ihrem Dataframe. Wir können den obigen Befehl etwa mit der Funktion group_by() modifizieren, um die gleiche zusammenfassende Statistik für jeden Herkunftsflughafen zu erhalten:\n\nsfo_feb_flights %>%\n  group_by(origin) %>%\n  summarise(median_dd = median(dep_delay), iqr_dd = IQR(dep_delay), n_flights = n())\n\nHier haben wir die Daten zunächst nach Herkunft gruppiert und dann die zusammenfassenden Statistiken berechnet.\n\n\nBerechnen Sie den Median und den Interquartilsabstand für arr_delays der Flüge im Datenrahmen sfo_feb_flights, gruppiert nach Fluggesellschaft. Welche Fluggesellschaft hat Ankunftsverspätungen mit der größten Variabilität?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#abflugverspätungen-nach-monaten",
    "href": "30-lab-02-intro-to-data.html#abflugverspätungen-nach-monaten",
    "title": "11  Lab 02: Pünktlichkeit von Flügen",
    "section": "11.3 Abflugverspätungen nach Monaten",
    "text": "11.3 Abflugverspätungen nach Monaten\nIn welchem Monat würden Sie die höchste durchschnittliche Verspätung bei Abflügen von einem New Yorker Flughafen erwarten?\nLassen Sie uns überlegen, wie Sie diese Frage beantworten können:\n\nBerechnen Sie zunächst die monatlichen Durchschnittswerte für Abflugverspätungen. Mit der neuen Sprache, die Sie gerade lernen, könnten Sie\n\ngroup_by() nach Monaten, dann\ndie durchschnittlichen Abflugverspätungen zusammenfassen mit summarise().\n\nDann könnten Sie diese durchschnittlichen Verspätungen in absteigender Reihenfolge mit arrange()anordnen\n\n\nnycflights %>%\n  group_by(month) %>%\n  summarise(mean_dd = mean(dep_delay)) %>%\n  arrange(desc(mean_dd))\n\n\n\nAngenommen, Sie mögen keine Verspätungen bei der Abreise und möchten Ihre Reise in einem Monat planen, der Ihre mögliche Verspätung bei der Abreise aus New York minimiert. Eine Möglichkeit ist, den Monat mit dem geringsten Mittelwerten der Abflugverspätung zu wählen. Eine andere Möglichkeit ist, den Monat mit dem geringsten Median der Abflugverspätung zu wählen. Was sind die Vor- und Nachteile dieser beiden Möglichkeiten?\n\n\n\n11.3.1 Pünktliche Abflugrate für NYC-Flughäfen\nAngenommen, Sie fliegen von New York City aus und möchten wissen, welcher der drei großen Flughäfen in New York City die beste Pünktlichkeitsrate bei abgehenden Flügen aufweist. Nehmen wir weiter an, dass für Sie ein Flug, der weniger als 5 Minuten Verspätung hat, grundsätzlich “pünktlich” (“on time”) ist. Sie betrachten jeden Flug, der mehr als 5 Minuten Verspätung hat, als “verspätet” (“delayed”).\nUm festzustellen, welcher Flughafen die beste Pünktlichkeitsquote hat, können Sie\n\nzunächst jeden Flug als “on time” oder “delayed” einstufen,\ndann die Flüge nach Herkunftsflughafen gruppieren,\ndann die Rate der pünktlichen Abflüge für jeden Herkunftsflughafen berechnen,\nund schließlich die Flughäfen in absteigender Reihenfolge nach dem Prozentsatz der pünktlichen Abflüge ordnen.\n\nBeginnen wir mit der Klassifizierung der einzelnen Flüge als “on time” oder “delayed”, indem wir mit der Funktion mutate() eine neue Variable erstellen.\n\nnycflights <- nycflights %>%\n  mutate(dep_type = ifelse(dep_delay < 5, \"on time\", \"delayed\"))\n\nDas erste Argument in der Funktion mutate() ist der Name der neuen Variable, die wir erstellen wollen, in diesem Fall dep_type. Wenn dep_delay < 5 ist, klassifizieren wir den Flug als “on time”, wenn nicht, als “delayed”, d. h. wenn der Flug 5 oder mehr Minuten verspätet ist.\nBeachten Sie, dass wir auch das Dataframe nycflights mit der neuen Version dieses Dataframes überschreiben, der die neue Variable dep_type enthält.\nAlle übrigen Schritte können wir in einem einzigen Code-Chunk erledigen:\n\nnycflights %>%\n  group_by(origin) %>%\n  summarise(ot_dep_rate = sum(dep_type == \"on time\") / n()) %>%\n  arrange(desc(ot_dep_rate))\n\n\n\nWenn Sie einen Flughafen nur aufgrund des prozentualen Anteils der Abflüge in der Zeit auswählen würden, welchen Flughafen in NYC würden Sie dann wählen?\n\n\nSie können auch die Verteilung der pünktlichen Abflugrate auf die drei Flughäfen mithilfe eines Balkendiagramms visualisieren.\n\nggplot(data = nycflights, aes(x = origin, fill = dep_type)) +\n  geom_bar()"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#weitere-übungen",
    "href": "30-lab-02-intro-to-data.html#weitere-übungen",
    "title": "11  Lab 02: Pünktlichkeit von Flügen",
    "section": "11.4 Weitere Übungen",
    "text": "11.4 Weitere Übungen\n\n\nÄndern Sie das Dataframe so, dass es eine neue Variable enthält, die die Durchschnittsgeschwindigkeit, avg_speed, die das Flugzeug bei jedem Flug zurückgelegt hat (in mph), angibt. Tipp: Die Durchschnittsgeschwindigkeit kann als Entfernung geteilt durch die Anzahl der Flugstunden berechnet werden, und beachten Sie, dass die Flugzeit air_time in Minuten angegeben wird.\nErstellen Sie ein Streudiagramm von der Durchschnittsgeschwindigkeit avg_speed und Entfernung distance. Beschreiben Sie die Beziehung zwischen Durchschnittsgeschwindigkeit und Entfernung. Tipp: Verwenden Sie geom_point().\nBauen Sie die folgende Darstellung nach. Tipp: Das dargestellte Dataframe enthält nur Flüge von American Airlines, Delta Airlines und United Airlines, und die Punkte sind nach Fluggesellschaft carrier eingefärbt (colored). Ermitteln Sie nach dem Plotten (grob) den Grenzwert für Abflugverspätungen, bei dem Sie noch erwarten können, Ihr Ziel rechtzeitig zu erreichen."
  },
  {
    "objectID": "06-explorative-numerisch.html",
    "href": "06-explorative-numerisch.html",
    "title": "6  Exploration von numerischen Daten",
    "section": "",
    "text": "Kernpakete aus tidyverse benennen\nein Workflow (Daten einlesen, zusammenfassen, darstellen) mit tidyverse durchführen\nFunktionen des Pakets dplyr für Datentransformation anwenden\ntidyverse ist eine Sammlung von R-Paketen, die explizit für Datenanalyse entwickelt wurden (https://www.tidyverse.org/). tidyverse versucht durch gemeinsame Philosophie in Design, Grammatik und Datenstruktur die Datenanalyse zu erleichtern (https://design.tidyverse.org/). Auch wenn tidyverse auf den ersten Blick etwas fremd erscheint, es ist ein Teil von R, kein eigenes Universum. Es ist also völlig in Ordnung, R-Basisfunktionen mit Funktionen aus tidyverse zu mischen.\nDas wichtigste Einführungsbuch zu tidyverse ist sicherlich R4DS: “R for Data Science” (Wickham and Grolemund 2021), das Sie kostenlos online lesen können (https://r4ds.had.co.nz/)."
  },
  {
    "objectID": "06-explorative-numerisch.html#grundpakete",
    "href": "06-explorative-numerisch.html#grundpakete",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.1 Grundpakete",
    "text": "6.1 Grundpakete\ntidyverse enthält folgende Grundpakete, die alle installiert werden, wenn Sie install.packages('tidyverse') ausführen.\n\n\n\nPaketname\nKurzbeschreibung\n\n\n\n\nggplot2\nVisualisierung\n\n\ndplyr\nDatentransformation\n\n\ntidyr\nDatenbereinigung\n\n\nreadr\nDaten einlesen\n\n\npurrr\nFunktionale Programmierung (Funktionen auf Objekte anwenden)\n\n\ntibble\nErweiterung von data.frame\n\n\nstringr\nFunktionen für Strings, d. h. Textvariablen\n\n\nforcats\nFunktionen für factor\n\n\n\nJedes dieser Pakete hat ein Cheat Sheet, eine übersichtliche Zusammenstellung der Funktionen des Pakets. Sie bekommen die Cheet Sheats über die tidyverse-Seite (https://www.tidyverse.org/packages/), indem Sie auf das jeweilige Paket klicken und zum Abschnitt ‘Cheatsheet’ scrollen."
  },
  {
    "objectID": "06-explorative-numerisch.html#der-explorative-workflow",
    "href": "06-explorative-numerisch.html#der-explorative-workflow",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.2 Der explorative Workflow",
    "text": "6.2 Der explorative Workflow\n\n6.2.1 Daten einlesen, revisited\nAls Erstes laden wir die Bibliothek tidyverse.\n\nlibrary(tidyverse)\n\nSie kennen bereits die Funktion read_delim() zum Einlesen von Textdateien. Die Funktion ist die allgemeinste Funktion der read_* Familie aus readr in tidyverse; read_csv() und read_csv2() sind jeweils für komma- und strichpunkt-getrennte Datensätze gedacht. In der Basisinstallation von R (also außerhalb von tidyverse) gibt die sehr umfangreiche Funktion read.table(), die ebenfalls zum Einlesen von Textdateien verwendet wird. Man könnte berechtigterweise fragen, warum neue Funktion (read_*) für etwas erfinden, was es schon gibt. Die Autoren von tidyverse versprechen Konsistenz und Geschwindigkeit. Ersteres war schon immer ein Problem von R, da es nicht von Computerspezialisten, sondern von Anwendern erfunden wurde. Daher ist eine Vereinheitlichung durch tidyverse mehr als willkommen. Und Geschwindigkeit ist spätestens bei größeren Datensätzen ein wichtiger Punkt.\nWir sehen uns Daten des Deutschen Wetterdienstes an, die ich am 24. Mai 2020 heruntergeladen habe (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). Der Datensatz enthält Stundenwerte für relative Luftfeuchte (%) und Lufttemperatur (°C) von drei Wetterstationen, nämlich Hof, Frankfurt und Köln-Bonn. Die Daten sind in der Datei “Drei_Stationen.csv” gespeichert.\nBeim Einlesen zeigt Ihnen read_delim() bereits, welche Spalten und welche Datentypen es erkennt, mit trim_ws = T werden Leerzeichen aus Spalten entfernt, weil die Daten sonst falsch eingelesen werden.\n\ntemp_humid <- read_delim('Daten/Drei_Stationen.csv', delim = ';', trim_ws = T)\n\nRows: 39600 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): eor\ndbl (5): STATIONS_ID, MESS_DATUM, QN_9, TT_TU, RF_TU\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEs sollte für Sie bereits Routine sein, das Ergebnis des Einlesens zu kontrollieren.\n\ntemp_humid\n\n\n\n  \n\n\n\nAlternative können Sie die Funktion glimpse() verwenden.\n\nglimpse(temp_humid)\n\nRows: 39,600\nColumns: 6\n$ STATIONS_ID <dbl> 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261…\n$ MESS_DATUM  <dbl> 2018111900, 2018111901, 2018111902, 2018111903, 2018111904…\n$ QN_9        <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ TT_TU       <dbl> -2.8, -2.5, -2.3, -2.0, -1.9, -2.1, -1.8, -1.5, -1.1, -0.6…\n$ RF_TU       <dbl> 99, 100, 100, 100, 99, 99, 99, 99, 99, 97, 95, 93, 94, 88,…\n$ eor         <chr> \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"e…\n\n\nIn diesem Datensatz sind folgende Variablen (Spalten) enthalten (s. Datensatzbeschreibung des DWDs)\n\n\n\nVariablen\nBeschreibung\n\n\n\n\nSTATIONS_ID\nStationsidentifikationsnummer\n\n\nMESS_DATUM\nZeitstempel im Format yyyymmddhh\n\n\nQN_9\nQualitätsniveau der nachfolgenden Spalten\n\n\nTT_TU\nLufttemperatur in 2 m Höhe °C\n\n\nRF_TU\nrelative Feuchte %\n\n\neor\nEnde data record"
  },
  {
    "objectID": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "href": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.3 Geschickter Umgang mit Zeit und Datum",
    "text": "6.3 Geschickter Umgang mit Zeit und Datum\nEin weiteres Paket, das zwar nicht zum Kern von tidyverse gehört, jedoch trotzdem extrem nützlich ist, heißt lubridate. Das haben wir bereits im letzten Kapitel verwendet, um aus einem Datum das Jahr zu extrahieren. lubridate hilft aber auch, Text sehr einfach in richtige Datums-Objekte zu transformieren. Wir transformieren die Spalte temp_humid$MESS_DATUM in ein richtiges Datum mit Uhrzeit. Die Funktion ymd_h() kann character in ein richtiges Datumsformat transformieren, wenn das Datum als year, month, day, hour codiert ist. Es gibt noch weitere Varianten der Codierung, die Sie bei Bedarf in der Hilfe nachschlagen sollten.\n\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid\n\n\n\n  \n\n\n\n\n6.3.1 Daten zusammenfassen\nDie drei Wetterstationen haben folgende IDs:\n\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\n\nWir zählen nach, wie viele Messpunkte es pro Station gibt. Die Funktion count() kennen Sie bereits. Sie zählt, wie häufig unterschiedlichen Merkmalsausprägungen vorkommen:\n\ntemp_humid %>% \n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDie Zeichenkombination %>% heißt Pipe-Operator (pipe) und wird als ‘und dann’ gelesen (then). Diesen Operator haben wir bereits im letzten Kapitel verwendet. Der Ausdruck temp_humid %>% count(STATIONS_ID) heißt also: nimm das Objekt temp_humid, und zähle dann die Anzahl der verschiedenen Merkmalsausprägungen zusammen. Der Pipe-Operator ist die Kernphilosophie von tidyverse und wird Ihnen überall begegnen. Der Operator stammt aus dem Paket magrittr (https://magrittr.tidyverse.org/). Seine Hauptaufgabe ist es, den Code übersichtlicher und besser lesbar zu machen (vielleicht nicht gleich zu Beginn der Lernkurve, aber schon bald 😎)."
  },
  {
    "objectID": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "href": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.4 Die Grammatik der Datenmanipulation – dplyr",
    "text": "6.4 Die Grammatik der Datenmanipulation – dplyr\nDie Funktion count() gehört zum Paket dplyr, das für Datentransformationen zuständig ist. Es ist mal wieder eine Grammatik. Dieses Paket enthält 5 Grundfunktionen (alle nach Verben benannt, damit man gleich weiß, was frau tut 😄):\n\n\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nfilter()\nWähle Daten anhand ihrer Werte\n\n\narrange()\nSortiere Zeilen\n\n\nselect()\nWähle Variablen anhand ihrer Namen\n\n\nmutate()\nErstelle neue Variablen als Funktionen vorhandener Variablen\n\n\nsummarize()\nFasse Daten zusammen\n\n\n\nWenn wir nur von einer bestimmten Station die Anzahl der Messwerte wissen möchten, dann filtern wir vorher.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nBeim Filtern läuft eine logische Abfrage. D. h. es wird bei jeden Eintrag in STATION_ID nachgesehen, ob da der Wert 2667 steht. Wenn da 2667 steht, dann gibt == ein TRUE zurück, wenn da etwas anderes steht, dann gibt == ein FALSE zurück. Und die Funktion filter() behält nur die Zeilen, bei denen == ein TRUE zurückgegeben hat.\nWeiter wichtige logische und relationale Operatoren finden Sie hier in der Hilfe zu filter(). Hier ein paar einfache Beispiele\n\n\n\n\n\n\n\nOperator\nBedeutung\n\n\n\n\n==/ > / >=\nist die linke Seite gleich / größer / größer-gleich als die rechte Seite\n\n\n!=\nist die linke Seite ungleich der rechten Seite\n\n\n\nZudem kann man bei filter() die Anfragen auch kombinieren. Wir wollen z. B. die Stationen Köln und Hof haben. | ist der logische Operator oder. Wenn man also sowohl Köln als auch Hof haben will, sagt man: finde alles, was entweder gleich Köln oder gleich Hof ist.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDas Gleiche erreicht man mit folgendem Code, indem man Frankfurt ausschließt:\n\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nAlternative kann man auch den Operator %in% verwenden. Dieser ist sehr nützlich, wenn man anhand einer einzelnen Variablen filtert, aber unterschiedliche Einträge auswählen möchte (z. B. zwei Messstationen). Es wird bei jeder Zeile in der Variablen STATIONS_ID nun überprüft, ob hier entweder 2667 oder 2261 stehen.\n\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\n\n6.4.1 Daten plotten\nWir sehen uns die Daten erst mal an, bevor wir weiter machen. Wir plotten die Temperatur. Weil es sich um Zeitreihen handelt, kommt auf die \\(x\\)-Achse die Zeit.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU, color = as_factor(STATIONS_ID))) + \n  geom_line() +\n  labs(x = 'Zeit', y = 'Temperatur (°C)', color = 'Stationen')\n\n\n\n\nBeachten Sie, dass wir die Variable zum Einfärben, nämlichSTATIONS_ID, direkt in ggplot() in eine kategoriale Variable umgewandelt haben. Sonst werden die Farben als Farbeverlauf statt drei unterschiedliche Farben, dargestellt.\nDa man erwarten kann, dass sich der Temperaturverlauf innerhalb Deutschlands nicht so stark unterscheidet, überdecken sich die Zeitreihen. Das ist für die Darstellung ungünstig. Daher wäre es besser, wenn wir die Zeitreihen in getrennte Grafiken je Station plotten würden. Dafür gibt es eine neue Funktion aus dem Paket ggplot2, nämlich facet_wrap(). Sie kann eine Grafik mithilfe einer kategorialen Variablen in Teilgrafiken aufteilen.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nDa wir die Teilgrafiken untereinander darstellen möchten, setzen wir bei facet_wrap() den Parameter nrow = 3. Bei Teilgrafiken kann man auf die Färbung der Zeitreihen verzichten.\n\n\n6.4.2 Jahresdurchschnittstemperatur\nWie hoch war die Jahresdurchschnittstemperatur auf den drei Stationen? Um diese Frage zu beantworten, erstellen wir zunächst eine neue Variable mit dem Jahr der Messungen. Das kennen Sie bereits aus dem letzten Kapitel. Die Funktion year() gehört zur Bibliothek lubridate. Die Funktion mutate() erstellt die neue Spalte und hängt sie an das Ende des Dataframes.\n\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM))\n\nDa wir die Durchschnittstemperatur für jede Station und jedes Jahr separat berechnen wollen, müssen wir unseren Datensatz nach den Stationen gruppieren. Durch die Gruppierung entstehen intern Gruppen, für die Berechnungen getrennt laufen werden. An den Daten selbst ändert sich nichts.\nAls zweiten Schritt nutzen wir dann die Funktion summerise(), die verschiedene statistische Zusammenfassungen der Daten berechnen kann. In diesem Fall möchten wir mithilfe der Funktion mean() den Mittelwert berechnen. Wir nennen den neu berechneten Datensatz yearly_means.\n\nyearly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year) %>% \n  summarize(mean_T = mean(TT_TU))\n\n`summarise()` has grouped output by 'STATIONS_ID'. You can override using the\n`.groups` argument.\n\n\nWir erhalten einen Datensatz, der pro Jahr und Station einen Mittelwert der Temperatur enthält. Die Variable, die die mittlere Temperatur enthält, haben wir mean_T genannt. Sie steht in der Zeile summarize(mean_T = mean(TT_TU)) links vom Aufruf der Funktion mean(). Der Code mean(TT_TU) berechnet den Mittelwert der Variablen TT_TU, also der Temperatur.\n\nyearly_means\n\n\n\n  \n\n\n\nDie Berechnung der Jahresmittelwerte ist sehr kritisch zu sehen. Nicht alle berechneten Werte machen Sinn. Diskutieren Sie in der Hausaufgabe warum.\n\n\n6.4.3 Monatliche Durchschnittstemperatur und ihre Variabilität\nWie hoch war die monatliche Durchschnittstemperatur auf den verschiedenen Stationen und wie stark schwankte sie? Diese Frage können wir beantworten, indem wir Mittelwerte und Standardabweichungen für jeden Monat eines jeden Jahres und jede Station berechnen. Für die Berechnung erstellen wir eine weite Spalte mit dem Monat. Die Funktion month() gehört ebenfalls zur Bibliothek lubridate und extrahiert den Monat aus MESS_DATUM.\n\ntemp_humid <- temp_humid %>% \n  mutate(month = month(MESS_DATUM))\n\ntemp_humid\n\n\n\n  \n\n\n\nJetzt können wir die Mittelwerte und die Standardabweichungen mit der Funktion summarise() berechnen. Diese Funktion kann gleichzeitig verschiedene statistische Zusammenfassungen berechnen. Den Mittelwert berechnen wir erneut mit der Funktion mean() und die Standardabweichung mit der Funktion sd().\nFür die Berechnung gruppieren wir die Daten nach STATIONS_ID, year und month mit der Funktion group_by(). Die Mittelwerte sollen ja je Station, Jahr und Monat berechnet werden. Beim Gruppieren gibt man die Variablennamen ohne Anführungszeichen durch Kommas getrennt an. Man kann nach einer oder mehreren Variablen gruppieren, die Logik bleibt immer die gleiche, nämlich group_by(VARIABLE_1) fürs Gruppieren mit einer Variablen oder group_by(VARIABLE_1, VARIABLE_2, VARIABLE_3) für z. B. gruppieren nach drei Variablen.\n\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), sd_T = sd(TT_TU))\n\n`summarise()` has grouped output by 'STATIONS_ID', 'year'. You can override\nusing the `.groups` argument.\n\nmonthly_means\n\n\n\n  \n\n\n\nDie Variable, die die Standardabweichung enthält, haben wir sd_T genannt.\nDas Dataframe monthly_means ist ein gruppiertes tibble. Das ist für die meisten Anwendungen nicht von Belang. Insbesondere ändert es nicht die Daten selbst, sondern nur die interne Organisation des tibble. Manchmal stört die Gruppierung jedoch beim Rechnen mit dem Datensatz und wir lösen sie wieder auf.\n\nmonthly_means <- ungroup(monthly_means)\n\nUm die monatlichen Daten als Zeitreihen zu plotten, brauchen wir noch eine Variable mit dem dazugehörigen Datum. Die Funktion parse_date_time() kann aus character richtige Datums- und Zeitobjekte erstellen. Sie ist allgemeiner als die oben verwendete ymd_h() Funktion, da man hier das Format explizit angeben kann. In unserem Fall ist das Format ‘ym’ für Jahr und Monat.\n\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET'))\n\nmonthly_means\n\n\n\n  \n\n\n\nDer Code paste0(year, month) “klebt” die Daten in der Variablen year und month zusammen. Das ist nötig, da die Funktion parse_date_time() einen zusammenhängenden Text als Input erwartet und keine zwei getrennten Spalten. Da das Datum außer dem Jahr und dem Monat noch einen Tag braucht, hat parse_date_time() automatisch den Ersten eines jeden Monats genommen. Beim Erstellen von korrekten Zeitangaben kommt es auch auf die Zeitzone an. Wir sind in Deutschland, da gilt die mitteleuropäische Zeit (engl. central European time, CET). Die Zeitzone ist für unsere Daten zwar nicht wirklich relevant, da wir hier Monatsdaten darstellen. Ich würde sie aber trotzdem richtig setzten, da die Standardeinstellung der Funktion parse_date_time(tz = \"UTC\") lautet und für Deutschland falsch ist.\n\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Zeit', y = 'Temperatur (°C)', color = 'Messstation')\n\n\n\n\nAlternativ können wir die Mittelwerte mit den Standardabweichungen darstellen.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nOder, weil es gerade Spaß macht, als halb-transparentes Band 😎.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nEin letzter Trick. Die Überschriften für die Teilgrafiken sind ungeschickt, da man die IDs als Mensch einfach nicht zuordnen kann. Weiter oben haben wir einen benannten Vektor definiert, der die Klarnamen enthält.\n\nstation_ids\n\n       2261        1420        2667 \n      \"Hof\" \"Frankfurt\"     \"Koeln\" \n\n\nDiesen Vektor nutzen wir als Titel.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')"
  },
  {
    "objectID": "06-explorative-numerisch.html#weiterführende-literatur-und-videos",
    "href": "06-explorative-numerisch.html#weiterführende-literatur-und-videos",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.5 Weiterführende Literatur und Videos",
    "text": "6.5 Weiterführende Literatur und Videos\n\nR4DS Wickham, Çetinkaya-Rundel, and Grolemund (2023): Kapitel 5 “Data transformation”\nEine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt 😄."
  },
  {
    "objectID": "06-explorative-numerisch.html#aufgaben",
    "href": "06-explorative-numerisch.html#aufgaben",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\n6.6.1 Was bedeutet der Code?\nWas bedeuten die Parameter ymin und ymax im folgenden Code?\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T))\n\n\n\n6.6.2 Welche Mittelwerte machen Sinn?\nDiskutieren Sie kritisch, welche mittleren Jahrestemperaturen Sinn machen und interpretiert werden können. Begründen Sie.\n\n\n6.6.3 Politbarometer\nBearbeiten Sie die Aufgaben Kapitel A.3.1 und Kapitel A.4.1 aus der Aufgabensammlung."
  },
  {
    "objectID": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "href": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.7 Ihre Arbeit einreichen",
    "text": "6.7 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.5 Exploration von numerischen Daten",
    "text": "A.5 Exploration von numerischen Daten\n\nA.5.1 Umweltdaten entlang der dänischen Küste\nDie Datei “Temperatur.csv” aus (Zuur2009a?) enthält Messungen von Temperatur, Salinität und Chlorophyll a an 31 Orten entlang der dänischen Küste. Der Datensatz kann hier heruntergeladen werden. Sie bekommen ihn aber bereits über ILIAS gestellt. Die Daten stammen vom dänischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgeführt, mit einer Häufigkeit von 0–4 Mal pro Monat je nach Jahreszeit.\n\nLesen Sie den Datensatz “Temperatur.csv” (auf ILIAS) ein.\nKonvertieren Sie die Spalte Date in ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (facet_wrap()) als Zeitreihen.\nBerechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur für alle Stationen, sowie die Standardabweichungen. Tipp: innerhalb von summarize() müssen Sie n = n() schreiben, um die Anzahl der Messwerte zu erhalten.\nStellen Sie die Monatsmittel der Temperatur als Linien dar. Tipp: Um die Montasnamen darzustellen, nutzen Sie den folgenden Code scale_x_discrete(limits = as_factor(1:12), labels = month.abb). Hängen Sie ihn mit einem + an. Was macht dieser Code?\nBeschriften Sie die Grafik sinnvoll.\nFügen Sie die Standardabweichungen als Band hinzu.\n\n\n\nA.5.2 Quantile\nWir beschäftigen uns mit dem Datensatz possum im Paket openintro.\n\nLaden Sie die Bibliothek und anschließend den Datensatz.\nBerechnen Sie\n\n\nDas 1. Quartil\nDas 3. Quartil\nDen Median\n\nDer Körper- und Kopflängen.\n\nStellen Sie die Körper- und Kopflängen als Boxplots nebeneinander dar. Nutzen Sie dazu die Bibliothek patchwork.\nStellen Sie die beiden Variablen als Streudiagramm dar (Körperlängen auf die \\(x\\)-Achse).\nBerechnen Sie den linearen Korrelationskoeffizienten mit der Funktion cor()."
  },
  {
    "objectID": "07-lineare-regression.html",
    "href": "07-lineare-regression.html",
    "title": "7  Lineare Regression",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklären.\nLineare Regression mit einer und mehreren erklärenden Variablen selbst in R durchführen.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression.html#begriff-regression",
    "href": "07-lineare-regression.html#begriff-regression",
    "title": "7  Lineare Regression",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prägte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem für den Zusammenhang zwischen der durchschnittlichen Körpergröße der Eltern und der Körpergröße ihrer erwachsenen Kinder. Leider war er nicht nur einer der Väter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher größer waren und umgekehrt, Kinder von überdurchschnittlich großen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (Rückkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression.html#idee-der-regression",
    "href": "07-lineare-regression.html#idee-der-regression",
    "title": "7  Lineare Regression",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschließlich mit solchen linearen Modellen beschäftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklärenden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklärende Variable, nämlich die Durchschnittsgröße der Eltern. Die Zielvariable war die zu erwartende Größe der Kinder. Es ging also nicht darum, die exakte Größe eines bestimmten Kindes zu berechnen, sondern den Einfluss der Durchschnittsgröße der Eltern auf die zu erwartende (oder eben mittlere) Größe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die Körpergröße sein. Sie kann binär, kategorial oder eine Zählvariable sein. Auch die erklärenden Variablen können stetig, binär oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschäftigen."
  },
  {
    "objectID": "07-lineare-regression.html#lineare-regression-mit-einer-erklärenden-variablen",
    "href": "07-lineare-regression.html#lineare-regression-mit-einer-erklärenden-variablen",
    "title": "7  Lineare Regression",
    "section": "7.3 Lineare Regression mit einer erklärenden Variablen",
    "text": "7.3 Lineare Regression mit einer erklärenden Variablen\nDie Formel für die lineare Regression mit einer erklärenden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklärende Variable oder Prädiktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklärenden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKönnen wir aus der Körpermasse der Pinguine deren mittlere Flügellänge vorhersagen?\nAls Erstes müssen wir untersuchen, ob es überhaupt einen plausiblen linearen Zusammenhang zwischen Körpermassen und Flügellängen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklärende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir können für die Visualisierung gleich die Gerade hinzu plotten. Das übernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst später kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu können, nutzen wir die Funktion lm(). Das steht für engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ Prädiktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen für die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthält sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigun der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt für ein schönes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kümmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls Nächstes müssen wir überprüfen, ob die Residuen in unserem Modell irgendwelche auffälligen Muster zeigen. Das wäre ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklärende Variable nicht berücksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werde auf der \\(x\\)-Achse die vom Modell angepassten Werte, d. h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthält. Die Streuung der Residuen sieht gleich aus für den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafür, dass das Modell soweit plausibel für unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein Gütemaß für das angepasste Modell. Er zeigt, wie viel Variabilität der Zielvariablen, hier also der Flügellängen, wird vom Modell erklärt. Mit anderen Worten, wenn wir das Modell verwenden und die Information über die Körpermasse der Tiere nutzen, um wie viel sinkt dann die Variabilität unserer Vorhersagen der Flügellängen.\nDen Determinationskoeffizienten \\(R^2\\) können wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der Variabilität der Flügellängen erklärt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche Flügellänge sich ändert, wenn die Körpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche Flügellänge, wenn die Körpermasse 0 ist. Das ist keine relevante Größe, da Körpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression.html#aufgaben",
    "href": "07-lineare-regression.html#aufgaben",
    "title": "7  Lineare Regression",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Vertiefung des linearen Modells\nArbeiten Sie das Tutorial Regression modeling: 4 - Interpreting regression models durch.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorial durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie für einen Pinguin mit der Körpermasse 5000 g die zu erwartende Flügellänge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:"
  },
  {
    "objectID": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "title": "7  Lineare Regression",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html",
    "href": "07-lineare-regression-ein-pred.html",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklären.\nLineare Regression mit einer erklärenden Variablen selbst in R durchführen.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#begriff-regression",
    "href": "07-lineare-regression-ein-pred.html#begriff-regression",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prägte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem für den Zusammenhang zwischen der durchschnittlichen Körpergröße der Eltern und der Körpergröße ihrer erwachsenen Kinder. Leider war er nicht nur einer der Väter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher größer waren und umgekehrt, Kinder von überdurchschnittlich großen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (Rückkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "href": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschließlich mit solchen linearen Modellen beschäftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklärenden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklärende Variable, nämlich die Durchschnittsgröße der Eltern. Die Zielvariable war die zu erwartende Größe der Kinder. Es ging also nicht darum, die exakte Größe eines bestimmten Kindes zu berechnen, sondern den Einfluss der Durchschnittsgröße der Eltern auf die zu erwartende (oder eben mittlere) Größe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die Körpergröße sein. Sie kann binär, kategorial oder eine Zählvariable sein. Auch die erklärenden Variablen können stetig, binär oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschäftigen."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklärenden-variablen",
    "href": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklärenden-variablen",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.3 Lineare Regression mit einer numerischen erklärenden Variablen",
    "text": "7.3 Lineare Regression mit einer numerischen erklärenden Variablen\nDie Formel für die lineare Regression mit einer erklärenden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklärende Variable oder Prädiktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklärenden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKönnen wir aus der Körpermasse der Pinguine deren mittlere Flügellänge vorhersagen?\nAls Erstes müssen wir untersuchen, ob es überhaupt einen plausiblen linearen Zusammenhang zwischen Körpermassen und Flügellängen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklärende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir können für die Visualisierung gleich die Gerade hinzu plotten. Das übernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst später kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu können, nutzen wir die Funktion lm(). Das steht für engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ Prädiktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen für die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthält sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigung der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt für ein schönes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kümmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls Nächstes müssen wir überprüfen, ob die Residuen in unserem Modell irgendwelche auffälligen Muster zeigen. Das wäre ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklärende Variable nicht berücksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werden auf der \\(x\\)-Achse die vom Modell angepassten Werte, d. h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthält. Die Streuung der Residuen sieht gleich aus für den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafür, dass das Modell soweit plausibel für unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein Gütemaß für das angepasste Modell. Er zeigt, wie viel Variabilität der Zielvariablen, hier also der Flügellängen, wird vom Modell erklärt. Mit anderen Worten, wenn wir das Modell verwenden und die Information über die Körpermasse der Tiere nutzen, um wie viel sinkt dann die Variabilität unserer Vorhersagen der Flügellängen.\nDen Determinationskoeffizienten \\(R^2\\) können wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der Variabilität der Flügellängen erklärt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche Flügellänge sich ändert, wenn die Körpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche Flügellänge, wenn die Körpermasse 0 ist. Das ist keine relevante Größe, da Körpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#aufgaben",
    "href": "07-lineare-regression-ein-pred.html#aufgaben",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Vertiefung des linearen Modells\nArbeiten Sie das Tutorial Regression modeling: 4 - Interpreting regression models durch.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorial durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie für einen Pinguin mit der Körpermasse 5000 g die zu erwartende Flügellänge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:"
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "index.html#lernergebnisse-intended-learning-outcomes",
    "href": "index.html#lernergebnisse-intended-learning-outcomes",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Lernergebnisse (intended learning outcomes)",
    "text": "Lernergebnisse (intended learning outcomes)\n\nDatenanalyse\n\nDaten für statistische Analysen aufbereiten\nExplorative (beschreibende) Datenanalyse durchführen\nDaten visualisieren\nErgebnisse der Analysen reproduzierbar darstellen\n\nStatistische Methoden\n\nEinfache statistische Kenngrößen (Mittelwert, Standardabweichung etc.) berechnen\nEine Korrelation zwischen zwei Datensätzen berechnen\nHypothesentests durchführen und die Ergebnisse richtig berichten und interpretieren\nKonfidenzintervalle berechnen und interpretieren\nEin lineares Modell berechnen, die Ergebnisse darstellen und interpretieren"
  },
  {
    "objectID": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPünktlichkeit in der Vorlesung und den Übungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenüber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen 😄"
  },
  {
    "objectID": "index.html#sinn-und-unsinn-dieses-skripts",
    "href": "index.html#sinn-und-unsinn-dieses-skripts",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Sinn und Unsinn dieses Skripts",
    "text": "Sinn und Unsinn dieses Skripts\nDieses Skript ist ein lebendiges Begleitdokument des Kurses. Es wird laufend angepasst und aktualisiert.\nIch nutze verschiedenfarbige Blöcke, um wichtige Stellen hervorzuheben:\n\nInfoblock\n\n\n\nAchtung, wichtig!\n\n\n\nDefinition\n\n\n\nLernziele"
  },
  {
    "objectID": "index.html#inspiration-quellen-und-danksagung",
    "href": "index.html#inspiration-quellen-und-danksagung",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Inspiration, Quellen und Danksagung",
    "text": "Inspiration, Quellen und Danksagung\nDieses Skript baut stark auf folgenden freien Quellen auf:\n\nr4ds: Wickham, Çetinkaya-Rundel, and Grolemund (2023)\nggplot2: Wickham (2020)\nModernDive: Ismay and Kim (2021)\nIntroduction to Modern Statistics: Çetinkaya-Rundel and Hardin (2021)\n\nDen Autoren dieser Bücher gilt ein großer Dank für Ihren Beitrag zur -Community !"
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Reproduzierbarkeit",
    "text": "Reproduzierbarkeit\nDieses Skript wurde in RStudio mit Quarto geschrieben und in R version 4.3.1 (2023-06-16) gebaut. Folgende Pakete werden für die Beispiele und Übungen benötigt:\n\n\n\n\n\n\n\n\n\npackage\nversion\nsource\n\n\n\n\ndabestr\n0.3.0\nGithub (ACCLAB/dabestr@8775899f7eba743a6a32bd2fdab5f57e79401fd6)\n\n\nemojifont\n0.5.5\nCRAN (R 4.2.0)\n\n\nfontawesome\n0.3.0\nCRAN (R 4.2.1)\n\n\ngapminder\n0.3.0\nCRAN (R 4.2.2)\n\n\ninfer\n1.0.3\nCRAN (R 4.2.2)\n\n\nlubridate\n1.8.0\nCRAN (R 4.2.0)\n\n\nmoderndive\n0.5.3\nCRAN (R 4.2.0)\n\n\ntidyverse\n1.3.1\nCRAN (R 4.2.0)\n\n\n\n\nDie komplette Information zur Session lautet:\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Berlin\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       crayon_1.5.1      cli_3.4.1         knitr_1.39       \n [5] rlang_1.1.1       xfun_0.31         highr_0.9         stringi_1.7.6    \n [9] purrr_0.3.4       generics_0.1.2    assertthat_0.2.1  jsonlite_1.8.0   \n[13] glue_1.6.2        rprojroot_2.0.3   htmltools_0.5.2   fansi_1.0.3      \n[17] rmarkdown_2.14    emo_0.0.0.9000    tibble_3.2.1      evaluate_0.15    \n[21] fontawesome_0.3.0 fastmap_1.1.0     lifecycle_1.0.3   yaml_2.3.5       \n[25] stringr_1.4.0     compiler_4.3.1    sessioninfo_1.2.2 pkgconfig_2.0.3  \n[29] htmlwidgets_1.5.4 rstudioapi_0.13   digest_0.6.29     R6_2.5.1         \n[33] utf8_1.2.2        pillar_1.9.0      magrittr_2.0.3    tools_4.3.1      \n[37] lubridate_1.8.0   desc_1.4.1       \n\n\n\nDieses Skript ist lizenziert unter Creative Commons Namensnennung - Nicht-kommerziell - Weitergabe unter gleichen Bedingungen 4.0 International.\n\n\n\n\nÇetinkaya-Rundel, Mine, and Johanna Hardin. 2021. Introduction to Modern Statistics. https://openintro-ims.netlify.app/.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for Data Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "09-tests-infer.html#workflow-in-infer",
    "href": "09-tests-infer.html#workflow-in-infer",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.2 Workflow in infer",
    "text": "8.2 Workflow in infer\nDas Paket infer bietet ein einheitliches Framework für Hypothesentests (Figure 8.1). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen und ein Verb für die Visualisierung der Ergebnisse:\n\nspecify() Variablen festlegen\nhypothesize() Nullhypothese definieren\ngenerate() Daten unter der Nullhypothese generieren\ncalculate() Stichprobenverteilung (d.h. Verteilung der Teststatistik) berechnen\nvisualize() Stichprobenverteilung darstellen\n\nMit get_p_value kann man den \\(p\\)-Wert berechnen und mit shade_p_value diesen darstellen lassen.\n\n\n\nFigure 8.1: Allgemeines Vorgehen bei Hypothesentests (Quelle: https://infer.netlify.app/)."
  },
  {
    "objectID": "09-tests-infer.html#aufgaben",
    "href": "09-tests-infer.html#aufgaben",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.4 Aufgaben",
    "text": "8.4 Aufgaben\n\n8.4.1 Vertiefung des Themas Zufall und Variabilität\nArbeiten Sie das Tutorial Foundations of inference: 1 - Sampling Variability durch."
  },
  {
    "objectID": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "href": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.1 Studiendauer in Werdeschlau",
    "text": "8.1 Studiendauer in Werdeschlau\nWir beschäftigen uns mit einem fiktiven Beispiel.\nAn der (kleinen) Universität Werdeschlau möchte man wissen, ob die vor einiger Zeit eingeführte Studienordnung die Studiendauer verändert hat. Dazu werden 300 Studierende zufällig über die Dauer ihres Studiums befragt. Zusätzlich werden noch andere Daten erhoben, aber mit diesen beschäftigen wir uns in einer andern Übung.\n\n8.1.1 Simulation der Grundgesamtheit\nBei statistischer Inferenz geht es unter anderem darum, die Begriffe Zufall und Variabilität zu quantifizieren. Um diese Konzepte zu verstehen, helfen Computerexperimente. Dafür erstellen wir uns unsere eigene Grundgesamtheit aller Studierenden an der Universität Werdeschlau. Das hat den Vorteil, dass wir viele verschiedene Befragungen durchführen können, die Variabilität der Antworten analysieren und dabei immer mit den wahren Parametern der Grundgesamtheit vergleichen können.\nWir erstellen zunächst die Grundgesamtheit. Die Zeile set.seed(123) sorgt für reproduzierbare Ergebnisse.\n\nset.seed(123)\n\npop_size <- 12000\nstudent_id <- 1:pop_size\n  \nanreise <- c(runif(n = pop_size * 0.8, min = 5, max = 40),\n             runif(n = pop_size * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = pop_size, replace = TRUE)\n\nstudienordnung <- sample(c('alt', 'neu'), size = pop_size, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nstudiendauer <- rnorm(n = pop_size, mean = 3.5, sd = 0.6)\n\nWir setzen geschlecht, wohnort, studiendauer, studienordnung und anreise zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, studiendauer, studienordnung, anreise)\n\n\n\n8.1.2 Befragung simulieren\nIn der Realität werden natürlich nicht alle 12000 Studierende befragt (wer hat schon so viele Kapazitäten?), sondern eine zufällige Stichprobe erhoben, also eine Teilmenge der Grundgesamtheit.\nUm unsere Stichprobe zu erstellen, ziehen wir 300 Studierende ohne Zurücklegen aus unserer Grundgesamtheit. Das entspricht einer einmaligen Befragung von 300 zufällig ausgewählten Studierenden.\n\nset.seed(345)\n\nbefragung_size <- 300\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nWir berechnen den Mittelwert der Studiendauer, jeweils für die alte und neue Studienordnung.\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nWie groß ist die Differenz der Mittelwerte?\n\nstat_obs$dauer[1] - stat_obs$dauer[2]\n\n[1] -0.1183631\n\n\nWie verändert sich die Differenz, wenn wir zufälligerweise andere Studierende befragt hätten? Wir wählen neue Studierende aus und wiederholen die Berechnung des Mittelwerts der Studiendauer.\n\nset.seed(987)\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nFür diese Gruppe der Befragten beträgt die Differenz der Mittelwerte 0.0323477."
  },
  {
    "objectID": "09-tests-infer.html#hypothesentest-durchführen",
    "href": "09-tests-infer.html#hypothesentest-durchführen",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.3 Hypothesentest durchführen",
    "text": "8.3 Hypothesentest durchführen\n\n8.3.1 Schritt 1: Nullhypothese und Alternativhypothese festlegen\nUnsere Forschungsfrage lautet: Hat sich die Studiendauer durch die Einführung der neuen Studienordnung verändert? Daraus ergeben sich folgende Hypothesen:\n\nNullhypothese H\\(_0\\): Die Studiendauer hat sich durch die Einführung der neuen Studienordnung nicht verändert. Sie ist gleich geblieben.\nAlternativhypothese H\\(_A\\): Die Studiendauer hat sich durch die Einführung der neuen Studienordnung verändert.\n\nDie Alternativhypothese ist unsere eigentliche Forschungsfrage. Da wir nicht wissen, in welche Richtung die Änderungen erfolgt sein könnte (Verlängerung oder Verkürzung der Studiendauer), formulieren wir eine sogenannte beidseitige Alternativhypothese. Beidseitig heißt, dass Änderungen in beide Richtungen interessant sind.\nWir berechnen zunächst die tatsächlich in den Daten (der Befragung) beobachtete Differenz zwischen den Studiendauern nach der alten und der neuen Studienordnung, also unsere Teststatistik. Die Differenz wird als alt \\(-\\) neu berechnet. Die Funktion observe() im Paket infer berechnet diese Teststatistik.\n\nd_hat <- befragung %>% \n  observe(formula = studiendauer ~ studienordnung,\n          stat = \"diff in means\", \n          order = c('alt', 'neu'))\n\nd_hat\n\n\n\n  \n\n\n\n\n\n8.3.2 Schritt 2: Simulationsexperimente durchführen\nUm Daten unter der Nullhypothese, d. h. wenn die Nullhypothese gilt, zu produzieren, permutieren wir 10000 Mal die Variable studienordnung. Denn, wenn die Studiendauer nicht von der Studienordnung abhängt, dann sind diese beiden Variablen unabhängig. Das legt die Zeile hypothesize(null = \"independence\") fest. Damit wir alle dieselben Ergebnisse bekommen, setzen wir erneut set.seed().\n\nset.seed(56)\n\nnull_dist <- befragung %>%\n  specify(studiendauer ~ studienordnung) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 10000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c('alt', 'neu'))\n\n\n\n8.3.3 Schritt 3: Ergebnisse darstellen\nWir stellen die Verteilung der Teststatistiken unter der Nullhypothese als ein Histogramm dar und zeichnen zusätzlich ein, wo sich die beobachtete Teststatistik (d. h. der beobachtete Unterschied der Mittelwerte) befindet als vertikale rote Linie. Die schattierten Bereiche zeigen Teststatistiken aus den Permutationen, die so extrem oder noch extremer sind, als die beobachtete Teststatistik von 0.0323477. Da unsere Alternativhypothese lautet, dass sich die Studiendauer verändert hat, betrachten wir extreme Werte sowohl bei der Verlängerung als auch bei der Verkürzung der Studiendauer als Evidenz gegen die Nullhypothese und zugunsten der Alternativhypothese. Daher färben wird die Bereiche links und spiegelbildlich rechts der beobachteten Teststatistik ein.\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n\n\n\n8.3.4 Schritt 4: \\(p\\)-Wert berechnen und Schlussfolgerungen ziehen\nDer folgende Code berechnet den \\(p\\)-Wert. Der \\(p\\)-Wert gibt uns die Wahrscheinlichkeit an, eine Teststatistik (also die Differenz der Mittelwerte) so extrem oder noch extremer als 0.0323477 zu beobachten, wenn die Nullhypothese tatsächlich korrekt ist. In anderen Worten, wenn wir in infer Daten generieren unter der Nullhypothese (d. h. übereinstimmend mit der Nullhypothese), dann kommt eine Differenz von 0.0323477 oder noch größer und spiegelbildlich von -0.0323477 oder noch kleiner mit einer Wahrscheinlichkeit von \\(p\\) vor. Um den \\(p\\)-Wert zu berechnen, rechnen wir den Anteil der eingefärbten Bereiche aus.\n\nnull_dist %>%\n  get_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n  \n\n\n\nWir sehen also, dass Differenzen zwischen den Mittelwerten von 0.0323477 oder noch größer oder und spiegelbildlich von -0.0323477 oder noch kleiner in 61.92% der Fälle vorkommen, wenn die Nullhypothese gilt. So eine Differenz ist also nichts Besonderes. Unser Signifikanzniveau ist \\(\\alpha = 0.05\\). Da \\(p > \\alpha\\), behalten wir die Nullhypothese bei. Es gibt also keinen Unterschied in der Studiendauer zwischen der alten und der neuen Studienordnung."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#variabilität-von-schätzungen",
    "href": "10-konfidenzintervall-infer.html#variabilität-von-schätzungen",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.1 Variabilität von Schätzungen",
    "text": "9.1 Variabilität von Schätzungen\nIm der Vorlesung und im Chapter 8 haben Sie erfahren, dass Statistiken aus zufällig gezogenen Stichproben, dem Zufall unterliegen. Sie sind Zufallsvariablen. Wenn wir Parameter der Grundgesamtheit schätzen (z. B. Mittelwert oder Anteil) oder in Experimenten die Effektstärke bestimmen möchten, dann ist es eher unwahrscheinlich, dass wir den wahren Parameter ganz genau treffen. Daher ist es sinnvoll, bei einer Schätzung einen Bereich von plausiblen Werten, das sogenannte Konfidenzintervall anzugeben."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#studiendauer-in-werdeschlau",
    "href": "10-konfidenzintervall-infer.html#studiendauer-in-werdeschlau",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.2 Studiendauer in Werdeschlau",
    "text": "9.2 Studiendauer in Werdeschlau\nWir beschäftigen uns erneut mit unserem fiktiven Beispiel der Studierenden an der Universität Werdeschlau. Diesmal interessieren wir uns dafür für den Anteil der Studierenden, die auf dem Land wohnen.\n\n9.2.1 Simulation der Grundgesamtheit und einer Befragung\nWir simulieren erneut unsere Grundgesamtheit.\n\nset.seed(123)\n\npop_size <- 12000\nstudent_id <- 1:pop_size\n  \nanreise <- c(runif(n = pop_size * 0.8, min = 5, max = 40),\n             runif(n = pop_size * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = pop_size, replace = TRUE)\n\nstudienordnung <- sample(c('alt', 'neu'), size = pop_size, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nstudiendauer <- rnorm(n = pop_size, mean = 3.5, sd = 0.6)\n\nWir setzen geschlecht, wohnort, studiendauer, studienordnung und anreise zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, studiendauer, studienordnung, anreise)\n\nWie im Chapter 8, simulieren wir eine Befragung von 300 Studierenden, indem wir eine zufällige Stichprobe (ohne Zurücklegen) aus den 1200 Studierenden (Grundgesamtheit) auswählen.\n\nset.seed(345)\n\nbefragung_size <- 300\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nUnsere Forschungsfrage lautet: Wie groß ist der Anteil der Studierenden, die auf dem Land wohnen. Wir möchten aus der eben gewonnen Stichprobe, die wahren Parameter (Anteil der Studierenden, die auf dem Land wohnen in der Grundgesamtheit), den wir mit \\(p\\) bezeichnen schätzen.\nDie beste Schätzung für \\(p\\) ist der Anteil der Studierenden, die auf dem Land wohnen, den wir in der Befragung, d. h. unsere zufällige Stichprobe beobachten. Diesen Anteil nennen wir \\(\\hat{p}\\) und die R Variable p_hat.\nZunächst zählen wir einfach die Studierenden der verschiedenen Wohnorte.\n\nbefragung %>% \n  count(wohnort)\n\n\n\n  \n\n\n\nWie verändern sich diese Zahlen, wenn wir zufälligerweise andere Studierende befragt hätten? Wir wählen neue Studierende aus und wiederholen die Berechnung des Mittelwerts der Studiendauer, ähnlich wie in Chapter 8.\n\nset.seed(987)\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nbefragung %>% \n  count(wohnort)\n\n\n\n  \n\n\n\nDer Anteil der Studierenden auf dem Land lässt sich wie folgt berechnen:\n\np_hat <- befragung %>% \n  group_by(wohnort) %>% \n  summarise(prop = n()/befragung_size)\n\np_hat\n\n\n\n  \n\n\n\nEs wohnen also 44.3% auf dem Land und entsprechend 55.7% in der Stadt. Dass beide Anteile berechnet werden, soll uns hier nicht stören. Natürlich sind die beiden Anteile zusammengerechnet immer gleich 1.\nErwartungsgemäß bringt jede Wiederholung der Befragung etwas andere Ergebnisse."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#workflow-in-infer",
    "href": "10-konfidenzintervall-infer.html#workflow-in-infer",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.3 Workflow in infer",
    "text": "9.3 Workflow in infer\nDas Paket infer bietet ein einheitliches Framework sowohl für Hypothesentests als auch für die Berechnung von Konfidenzintervallen (Figure 8.1). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen und ein Verb für die Visualisierung der Ergebnisse:\n\nspecify() Variablen festlegen\nhypothesize() Nullhypothese definieren\ngenerate() Daten unter der Nullhypothese generieren\ncalculate() Stichprobenverteilung (d.h. Verteilung der Teststatistik) berechnen\nvisualize() Stichprobenverteilung darstellen\n\nFür die Berechnung der Konfidenzintervalle brauchen wir keine Hypothese (also kein hypothesize()) und keine \\(p\\)-Werte. Alle anderen Funktionen sind nach wie vor notwendig. Das Berechnen des Konfidenzintervalls übernimmt die Funktion get_confidence_interval()."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen",
    "href": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.4 Konfidenzintervalle berechnen",
    "text": "9.4 Konfidenzintervalle berechnen\n\n9.4.1 Schritt 1:\nUnsere Forschungsfrage lautet:\n\n\n9.4.2 Schritt 2: Bootstrappen\n\n\n9.4.3 Schritt 3: Ergebnisse darstellen\n\n\n9.4.4 Schritt 4: Schlussfolgerungen ziehen"
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#kleine-zusammenfassung",
    "href": "10-konfidenzintervall-infer.html#kleine-zusammenfassung",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.5 Kleine Zusammenfassung",
    "text": "9.5 Kleine Zusammenfassung\n\n\nGrundgesamtheit: alle Studierenden der Universität Werdeschlau\nzufällige Stichprobe: eine zufällig ausgesuchte Gruppe von Studierenden\nParameter der Grundgesamtheit: z.B. der wahre Anteil von Studierenden, die in der Stadt oder auf dem Land leben\nSchätzer für diesen Parameter der Grundgesamtheit: Anteil der Studierenden, die in der Stadt oder auf dem Land leben, berechnet aus der zufälligen Stichprobe. Da die Stichprobe zufällig ist, kann man davon ausgehen, dass sie repräsentativ für die Grundgesamtheit ist und der Schätzer unverzerrt (unbiased, d.h. ohne einen systematischen Fehler).\nInferenz: schließen auf die Grundgesamtheit darf man, wenn die Stichprobe zufällig erhoben wurde und repräsentativ für die Fragestellung ist.\n\n\nDie Begriffe Statistik, Schätzer, Schätzfunktion und Stichprobenfunktion werden als Synonyme verwendet. Die Statistik ist ja auch eine Funktion, da sie mit einer Formel eine Zahl aus Daten (Stichprobe) berechnet. Sie fasst die Stichprobe also zusammen."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#aufgaben",
    "href": "10-konfidenzintervall-infer.html#aufgaben",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\n9.6.1 Vertiefung des Themas Parameterschätzung und Konfidenzintervalle\nArbeiten Sie das Tutorial Foundations of inference: 4 - Parameters and confidence intervals durch."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen-mit-infer",
    "href": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen-mit-infer",
    "title": "9  Konfidenzintervalle mit Bootstrap",
    "section": "9.4 Konfidenzintervalle berechnen mit infer",
    "text": "9.4 Konfidenzintervalle berechnen mit infer\n\n9.4.1 Schritt 1: Berechnen der Statistik\nUnsere Forschungsfrage lautet: Wie groß ist der Anteil der Studierenden, die auf dem Land wohnen. Wir möchten diesen Anteil durch unsere Befragung schätzen und ein Konfidenzintervall für die Schätzung angeben.\nDie Schätzung haben wir bereits:\n\np_hat\n\n\n\n  \n\n\n\n\n\n9.4.2 Schritt 2: Bootstrappen\nIm nächsten Schritt ziehen wir aus unserer Stichprobe befragung mit Zurücklegen Bootstrap-Stichproben und berechnen für diese die Anteile der Wohnorte. Das sind unsere Bootstrap-Stichproben und die entsprechenden Statistiken. Wir können infer mitteilen, dass wir nur den Anteil der Landbewohner brauchen.\n\nset.seed(345)\n\nbootstrap_distribution <- befragung %>%\n  specify(response = wohnort, success = 'land') %>% \n  generate(reps = 10000, type = 'bootstrap') %>% \n  calculate(stat = 'prop')\n\n\n\n9.4.3 Schritt 3: Ergebnisse darstellen\nNun können wir auch das Konfidenzintervall für unsere Schätzung \\(\\hat{p}\\) berechnen:\n\npercentile_ci <- bootstrap_distribution %>% \n  get_confidence_interval(point_estimate = p_hat$prop[1],\n                          level = 0.95, type = \"percentile\")\n\npercentile_ci\n\n\n\n  \n\n\n\nDie Verteilung der Anteile der Studierenden, die auf dem Land wohnen, in den Bootstrap-Stichproben stellen wir als Histogramm dar und markieren gleich das Konfidenzintervall.\n\nvisualize(bootstrap_distribution) +\n  shade_confidence_interval(percentile_ci) +\n  geom_vline(xintercept = p_hat$prop[1], size = 3, col = 'red')\n\n\n\n\n\n\n9.4.4 Schritt 4: Schlussfolgerungen ziehen\nWir können nun unsere Forschungsfrage beantworten:\nWir schätzen den Anteil der Studierenden, die auf dem Land wohnen, auf 0.44, mit dem Konfidenzintervall von 0.39, 0.5."
  },
  {
    "objectID": "100-aufgabensammlung.html#erste-schritte",
    "href": "100-aufgabensammlung.html#erste-schritte",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.1 Erste Schritte",
    "text": "A.1 Erste Schritte\n\nA.1.1 Morphometrische Messungen an Vögeln\nIn einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider gibt die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\nFluegel\nFuss\nKopf\nGewicht\n\n\n\n\n59.0\n22.3\n31.2\n9.5\n\n\n55.0\n19.7\n30.4\n13.8\n\n\n53.5\n20.8\n30.6\n14.8\n\n\n55.0\n20.3\n30.3\n15.2\n\n\n52.5\n20.8\n30.3\n15.5\n\n\n57.5\n21.5\n30.8\n15.6\n\n\n53.0\n20.6\n32.5\n15.6\n\n\n55.0\n21.5\nNA\n15.7\n\n\n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele Vögel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFühren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.6 Umgang mit der Normalverteilung",
    "text": "A.6 Umgang mit der Normalverteilung\n\nA.6.1 Simulieren von Daten aus einer Normalverteilung\n\nSimulieren Sie 1000 Werte aus der Standardnormalverteilung. Nutzen Sie dazu die Funktion rnorm() und stellen Sie die Daten als Histogramm dar. Tipp: Wandeln Sie die Daten in ein tibble um.\nDie Funktion dnorm berechnet den Wert der Wahrscheinlichkeitsdichte \\(f(x)\\), also einen Punkt auf der Glockenkurve. Berechnen Sie diesen Wert für \\(x = 0.3\\) für die Standardnormalverteilung.\nDie Funktion dnorm kann man dazu nutzen, um die theoretische Normalverteilung über die simulierten Daten aus Aufgabe 1 zu plotten. Nutzen Sie dazu die Funktionen geom_density() und geom_function(). Diese Aufgabe machen wir gemeinsam.\nÜberprüfen Sie, dass der Bereich \\(\\pm\\) 1.96 Standardabweichungen in einer Normalverteilung 95% der Werte enthält. Zeichnen Sie den Bereich richtig ein."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "href": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.7 Mittelwert der Studiendauer in Werdeschlau",
    "text": "A.7 Mittelwert der Studiendauer in Werdeschlau\nDie Studierendenvertretung in Werdeschlau möchte wissen, wie hoch im Schnitt die Studiendauer an der Uni Werdeschlau beträgt.\nFühren Sie eine Befragung von 100 zufällig ausgewählten Studierenden durch. Schätzen Sie aus diesen Daten die Studiendauer und geben Sie ein 95%-Konfidenzintervall an. Berechnen Sie dieses Konfidenzintervall.\n\nmit Bootstrap\nmithilfe der Normalverteilung. Der Standardfehler des Mittelwerts sei 0.06 Jahre.\n\nVergleichen Sie die beiden Konfidenzintervalle."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.8 Umgang mit der \\(t\\)-Verteilung",
    "text": "A.8 Umgang mit der \\(t\\)-Verteilung\n\nFinden Sie den kritischen Wert \\(t^*_{2}\\) für das 95%-Konfidenzintervall. Nutzen Sie dazu die Funktion qt().\nPlotten Sie die dazugehörige Verteilung mit normTail() und markieren Sie den Bereich, der 95% aller Werte enthält.\nVergleichen Sie die mit dem kritischen Wert für eine \\(t\\)-Verteilung mit 18 Freiheitsgraden."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race",
    "text": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race\nBeim Cherrys Blossom Race laufen die Teilnehmer ein 10-Meilen Rennen. Wie hoch ist die mittlere Laufzeit (mit 95%-Konfidenzintervall) im Jahr 2017? Der Datensatz run17 enthält die Daten.\n\nFiltern Sie zuerst nach event == '10 Mile', da der Datensatz mehrere Rennen enthält (Hilfe lesen!).\nZiehen Sie eine Zufallsstichprobe von 100 Läufern und rechnen Sie die Laufzeit net_sec in Minuten um.\nÜberprüfen Sie die Anforderungen an die Daten. Welches Modell dürfen Sie nutzen?\nBerechnen Sie die Punktschätzung und das Konfidenzintervall."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race – mit infer",
    "text": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race – mit infer\nLösen Sie die obige Aufgabe mit dem Paket infer."
  },
  {
    "objectID": "100-aufgabensammlung.html#test-für-den-mittelwert",
    "href": "100-aufgabensammlung.html#test-für-den-mittelwert",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.11 $$-Test für den Mittelwert",
    "text": "A.11 $$-Test für den Mittelwert\nWird der typische US-Läufer mit der Zeit schneller oder langsamer? Wir betrachten diese Frage im Kontext des Cherrys Blossom Race, einem 10-Meilen-Lauf in Washington, DC, der jedes Frühjahr stattfindet. Die Durchschnittszeit aller Läufer, die den Kirschblütenlauf im Jahr 2016 beendeten, betrug 93.29 Minuten (93 Minuten und etwa 17 Sekunden). Anhand der Daten von 100 Teilnehmern des Kirschblütenlaufs 2017 möchten wir feststellen, ob die Läufer bei diesem Lauf schneller oder langsamer werden, oder ob es keine Veränderungen gibt.\nLösen Sie die Aufgabe mit infer.\n\nA.11.1 Bodenverdichtung\nSchwere landwirtschaftliche Maschinen können beim Bearbeiten des Bodens zu Bodenverdichtung führen. In einem randomisierten Design wurden zufällig Parzellen auf einem sonst homogenen Feld mit einer schweren Maschine bearbeitet (compacted). Auf allen Parzellen wurde danach die Lagerungsdichte bestimmt. Aus langjährigen Messungen ist ist der Mittelwert des unverdichteten Bodens bekannt und beträgt 1.3 [g/cm³]. Die Lagerungsdichte (auch Trockenrohdichte) ist ein Maß für Bodenstruktur und gibt das Verhältnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird häufig in [g/cm³] gemessen und kann als ein Indikator für Bodenverdichtung genutzt werden. Eine Erhöhung der Lagerungsdichte ist ein Indikator für Verdichtung. Der Datensatz ist in der Datei “bd_compaction_simple.csv” gespeichert.\n\nÜberprüfen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erhöht hat.\n\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009a. A Beginner’s Guide to R. Springer.\n\n\n———. 2009b. A Beginner’s Guide to R. Springer."
  },
  {
    "objectID": "100-aufgabensammlung.html#t-test-für-den-mittelwert",
    "href": "100-aufgabensammlung.html#t-test-für-den-mittelwert",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.11 \\(t\\)-Test für den Mittelwert",
    "text": "A.11 \\(t\\)-Test für den Mittelwert\nWird der typische US-Läufer mit der Zeit schneller oder langsamer? Wir betrachten diese Frage im Kontext des Cherrys Blossom Race, einem 10-Meilen-Lauf in Washington, DC, der jedes Frühjahr stattfindet. Die Durchschnittszeit aller Läufer, die den Kirschblütenlauf im Jahr 2016 beendeten, betrug 93.29 Minuten (93 Minuten und etwa 17 Sekunden). Anhand der Daten von 100 Teilnehmern des Kirschblütenlaufs 2017 möchten wir feststellen, ob die Läufer bei diesem Lauf schneller oder langsamer werden, oder ob es keine Veränderungen gibt.\nLösen Sie die Aufgabe mit infer.\n\nA.11.1 Bodenverdichtung\nSchwere landwirtschaftliche Maschinen können beim Bearbeiten des Bodens zu Bodenverdichtung führen. In einem randomisierten Design wurden zufällig Parzellen auf einem sonst homogenen Feld mit einer schweren Maschine bearbeitet (compacted). Auf allen Parzellen wurde danach die Lagerungsdichte bestimmt. Aus langjährigen Messungen ist der Mittelwert des unverdichteten Bodens bekannt und beträgt 1.3 [g/cm³]. Die Lagerungsdichte (auch Trockenrohdichte) ist ein Maß für Bodenstruktur und gibt das Verhältnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird häufig in [g/cm³] gemessen und kann als ein Indikator für Bodenverdichtung genutzt werden. Eine Erhöhung der Lagerungsdichte ist ein Indikator für Verdichtung. Der Datensatz ist in der Datei “bd_compaction_simple.csv” gespeichert.\n\nÜberprüfen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erhöht hat.\n\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner’s Guide to r. Springer. http://link.springer.com/book/10.1007%2F978-0-387-93837-0."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "href": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "title": "10  Lab 01: Einführung in R und RStudio",
    "section": "10.1 Die Entwicklungsumgebung RStudio",
    "text": "10.1 Die Entwicklungsumgebung RStudio\nZiel dieser Übung ist es, Sie mit R und RStudio vertraut zu machen, die Sie im Laufe des Kurses sowohl zum Erlernen der im Kurs besprochenen statistischen Konzepte als auch zur Analyse realer Daten und zum Ziehen fundierter Schlussfolgerungen verwenden werden. Der Unterschied zwischen R und RStudio ist folgender: R ist der Name der Programmiersprache selbst und RStudio ist eine praktische Schnittstelle für die Arbeit mit R. Genauer nennt man die Software RStudio eine integrierte Entwicklungsumgebung (IDE, von englisch integrated development environment).\nIm Laufe der Übungen werden Sie ermutigt, über das hinauszugehen, was die Übungen vorgeben; die Bereitschaft zum Experimentieren wird Sie zu einem/einer viel besseren Programmierer*in machen! Bevor wir jedoch so weit sind, müssen Sie einige Grundkenntnisse in R erwerben. Zuerst werden wir die grundlegenden Bausteine von R und RStudio erkunden: die Entwicklungsumgebung RStudio, das Laden von Daten und grundlegende Befehle für die Arbeit mit Daten in R.\nFahren Sie fort und starten Sie RStudio. Sie sollten ein Fenster sehen, das wie in Abbildung 10.1 aussieht.\n\n\n\nAbbildung 10.1: Die Entwicklungsumgebung RStudio\n\n\nDas Panel unten links ist der Ort, an dem R arbeitet. Dieser Bereich wird Konsole genannt. Jedes Mal, wenn Sie RStudio starten, erscheint oben in der Konsole derselbe Text, der Ihnen die Version von R angibt, die Sie gerade ausführen. Unterhalb dieser Information befindet sich die Eingabeaufforderung, die durch das Symbol > gekennzeichnet ist. Wie der Name schon sagt, ist dieser Prompt eigentlich eine Aufforderung: eine Aufforderung zu einem Befehl. Ursprünglich ging es bei der Interaktion mit R nur darum, Befehle einzugeben und die Ausgabe zu interpretieren. Diese Befehle und ihre Syntax haben sich im Laufe der Jahrzehnte (im wahrsten Sinne des Wortes) weiterentwickelt und bieten nun eine für viele Benutzer recht natürliche Möglichkeit, auf Daten zuzugreifen und statistische Berechnungen zu organisieren, zu beschreiben und aufzurufen.\nDas Feld oben rechts enthält Ihre Arbeitsumgebung (Environment) sowie eine Aufzeichnung (History) der Befehle, die Sie zuvor eingegeben haben.\nDas Feld unten rechts enthält Registerkarten zum Durchsuchen der Files (Dateien) in Ihrem Projektordner, zum Zugriff auf Help (Hilfedateien) für R-Funktionen, zum Installieren und Verwalten von Packages (R-Paketen) und für Plots (Visualisierungen). Standardmäßig werden alle von Ihnen erstellten Datenvisualisierungen direkt unter dem Code angezeigt, mit dem Sie sie erstellt haben. Wenn Sie möchten, dass Ihre Darstellungen auf der Registerkarte Plots erscheinen, müssen Sie Ihre globalen Optionen ändern.\n\n10.1.1 R-Pakete\nR ist eine Open-Source-Programmiersprache, was bedeutet, dass Benutzer Pakete beisteuern können, die uns das Leben leichter machen, und wir können sie kostenlos nutzen. Für diese Übung und viele andere in der Zukunft werden wir die folgenden Pakete verwenden:\n\nDas tidyverse “Dach”-Paket, das eine Reihe von vielen verschiedenen R-Paketen enthält: für Datenverarbeitung und Datenvisualisierung\nDas openintro R-Paket: für Daten und benutzerdefinierte Funktionen mit den OpenIntro-Ressourcen\n\nKlicken Sie in der unteren rechten Ecke auf die Registerkarte Packages. Geben Sie den Namen jedes dieser Pakete (tidyverse, openintro) in das Suchfeld ein, um zu sehen, ob sie installiert wurden. Wenn diese Pakete bei der Eingabe ihres Namens nicht angezeigt werden, installieren Sie sie, indem Sie die folgenden zwei Codezeilen kopieren und einfügen oder in die Konsole eingeben. Achten Sie darauf, dass Sie nach jeder Codezeile die Eingabetaste drücken. Achtung, bitte denken Sie an die Anführungszeichen um den Namen des R-Pakets!\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"openintro\")\n\nNachdem Sie Enter/Return gedrückt haben, beginnt ein Textstrom, der den Prozess beschreibt, den R durchläuft, um das Paket von dem Ort zu installieren, den Sie bei der Installation von R ausgewählt haben. Wenn Sie bei der Installation von R nicht aufgefordert wurden, einen Server für das Herunterladen von Paketen auszuwählen, kann RStudio Sie auffordern, einen Server auszuwählen, von dem das Paket heruntergeladen werden soll; jeder von ihnen wird funktionieren.\nSie müssen Pakete nur einmal installieren, aber Sie müssen sie jedes Mal laden, wenn Sie RStudio neu starten. Wir laden die Pakete mit der Funktion library. Kopieren Sie die folgenden zwei Zeilen und fügen Sie sie in einen neuen Chunk ein. Um die Pakete tidyverse und openintro in Ihre Arbeitsumgebung zu laden, führen Sie den Code aus.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nSie können den obigen Code ausführen, indem Sie:\n\nden Cursor auf die Zeile setzen und Strg-Enter oder Cmd-Enter drücken\nden Cursor auf die Zeile setzen und die Schaltfläche “Run” in der oberen rechten Ecke der R Markdown-Datei drücken, oder\ndurch Klicken auf den grünen Pfeil in der oberen rechten Ecke des Codeabschnitts.\n\nWir haben uns für das tidyverse-Paket entschieden, weil es aus einer Reihe von Paketen besteht, die für verschiedene Aspekte der Arbeit mit Daten erforderlich sind, vom Laden von Daten über die Verarbeitung von Daten bis hin zur Visualisierung und Analyse von Daten. Außerdem haben diese Pakete eine gemeinsame Philosophie und sind so konzipiert, dass sie zusammenarbeiten. Sie können mehr über die Pakete im tidyverse unter tidyverse.org erfahren.\n\n\n10.1.2 Erstellen eines reproduzierbaren Berichts\nWir werden R Markdown verwenden, um reproduzierbare Berichte zu erstellen. Wie und warum Sie das machen sollen, haben Sie bereits in Kapitel ?sec-erste-schritte gelernt."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "href": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "title": "10  Lab 01: Einführung in R und RStudio",
    "section": "10.2 Taufaufzeichnungen von Dr. Arbuthnot",
    "text": "10.2 Taufaufzeichnungen von Dr. Arbuthnot\nWir laden den Datensatz arbuthnot aus dem Paket openintro.\n\ndata(arbuthnot)\n\nDie einzige Codezeile in diesem Codechunk weist R an, einige Daten zu laden: die Arbuthnot-Taufzahlen für Jungen und Mädchen. Sie sollten sehen, dass die Registerkarte Environment in der oberen rechten Ecke des RStudio-Fensters nun einen Datensatz namens “Arbuthnot” mit 82 Beobachtungen für 3 Variablen auflistet. Wenn Sie mit R arbeiten, werden Sie Objekte für eine Vielzahl von Zwecken erstellen. Manchmal laden Sie die Objekte in Ihren Arbeitsbereich, indem Sie ein Paket laden, wie wir es hier getan haben, aber manchmal erstellen Sie selbst Objekte als Nebenprodukt eines Berechnungsprozesses, für eine Analyse, die Sie durchgeführt haben, oder für eine Visualisierung, die Sie erstellt haben. Wie Sie Daten aus einer Textdatei einlesen, erfahren Sie in Kapitel Kapitel 4.\nDer Arbuthnot-Datensatz geht auf die Arbeit von Dr. John Arbuthnot zurück, einem Arzt, Schriftsteller und Mathematiker aus dem 18. Jahrhundert. Er interessierte sich für das Verhältnis zwischen neugeborenen Jungen und neugeborenen Mädchen und sammelte daher die Taufeinträge für in London geborene Kinder für jedes Jahr zwischen 1629 und 1710. Auch hier können wir die Daten anzeigen, indem wir den unten stehenden Code ausführen oder den Namen des Datensatzes in die Konsole eingeben. Achten Sie auf die Schreibweise und Großschreibung! R unterscheidet Groß- und Kleinschreibung. Wenn Sie also versehentlich “Arbuthnot” eingeben, meldet R, dass das Objekt nicht gefunden werden kann.\n\narbuthnot\n\n\n\n  \n\n\n\nDer Befehl arbuthnot (also der Name des Datensatzes) zeigt die Daten für uns an. Sie können im R Markdown durch den Datensatz blättern, wenn sie unter dem Datensatz auf “Next” klicken. Alternativ können Sie den Datensatz im Datenbetrachter (im Lesemodus) ansehen. Auf der Registerkarte Environment (im oberen rechten Bereich) werden die Objekte in Ihrer Umgebung aufgelistet. Wenn Sie auf den Namen arbuthnot klicken, öffnet sich ein Data Viewer Reiter neben Ihrer R Markdown Datei, der eine alternative Anzeige des Datensatzes bietet. Diese Anzeige sollte sich ähnlich anfühlen wie die Anzeige von Daten in Excel, wo Sie durch den Datensatz blättern können, um ihn zu prüfen. Im Gegensatz zu Excel können Sie die Daten auf dieser Registerkarte jedoch nicht bearbeiten. Wenn Sie mit der Ansicht der Daten fertig sind, können Sie diese Registerkarte schließen, indem Sie auf das “x” in der oberen linken Ecke klicken.\nWenn Sie sich die Daten ansehen, sollten Sie vier Zahlenspalten und 82 Zeilen sehen. Jede Zeile steht für ein anderes Jahr, in dem Arbuthnot Daten gesammelt hat. Der erste Eintrag in jeder Zeile ist die Zeilennummer (ein Index, mit dem wir bei Bedarf auf die Daten einzelner Jahre zugreifen können), der zweite ist das Jahr, und der dritte und vierte sind die Anzahl der in diesem Jahr getauften Jungen bzw. Mädchen.\nBeachten Sie, dass die Zeilennummern in der ersten Spalte nicht zu den Daten von Arbuthnot gehören. R fügt diese Zeilennummern als Teil des Ausdrucks hinzu, damit Sie visuelle Vergleiche anstellen können. Man kann sie sich als den Index vorstellen, den man auf der linken Seite eines Tabellenblatts sieht. In der Tat ist der Vergleich der Daten mit einer Tabellenkalkulation im Allgemeinen hilfreich. R hat die Daten von Arbuthnot in einem Objekt gespeichert, das einer Tabellenkalkulation oder einer Tabelle ähnelt und das R einen Dataframe nennt.\nSie können die Dimensionen dieses Dataframes sowie die Namen der Variablen und die ersten paar Beobachtungen sehen, indem Sie den Namen des Datensatzes aufrufen oder alternative in die Funktion glimpse() einfügen, wie unten gezeigt:\n\nglimpse(arbuthnot)\n\nRows: 82\nColumns: 3\n$ year  <int> 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639…\n$ boys  <int> 5218, 4858, 4422, 4994, 5158, 5035, 5106, 4917, 4703, 5359, 5366…\n$ girls <int> 4683, 4457, 4102, 4590, 4839, 4820, 4928, 4605, 4457, 4952, 4784…\n\n\nWir können sehen, dass es 82 Beobachtungen und 3 Variablen in diesem Datensatz gibt. Die Namen der Variablen sind year, boys und girls. An dieser Stelle werden Sie vielleicht bemerken, dass viele der Befehle in R sehr wie Funktionen aus dem Mathematikunterricht aussehen; das heißt, der Aufruf von R-Befehlen bedeutet, dass man einer Funktion eine Anzahl von Eingaben (die sogenannten Argumente) gibt, die die Funktion verwendet, um eine Ausgabe zu erzeugen. Der Befehl glimpse() zum Beispiel nimmt ein einziges Argument, den Namen eines Dataframes, und erzeugt eine Anzeige des Datensatzes als Ausgabe."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#explorative-analyse",
    "href": "25-lab-01-intro-to-r.html#explorative-analyse",
    "title": "10  Lab 01: Einführung in R und RStudio",
    "section": "10.3 Explorative Analyse",
    "text": "10.3 Explorative Analyse\nBeginnen wir damit, die Daten ein wenig genauer zu untersuchen. Wir können auf die Daten in einer einzelnen Spalte eines Dataframes zugreifen, indem wir die Spalte mit einem “$” extrahieren. Der folgende Code extrahiert die Spalte boys aus dem Dataframe “Arbuthnot”.\n\narbuthnot$boys\n\n [1] 5218 4858 4422 4994 5158 5035 5106 4917 4703 5359 5366 5518 5470 5460 4793\n[16] 4107 4047 3768 3796 3363 3079 2890 3231 3220 3196 3441 3655 3668 3396 3157\n[31] 3209 3724 4748 5216 5411 6041 5114 4678 5616 6073 6506 6278 6449 6443 6073\n[46] 6113 6058 6552 6423 6568 6247 6548 6822 6909 7577 7575 7484 7575 7737 7487\n[61] 7604 7909 7662 7602 7676 6985 7263 7632 8062 8426 7911 7578 8102 8031 7765\n[76] 6113 8366 7952 8379 8239 7840 7640\n\n\nDieser Befehl zeigt nur die Anzahl der Jungen an, die jedes Jahr getauft werden. R interpretiert das “$” so, dass es sagt: “Gehe zu dem Dataframe, der vor mir kommt, und finde die Variable, die nach mir kommt.”\n\n\nWelchen Befehl würden Sie verwenden, um nur die Anzahl der getauften Mädchen zu extrahieren? Probieren Sie es in der Konsole aus!\n\n\nBeachten Sie, dass die Art und Weise, wie R diese Daten ausgibt, unterschiedlich ist. Als wir uns den kompletten Dataframes angesehen haben, sahen wir 82 Zeilen, eine in jeder Zeile der Anzeige. Diese Daten wurden aus dem Dataframe extrahiert, sodass sie nicht mehr in einer Tabelle mit anderen Variablen strukturiert sind. Stattdessen werden diese Daten direkt nacheinander angezeigt. Objekte, die auf diese Weise ausgedruckt werden, nennt man Vektoren; ähnlich wie die Vektoren, die Sie aus dem Mathematikunterricht kennen, stellen Vektoren eine Liste von Zahlen dar. R hat Zahlen in [Klammern] auf der linken Seite des Ausdrucks hinzugefügt, um die Position jedes Eintrags innerhalb des Vektors anzugeben. Zum Beispiel folgt 5218 auf [1], was bedeutet, dass 5218 der erste Eintrag im Vektor ist. Wenn “43” am Anfang einer Zeile angezeigt wird, bedeutet dies, dass die erste Zahl in dieser Zeile dem 43. Eintrag in diesem Vektor entspricht.\n\n10.3.1 Datenvisualisierung\nR verfügt über einige leistungsstarke Funktionen zur Erstellung von Grafiken. Mit dem folgenden Code können wir eine einfache Darstellung der Anzahl der getauften Mädchen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) + \n  geom_point()\n\n\n\n\nIn diesem Code verwenden wir die Funktion ggplot(), um ein Diagramm zu erstellen. Wenn Sie diesen Codeabschnitt ausführen, wird ein Diagramm unterhalb des Codeabschnitts angezeigt. Das R Markdown-Dokument zeigt die Darstellung unterhalb des Codes an, mit dem sie erzeugt wurde.\nDer obige Befehl sieht ebenfalls wie eine mathematische Funktion aus. Diesmal benötigt die Funktion jedoch mehrere Eingaben (Argumente), die durch Kommata getrennt sind.\nMit ggplot():\n\nDas erste Argument ist immer der Name des Datensatzes, den Sie zum Plotten verwenden möchten.\nAls Nächstes geben Sie die Variablen aus dem Datensatz an, die den verschiedenen ästhetischen Elementen der Darstellung, wie der \\(x\\)- und der \\(y\\)-Achse, zugeordnet werden sollen.\n\nDiese Befehle erstellen ein leeres Diagramm mit den Variablen, die Sie den \\(x\\)- und \\(y\\)-Achsen zugewiesen haben. Als Nächstes müssen Sie ggplot() mitteilen, welche Art von Visualisierung Sie der leeren Vorlage hinzufügen möchten. Sie fügen eine weitere Ebene zu ggplot() hinzu, indem Sie:\n\nein “+” am Ende der Zeile hinzufügen, um anzuzeigen, dass Sie eine Ebene hinzufügen\ndann das geometrische Objekt angeben, das zur Erstellung des Plots verwendet werden soll.\n\nDa wir ein Streudiagramm erstellen wollen, verwenden wir geom_point(). Damit wird ggplot() mitgeteilt, dass jeder Datenpunkt durch einen Punkt im Diagramm dargestellt werden soll. Wenn Sie das obige Diagramm mit einem Liniendiagramm anstelle eines Streudiagramms darstellen wollten, würden Sie geom_point() durch geom_line() ersetzen. Dies weist ggplot() an, eine Linie von jeder Beobachtung zur nächsten Beobachtung zu zeichnen (sequenziell).\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) +\n  geom_line()\n\n\n\n\nVerwenden Sie das Diagramm, um die folgende Frage zu beantworten:\n\n\nGibt es einen offensichtlichen Trend in der Zahl der getauften Mädchen im Laufe der Jahre? Wie würden Sie ihn beschreiben? Um sicherzustellen, dass Ihr Bericht umfassend ist, sollten Sie den Code, der zur Erstellung der Grafik erforderlich ist, sowie Ihre schriftliche Interpretation beifügen.\n\n\nSie fragen sich vielleicht, woher Sie die Syntax für die Funktion ggplot() kennen sollen. Zum Glück dokumentiert R alle seine Funktionen ausführlich. Um zu erfahren, was eine Funktion tut und wie man sie benutzt (z.B. die Argumente der Funktion), geben Sie einfach ein Fragezeichen gefolgt von dem Namen der Funktion, die Sie interessiert, in die Konsole ein. Geben Sie Folgendes in Ihre Konsole ein:\n\n?ggplot\n\nBeachten Sie, dass die Hilfedatei in den Vordergrund rückt und die Darstellung im unteren rechten Bereich ersetzt. Sie können zwischen den Registerkarten hin- und herschalten, indem Sie auf ihre Namen klicken.\n\n\n10.3.2 R als großer Taschenrechner\nNehmen wir nun an, wir möchten die Gesamtzahl der Taufen darstellen. Um dies zu berechnen, könnten wir R als einen großen Taschenrechner verwenden. Dazu können wir mathematische Ausdrücke wie die folgende Berechnung in die Konsole eintippen.\n\n5218 + 4683\n\n[1] 9901\n\n\nDiese Berechnung würde uns die Gesamtzahl der Taufen im Jahr 1629 liefern. Wir könnten diese Berechnung dann für jedes Jahr einmal wiederholen. Das würde wahrscheinlich eine Weile dauern, aber zum Glück gibt es einen schnelleren Weg! Wenn wir den Vektor der Taufen für Jungen zu dem der Mädchen addieren, kann R jede dieser Summen gleichzeitig berechnen.\n\narbuthnot$boys + arbuthnot$girls\n\n [1]  9901  9315  8524  9584  9997  9855 10034  9522  9160 10311 10150 10850\n[13] 10670 10370  9410  8104  7966  7163  7332  6544  5825  5612  6071  6128\n[25]  6155  6620  7004  7050  6685  6170  5990  6971  8855 10019 10292 11722\n[37]  9972  8997 10938 11633 12335 11997 12510 12563 11895 11851 11775 12399\n[49] 12626 12601 12288 12847 13355 13653 14735 14702 14730 14694 14951 14588\n[61] 14771 15211 15054 14918 15159 13632 13976 14861 15829 16052 15363 14639\n[73] 15616 15687 15448 11851 16145 15369 16066 15862 15220 14928\n\n\nWas Sie sehen, ist eine Liste von 82 Zahlen. Diese Zahlen erscheinen als Liste, weil wir mit Vektoren und nicht mit einem Dataframe arbeiten. Jede Zahl steht für die Summe der Anzahl der Jungen und Mädchen, die in diesem Jahr getauft wurden. Sie können einen Blick auf die ersten Zeilen der Spalten boys und girls werfen, um zu sehen, ob die Berechnung richtig ist.\n\n\n10.3.3 Hinzufügen einer neuen Variable zum Dataframe\nWir möchten diesen neuen Vektor der Gesamtzahl der Taufen verwenden, um einige Diagramme zu erstellen, daher möchten wir ihn als permanente Spalte in unserem Dataframe speichern. Dies können wir mit dem folgenden Code tun:\n\narbuthnot <- arbuthnot %>%\n  mutate(total = boys + girls)\n\nDieser Code besteht aus vielen neuen Teilen, die wir nun aufschlüsseln wollen. In der ersten Zeile tun wir zwei Dinge: (1) wir fügen eine neue Spalte total zu diesem aktualisierten Dataframe hinzu, und (2) wir überschreiben das vorhandenen Dataframe mit einem aktualisierten Dataframe, das die neue Spalte total enthält. Wir können diese beiden Schritte mit dem Operator piping (%>%) miteinander verknüpfen. Der Piping-Operator nimmt die Ausgabe des vorherigen Ausdrucks und leitet sie in das erste Argument des nächsten Ausdrucks ein.\nUm unsere Analogie mit mathematischen Funktionen fortzusetzen, ist x %>% f(y) gleichbedeutend mit f(x, y). Die Verbindung von arbuthnot und mutate(total = boys + girls) mit dem Pipe-Operator ist dasselbe wie die Eingabe von mutate(arbuthnot, total = boys + girls), wobei arbuthnot das erste Argument der Funktion mutate() wird.\n\nEine Anmerkung zum Piping: Beachten Sie, dass wir diese beiden Codezeilen wie folgt lesen können:\n“Nehmen Sie den Datensatz”arbuthnot” und pipen Sie ihn in die Funktion “mutate”. Verändern Sie (mutate) den arbuthnot-Datensatz, indem Sie eine neue Variable namens total erstellen, die die Summe der Variablen namens boys und girls ist. Weisen Sie dann den resultierenden Datensatz dem Objekt mit dem Namen arbuthnot zu, d.h. überschreiben Sie den alten arbuthnot-Datensatz mit dem neuen, der die neue Variable enthält.”\nDies ist gleichbedeutend mit dem Durchgehen jeder Zeile und dem Aufsummieren der Anzahl der Jungen und Mädchen für dieses Jahr und dem Aufzeichnen dieses Wertes in einer neuen Spalte mit dem Namen total.\n\n\nWo ist die neue Variable? Wenn Sie Änderungen an Variablen in Ihrem Datensatz vornehmen, rufen Sie ihn erneut durch die Eingabe des Datensatznamens. Die neue Variable wird am Ende des Datensatzes hinzugefügt.\n\nSie werden sehen, dass es jetzt eine neue Spalte namens total gibt, die an das Dataframe angeheftet wurde. Das spezielle Symbol <- führt eine Zuweisung durch, indem es die Ausgabe der Piping-Operationen nimmt und sie in einem Objekt in Ihrer Umgebung speichert. In diesem Fall haben Sie bereits ein Objekt mit dem Namen arbuthnot in Ihrer Umgebung, also aktualisiert dieser Befehl diesen Datensatz mit der neuen mutierten Spalte.\nMit dem folgenden Code können Sie ein Liniendiagramm der Gesamtzahl der Taufen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = total)) + \n  geom_line()\n\n\n\n\nIn ähnlicher Weise kann man, wenn man die Gesamtzahl der Taufen für Jungen und Mädchen im Jahr 1629 kennt, das Verhältnis zwischen der Zahl der Jungen und der Zahl der getauften Mädchen mit dem folgenden Code berechnen:\n\n5218 / 4683\n\n[1] 1.114243\n\n\nAlternativ könnten Sie dieses Verhältnis für jedes Jahr berechnen, indem Sie auf die vollständigen Spalten boys und girls einwirken und diese Berechnungen dann in einer neuen Variablen mit dem Namen boy_to_girl_ratio speichern:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_to_girl_ratio = boys / girls)\n\nSie können auch den Anteil der Neugeborenen im Jahr 1629, die Jungen sind, mit dem folgenden Code berechnen:\n\n5218 / (5218 + 4683)\n\n[1] 0.5270175\n\n\nSie können diesen Wert auch für alle Jahre gleichzeitig berechnen und ihn als neue Variable mit dem Namen boy_ratio zum Datensatz hinzufügen:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_ratio = boys / total)\n\nBeachte, dass wir nicht durch boys + girls dividieren, sondern die Variable total verwenden, die wir zuvor in unseren Berechnungen erstellt haben!\n\n\nErstellen Sie nun eine Grafik des Anteils der geborenen Jungen über die Zeit. Was sehen Sie?\n\n\n\nTipp: Wenn Sie die Pfeiltasten nach oben und unten in der Konsole benutzen, können Sie durch Ihre vorherigen Befehle blättern, Ihre sogenannte Befehlshistorie. Sie können auch auf Ihre Befehlshistorie zugreifen, indem Sie auf die Registerkarte “History” in der oberen rechten Leiste klicken. Dies kann Ihnen in Zukunft viel Tipparbeit ersparen.\n\nZusätzlich zu den einfachen mathematischen Operatoren wie Subtraktion und Division können Sie R auffordern, Vergleiche durchzuführen, z. B. größer als, >, kleiner als, <, und Gleichheit, ==. Mit dem folgenden Code können wir unter anderem eine neue Variable namens more_boys erstellen, die uns sagt, ob die Anzahl der Geburten von Jungen die der Mädchen in jedem Jahr übersteigt:\n\narbuthnot <- arbuthnot %>%\n  mutate(more_boys = boys > girls)\n\nDieser Befehl fügt dem Dataframe arbuthnot eine neue Variable hinzu, die entweder den Wert TRUE enthält, wenn es in diesem Jahr mehr Jungen als Mädchen gab, oder FALSE, wenn dies nicht der Fall war (die Antwort mag Sie überraschen). Diese Variable enthält eine andere Art von Daten als die, die wir bisher kennengelernt haben. Alle anderen Spalten im Dataframe arbuthnot haben numerische Werte (das Jahr, die Anzahl der Jungen und Mädchen). Hier haben wir R gebeten, logische Daten zu erstellen, also Daten, deren Werte entweder TRUE oder FALSE sind. Im Allgemeinen werden bei der Datenanalyse viele verschiedene Datentypen verwendet, und ein Grund für die Verwendung von R ist, dass es in der Lage ist, viele dieser Datentypen darzustellen und mit ihnen zu rechnen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#mehr-übungen",
    "href": "25-lab-01-intro-to-r.html#mehr-übungen",
    "title": "10  Lab 01: Einführung in R und RStudio",
    "section": "10.4 Mehr Übungen",
    "text": "10.4 Mehr Übungen\nAuf den vorangegangenen Seiten haben Sie einige der Anzeigen und vorläufigen Analysen von Arbuthnots Taufdaten nachgebildet. Ihre Aufgabe besteht darin, diese Schritte zu wiederholen, allerdings für die heutigen Geburtsdaten in den Vereinigten Staaten. Die Daten sind in einem Datenrahmen mit dem Namen present gespeichert.\nUm die Minimal- und Maximalwerte der Spalten zu ermitteln, können Sie die Funktionen min() und max() innerhalb eines summarize()-Aufrufs verwenden, über den Sie im Verlaufe des Kurses mehr erfahren werden.\nHier ist ein Beispiel dafür, wie man die minimale und maximale Anzahl der Geburten von Jungen in einem Jahr ermitteln kann:\n\narbuthnot %>%\n  summarize(min = min(boys),\n            max = max(boys)\n            )\n\n\n\n  \n\n\n\nBeantworten Sie die folgenden Fragen mit dem Datensatz present:\n\n\nWelche Jahre sind in diesem Datensatz enthalten? Welche Dimensionen hat das Dataframe? Wie lauten die Namen der Variablen (Spalten)?\nWie lassen sich diese Zählungen mit denen von Arbuthnot vergleichen? Sind sie von ähnlicher Größenordnung?\nErstellen Sie ein Diagramm, das den Anteil der geborenen Jungen im Laufe der Zeit darstellt. Was sehen Sie? Trifft Arbuthnots Beobachtung, dass Jungen in größerem Umfang als Mädchen geboren werden, in den Vereinigten Staaten zu? Fügen Sie die Grafik in Ihre Antwort ein. Hinweis: Sie sollten in der Lage sein, Ihren Code aus der obigen Aufgabe wiederzuverwenden, ersetzen Sie einfach den Namen des Dataframes.\nIn welchem Jahr gab es die höchste Gesamtzahl an Geburten in den Vereinigten Staaten? Tipp: Berechnen Sie zunächst die Gesamtzahlen und speichern Sie sie als neue Variable. Sortieren Sie dann Ihren Datensatz in absteigender Reihenfolge nach der Spalte total. Sie können dies interaktiv in der Datenanzeige tun, indem Sie auf die Pfeile neben den Variablennamen klicken. Um das sortierte Ergebnis in Ihren Bericht aufzunehmen, müssen Sie zwei neue Funktionen verwenden. Zuerst verwenden wir arrange(), um die Variable zu sortieren. Dann können wir die Daten mit einer anderen Funktion, desc(), in absteigender Reihenfolge anordnen. Der Beispielcode ist unten angegeben.\n\n\n\npresent %>%\n  arrange(desc(total))\n\nDiese Daten stammen aus Berichten der Centers for Disease Control. Sie können mehr über sie erfahren, indem Sie die Hilfedatei mit dem Befehl ?present aufrufen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "href": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "title": "10  Lab 01: Einführung in R und RStudio",
    "section": "10.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio",
    "text": "10.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio\nDas war eine kurze Einführung in R und RStudio, aber wir werden Ihnen im weiteren Verlauf des Kurses weitere Funktionen und ein umfassenderes Gefühl für die Sprache vermitteln.\nIn diesem Kurs werden wir die R-Pakete aus dem tidyverse verwenden. Das Buch [R For Data Science] (https://r4ds.hadley.nz/) von Wickham et al. ist eine fantastische Quelle für die Datenanalyse in R mit tidyverse. Wenn Sie nach R-Code suchen, stellen Sie sicher, dass Sie auch diese Paketnamen in Ihre Suchanfrage aufnehmen. Suchen Sie zum Beispiel nicht nach “scatterplot in R”, sondern nach “scatterplot in R with the tidyverse”.\nDiese Unterlagen können sich im Laufe des Semesters als nützlich erweisen:\n\nRMarkdown Cheatsheet\nCheatsheet zur Datentransformation\nCheatsheet zur Datenvisualisierung\n\nBeachten Sie, dass einige der Codes auf diesen Cheatsheets für diesen Kurs zu fortgeschritten sein könnten. Der Großteil davon wird jedoch im Laufe des Semesters nützlich sein."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-vorlesung",
    "href": "04-einlesen.html#die-umfrage-aus-der-vorlesung",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.8 Die Umfrage aus der Vorlesung",
    "text": "4.8 Die Umfrage aus der Vorlesung\nLesen Sie die Datei ‘Umfrage_2023_kurz.csv’ ein (sie ist auf ILIAS zu finden). Sie enthält die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage ‘Haben Sie schon mal einen Statistikkurs besucht?’\n\nWie viele Einträge enthält der Datensatz?\nWie viele Variablen enthält der Datensatz?\nSind die Variablen numerisch oder kategorial? Wurden die Variablen auch so von R eingelesen?\nErklären Sie jede Variable. Welche Information enthält sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungefähr)?"
  },
  {
    "objectID": "04-einlesen.html#lab-01",
    "href": "04-einlesen.html#lab-01",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.9 Lab 01",
    "text": "4.9 Lab 01\nBearbeiten Sie selbständig das Lab 01: Einführung in R und RStudio in Kapitel 10."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "href": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.9 Mittelwert der Laufzeiten beim Cherrys Blossom Race",
    "text": "A.9 Mittelwert der Laufzeiten beim Cherrys Blossom Race\nBeim Cherrys Blossom Race laufen die Teilnehmer ein 10-Meilen-Rennen. Wie hoch ist die mittlere Laufzeit (mit 95%-Konfidenzintervall) im Jahr 2017? Der Datensatz run17 enthält die Daten.\n\nFiltern Sie zuerst nach event == '10 Mile', da der Datensatz mehrere Rennen enthält (Hilfe lesen!).\nZiehen Sie eine Zufallsstichprobe von 100 Läufern und rechnen Sie die Laufzeit net_sec in Minuten um.\nÜberprüfen Sie die Anforderungen an die Daten. Welches Modell dürfen Sie nutzen?\nBerechnen Sie die Punktschätzung und das Konfidenzintervall."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "href": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.10 Mittelwert der Laufzeiten beim Cherrys Blossom Race – mit infer",
    "text": "A.10 Mittelwert der Laufzeiten beim Cherrys Blossom Race – mit infer\nLösen Sie die obige Aufgabe mit dem Paket infer."
  }
]