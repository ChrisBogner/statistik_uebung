[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "",
    "text": "Vorwort\nIn dieser Veranstaltung werden wir folgende Werkzeuge verwenden:\nILIAS: die Online-Lernplattform der UzK. Sie sollten alle bereits registriert sein.\nCampuswire: die Chatplattform dient der allgemeinen Kommunikation und der Selbstorganisation des Lernens. Verwenden Sie diese, um Fragen mit Ihren Kommilitonen*innen und mir zu diskutieren. Sie sollten eine Einladungsmail zu Campuswire erhalten haben.\nZoom: die Videokonferenz-Software bleibt unser Notfall-Werkzeug, falls keine Präsenz möglich ist."
  },
  {
    "objectID": "01-einfuehrung.html",
    "href": "01-einfuehrung.html",
    "title": "1  Die Übung",
    "section": "",
    "text": "Note\n\n\n\n\nDaten für Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchführen\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#lernziele-des-kurses",
    "href": "01-einfuehrung.html#lernziele-des-kurses",
    "title": "1  Der Kurs",
    "section": "Lernziele des Kurses",
    "text": "Lernziele des Kurses\n\n\n\n\n\n\nNote\n\n\n\n\nDaten für Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchführen\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "1  Die Übung",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPünktlichkeit bei Präsenz- und Zoomsitzungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenüber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen 😄"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Çetinkaya-Rundel, Mine, and Johanna Hardin. 2022. Introduction to\nModern Statistics. https://openintro-ims.netlify.app/.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A\nLanguage for Data Analysis and\nGraphics.” Journal of Computational and\nGraphical Statistics 5 (3): 299–314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive:\nStatistical Inference via Data Science.\nhttps://moderndive.com/.\n\n\nKnuth, D. E. 1984. “Literate Programming.”\nThe Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for\nData Analysis. 3rd, in progress.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data\nScience. https://r4ds.had.co.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R\nMarkdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/.\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner’s Guide to\nR. Springer."
  },
  {
    "objectID": "01-erste-schritte.html",
    "href": "01-erste-schritte.html",
    "title": "1  Erste Schritte in R",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nAttache Paket: 'kableExtra'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "01-erste-schritte.html#was-ist",
    "href": "01-erste-schritte.html#was-ist",
    "title": "1  Erste Schritte in R",
    "section": "1.1 Was ist ?",
    "text": "1.1 Was ist ?\nR ist eine Programmiersprache für Datenanalyse und statistische Modellierung. Es ist frei verfügbar (open source software) und neben Python einer der am meisten benutzten Programmiersprachen zur Datenanalyse und -visualisierung. R wurde von Ross Ihaka und Robert Gentleman 1996 veröffentlicht (Ihaka and Gentleman 1996). Es gibt für R eine Vielzahl von Zusatzpaketen, die die Funktionalität und die Einsatzmöglichkeiten enorm erweitern.\nSie können R für Ihren Computer auf der offiziellen R-Seite https://www.r-project.org/ herunterladen und installieren. Eine kurze Anleitung finden Sie auf ILIAS, zusammen mit der Liste der Pakete, die wir in diesm Kurs brachen werden. Zusätzlich können Sie sich hier ein Video zur Installation ansehen.\nAuf der offiziellen R-Seite finden Sie auch zusätzliche Pakete, und zwar unter CRAN (The Comprehensive R Archive Network). Manche Pakete sind auf den CRAN-Seiten thematische in sogen. CRAN Task Views gegliedert. Für den Umweltbereich sind folgende Paketsammlungen besonders relevant:\n\nEnvironmetrics: Analyse von Umweltdaten\nMultivariate: Multivariate Statistik\nSpatial: Analyse von räumlichen Daten\nTimeSeries: Zeitreihenanalyse\n\nZu Beginn des Kurses werden wir jedoch nicht auf Ihren lokalen Rechnern arbeiten, sondern auf den bereits eingerichteten Uni-Rechnern in den EDV-Räumen. Daher biete ich zu diesem frühen Zeitpunkt im Kurs keine Unterstützung bei der Installation von R auf Ihren Privatrechnern. Für die ganz Ungeduldigen, gibt es hier eine kurze Einleitung zur Installation."
  },
  {
    "objectID": "01-erste-schritte.html#was-ist-rstudio",
    "href": "01-erste-schritte.html#was-ist-rstudio",
    "title": "1  Erste Schritte in R",
    "section": "1.2 Was ist RStudio?",
    "text": "1.2 Was ist RStudio?\nRStudio Desktop ist eine Entwicklungsumgebung für R. Wichtig: RStudio wird erst nach R installiert und macht ohne R keinen Sinn. Sie können die open source Version kostenlos für Ihren Rechner hier herunterladen, falls Sie sich entscheiden, (später) R auf Ihrem Rechner zu installieren. Es gibt eine live Einführung in RStudio im Kurs. Zusätzlich können Sie hier ein Video dazu ansehen.\nDie Oberfläche von RStudio ist in vier Bereiche unterteilt (Figure 1.1).\n\n\n\nFigure 1.1: Aufbau von RStudio\n\n\nSie sollten auch auf Ihrem eigenen Rechner einen Ordner für die Veranstaltung anlegen und darin jeweils einen Ordner für Folien, Daten und Notebooks."
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff",
    "href": "01-erste-schritte.html#lesestoff",
    "title": "1  Erste Schritte in R",
    "section": "1.3 Lesestoff",
    "text": "1.3 Lesestoff\nKapitel 1.1 und 1.2 in Ismay and Kim (2021)."
  },
  {
    "objectID": "01-erste-schritte.html#aufgaben",
    "href": "01-erste-schritte.html#aufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.4 Aufgaben",
    "text": "1.4 Aufgaben\n\nBitte speichern Sie Ihr Skript regelmäßig ab!\n\n\n1.4.1 R als Taschenrechner\nR ist ein großer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die üblichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie später Daten in R einlesen möchten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.4.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles Mögliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verfügung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen können in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: Die linke Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erhält eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungültige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen können (fast) frei gewählt werden. Sie müssen mit einem Buchstaben beginnen und dürfen keine Sonderzeichen enthalten. Bei längeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.4.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie können im Übrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden Länge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHäufig wollen wir für unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.4.4 Objekte ansprechen\nUm das “Innenleben” der Objekte in R anzusprechen, gibt es verschieden Möglichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren möchte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir können auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen müssen in Anführungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anführungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.4.5 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat möchte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst möchte er sich einen Überblick über seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\n\nArs Mensaausgaben\n \n  \n    Wochentag \n    Ausgaben (€) \n  \n \n\n  \n    Montag \n    2,57 \n  \n  \n    Dienstag \n    2,90 \n  \n  \n    Mittwoch \n    2,73 \n  \n  \n    Donnerstag \n    3,23 \n  \n  \n    Freitag \n    3,90 \n  \n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Betrag?\nWie viel hätte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hätte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwählen!\n\nLeider hat Ar sich beim Übertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 € statt 2,90 € ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verändern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.6 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\n\nArs Mensaausgaben, cont.\n \n  \n    Wochentag \n    Amount spent (€) \n  \n \n\n  \n    Montag, 9. März \n    2,57 \n  \n  \n    Dienstag, 10. März \n    2,90 \n  \n  \n    Mittwoch, 11. März \n    2,73 \n  \n  \n    Donnerstag, 12. März \n    3,23 \n  \n  \n    Freitag, 13. März \n    3,90 \n  \n  \n    Montag, 16. März \n    NA \n  \n\n\n\n\n\nWie ändert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthält. Rufen Sie dazu die Hilfe auf, i.e. ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend.\n\n\n\n1.4.7 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nämlich um echte Datensätze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab('Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)') +\n  ylab('Lebenserwartung bei der Geburt (Jahre)') +\n  labs(title = 'Daten von Gapminder für das Jahr 2007')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e. ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgröße dargestellt?\nWie würden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "href": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "title": "1  Erste Schritte in R",
    "section": "1.6 Ihre Arbeit einreichen",
    "text": "1.6 Ihre Arbeit einreichen\n\nSpeichern Sie Ihre .Rmd Datei ab.\nLaden Sie die Datei auf ILIAS in Ihrer Übungsgruppe in der dazugehörigen Übung hoch.\nNach der Abgabe erhalten Sie die Musterlösung.\nVergleichen Sie Ihre Lösung selbstständig mit der Musterlösung.\nStellen Sie entweder in Campuswire (im #class-chat) oder in der nächsten Sitzung Fragen, falls Sie bei den Aufgaben etwas nicht verstanden haben und die Musterlösung es nicht aufklären konnte.\n\n\n\nBeachten Sie die Deadline für das Hochladen der Hausaufgaben!"
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff-1",
    "href": "01-erste-schritte.html#lesestoff-1",
    "title": "1  Erste Schritte in R",
    "section": "1.7 Lesestoff",
    "text": "1.7 Lesestoff\nr4ds, Kapitel 4 (Wickham and Grolemund 2021)\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5 (3): 299–314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "02-rmarkdown.html",
    "href": "02-rmarkdown.html",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "",
    "text": "Wichtigkeit der Reproduzierbarkeit erklären\nBegriff literate programming definieren\nAufbau einer RMarkdown-Datei erklären\nEinen einfachen ersten reproduzierbaren Bericht selbst schreiben"
  },
  {
    "objectID": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "href": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist",
    "text": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation für dieses Thema empfehle ich das Video von Prof. Roger Peng der John Hopkins Bloogmerg School of Public Health."
  },
  {
    "objectID": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "href": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.2 Literate Programming Idee von Donald Knuth",
    "text": "2.2 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugehörige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zurück. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erklären, was man den Computer machen lassen möchte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verständlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt für viele (unentdeckte und unnötige) Fehler und Frust."
  },
  {
    "objectID": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "href": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.3 Reproduzierbare Berichte mit R Markdown",
    "text": "2.3 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und ermöglicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Präsentationsfolien usw.\nEs wird Sie vielleicht überraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein “literarisch” programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell für lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code ermöglichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endgültiges Dokument umgewandelt werden. Diesen Prozess nennt man knit."
  },
  {
    "objectID": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "href": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.4 Ein neues R Notebook erstellen",
    "text": "2.4 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine grüne Plus oben links und wählen Sie R Notebook aus. Sie können es erst einmal bei untitled belassen (Figure 2.1).\n\n\n\nFigure 2.1: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enthält das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenkürzel und Tipps. Danach können Sie den Text unterhalb des Headers löschen."
  },
  {
    "objectID": "02-rmarkdown.html#header",
    "href": "02-rmarkdown.html#header",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten müssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einrückungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterführende Literatur). Wir bleiben bei einem einfachen Header ohne Einrückungen (Abbildung Figure 2.2).\nUm einen neuen R-Chunk hinzuzufügen, klicken Sie auf das kleine grüne C+ oben rechts oder verwenden Sie das Tastenkürzel Str+Alt+i.\n\n\n\nFigure 2.2: Einen neuen R Chunk hinzufügen\n\n\nText kann einfach unterhalb des Headers und außerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente für den Text finden Sie hier. R Markdown unterstützt mathematische Notation in Latex-Stil. Eine Einführung in Latex würde an dieser Stelle aber zu weit führen.\nDas R Notebook hat den Vorteil, dass man über den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie müssen also nicht knitten. Falls Sie es doch möchten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal “geknittetes” Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, müssen Sie im Header output: html_notebbok einstellen (Abbildung (fig:rmarkdown-file?))."
  },
  {
    "objectID": "02-rmarkdown.html#wichtigste-regeln-für-reproduzierbarkeit",
    "href": "02-rmarkdown.html#wichtigste-regeln-für-reproduzierbarkeit",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.6 Wichtigste Regeln für Reproduzierbarkeit",
    "text": "2.6 Wichtigste Regeln für Reproduzierbarkeit\nEin weiteres Video von Prof. Peng widmet sich den wichtigsten Regeln für Reproduzierbarkeit."
  },
  {
    "objectID": "02-rmarkdown.html#lesestoff",
    "href": "02-rmarkdown.html#lesestoff",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.7 Lesestoff",
    "text": "2.7 Lesestoff\nIntro zu Kapitel 2 (Basics), Kapitel 3.2.1 und 3.2.2 in Xie, Allaire, and Grolemund (2021)"
  },
  {
    "objectID": "02-rmarkdown.html#weiterführende-literatur",
    "href": "02-rmarkdown.html#weiterführende-literatur",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.8 Weiterführende Literatur",
    "text": "2.8 Weiterführende Literatur\nr4ds, Kapitel 27 (Wickham and Grolemund 2021)"
  },
  {
    "objectID": "02-rmarkdown.html#aufgaben",
    "href": "02-rmarkdown.html#aufgaben",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.9 Aufgaben",
    "text": "2.9 Aufgaben\n\n2.9.1 Erstes Notebook\n\nErstellen Sie ein R Notebook.\nFügen Sie Layoutelemente hinzu:\n\nÜberschrift\nUnterüberschrift\nkursiver Text\nein Exponent: R2\nein Mathematikelement: \\(x^2\\)\neine Liste\n\n\nNutzen Sie die unter Section 2.5 verlinkte Liste der Layoutelemente.\n\n\n2.9.2 Erste Schritte als Notebook\n\nEditieren Sie das R Notebook der ersten Session.\nGliedern Sie Ihr Notebook mit passenden Layoutelementen.\nFügen Sie mehr Erklärungstext zu den einzelnen Abschnitten.\n\n\n\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "01-erste-schritte.html#gemeinsame-aufgaben",
    "href": "01-erste-schritte.html#gemeinsame-aufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.4 Gemeinsame Aufgaben",
    "text": "1.4 Gemeinsame Aufgaben\n\nBitte speichern Sie Ihr Skript regelmäßig ab!\n\n\n1.4.1 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat möchte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst möchte er sich einen Überblick über seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\n\nArs Mensaausgaben\n \n  \n    Wochentag \n    Ausgaben (€) \n  \n \n\n  \n    Montag \n    2,57 \n  \n  \n    Dienstag \n    2,90 \n  \n  \n    Mittwoch \n    2,73 \n  \n  \n    Donnerstag \n    3,23 \n  \n  \n    Freitag \n    3,90 \n  \n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groß ist die Differenz zwischen dem höchsten und dem niedrigsten Betrag?\nWie viel hätte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hätte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwählen!\n\nLeider hat Ar sich beim Übertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 € statt 2,90 € ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verändern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.2 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\n\nArs Mensaausgaben, cont.\n \n  \n    Wochentag \n    Amount spent (€) \n  \n \n\n  \n    Montag, 9. März \n    2,57 \n  \n  \n    Dienstag, 10. März \n    2,90 \n  \n  \n    Mittwoch, 11. März \n    2,73 \n  \n  \n    Donnerstag, 12. März \n    3,23 \n  \n  \n    Freitag, 13. März \n    3,90 \n  \n  \n    Montag, 16. März \n    NA \n  \n\n\n\n\n\nWie ändert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthält. Rufen Sie dazu die Hilfe auf, i.e. ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend."
  },
  {
    "objectID": "01-erste-schritte.html#hausaufgaben",
    "href": "01-erste-schritte.html#hausaufgaben",
    "title": "1  Erste Schritte in R",
    "section": "1.5 Hausaufgaben",
    "text": "1.5 Hausaufgaben\n\n1.5.1 R als Taschenrechner\nR ist ein großer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die üblichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie später Daten in R einlesen möchten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.5.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles Mögliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verfügung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen können in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: Die rechte Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erhält eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungültige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen können (fast) frei gewählt werden. Sie müssen mit einem Buchstaben beginnen und dürfen keine Sonderzeichen enthalten. Bei längeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.5.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie können im Übrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden Länge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHäufig wollen wir für unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.5.4 Objekte ansprechen\nUm das “Innenleben” der Objekte in R anzusprechen, gibt es verschieden Möglichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren möchte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir können auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen müssen in Anführungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anführungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.5.5 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nämlich um echte Datensätze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = 'Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)', \n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e. ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgröße dargestellt?\nWie würden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "02-rmarkdown.html#sec-header",
    "href": "02-rmarkdown.html#sec-header",
    "title": "2  R Markdown für reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten müssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einrückungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterführende Literatur). Wir bleiben bei einem einfachen Header ohne Einrückungen (Figure 2.2).\nUm einen neuen R-Chunk hinzuzufügen, klicken Sie auf das kleine grüne C+ oben rechts oder verwenden Sie das Tastenkürzel Str+Alt+i.\n\n\n\nFigure 2.2: Einen neuen R Chunk hinzufügen\n\n\nText kann einfach unterhalb des Headers und außerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente für den Text finden Sie hier. R Markdown unterstützt mathematische Notation in Latex-Stil. Eine Einführung in Latex würde an dieser Stelle aber zu weit führen.\nDas R Notebook hat den Vorteil, dass man über den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie müssen also nicht knitten. Falls Sie es doch möchten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal “geknittetes” Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, müssen Sie im Header output: html_notebbok einstellen (Figure 2.2)."
  },
  {
    "objectID": "20-aufgabensammlung.html",
    "href": "20-aufgabensammlung.html",
    "title": "Appendix A — Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele Vögel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFühren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "03-ggplot.html",
    "href": "03-ggplot.html",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "",
    "text": "Aufbau des Aufrufs der Funktion ggplot() kennen\nfünf wichtigste Grafiktypen kennen und einsetzten"
  },
  {
    "objectID": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "href": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.1 Aufbau eines Darstellungsbefehls",
    "text": "3.1 Aufbau eines Darstellungsbefehls\nDas Paket ggplot2 ist ein sehr mächtiges Visualisierungswerkzeug. Der Name steht für “the grammar of graphics”. Das bedeutet, dass man mithilfe von verschiedenen Funktion in ggplot2 seine Grafik Schritt für Schritt aufbaut, wie einen (grammatikalisch korrekten) Satz. In aller Kürze bedeutet das:\n\nEine statistische Grafik ist eine Zuordnung (mapping) von Variablen in einem Datensatz (data) zu (ästhetischen) Attributen (aes) von geometrischen Objekten (geom).\n\nWir müssen also für die Darstellung von Daten R Folgendes mitteilen:\n\ndata: der Datensatz, der die Variablen enthält, die wir darstellen möchten.\naes: (ästhetische) Attribute für die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z.B. die x und y Koordinaten, Farbe, Form und Größe der geometrischen Objekte\ngeom: geometrische Objekte, die dargestellt werden sollen, z.B. Punkte, Linien, Boxen, Balken/Säulen etc.\n\nWir laden zunächst die nötigen Bibliotheken.\n\nlibrary(ggplot2)\nlibrary(gapminder)\n\nAnschließend filtern wir den Datensatz gapminder, um nur die Daten aus dem Jahr 2007 zu behalten. Der Code filter(year == 2007) bedeutet, dass wir nur die Zeilen aus dem Datensatz behalten wollen, in denen in der Variable year 2007 steht.\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nWir überzeugen uns davon, dass es geklappt hat 😄. Blättern Sie durch den Datensatz und überprüfen Sie die Werte in der Variablen year.\n\ngapminder2007"
  },
  {
    "objectID": "03-ggplot.html#punktdiagramm",
    "href": "03-ggplot.html#punktdiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Punktdiagramm",
    "text": "3.2 Punktdiagramm\nEin typischer Befehl zur Visualisierung würde also so aussehen:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n{width== “90%”}\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap\nauf die y-Achse die Variable lifeExp\nfärbe ein mithilfe der Variablen continent\nbestimme die Größe der Symbole mithilfe der Variablen pop\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe als auch für die Größe der Symbole, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z.B. sind die Beschriftungen der beiden Achsen so nichtssagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Kopf (US$)', y = 'Lebenserwartung (Jahre)',\n       color = 'Kontinent', size = 'Bevölkerung')\n\n{width== “90%”}"
  },
  {
    "objectID": "03-ggplot.html#weitere-geoms",
    "href": "03-ggplot.html#weitere-geoms",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.3 Weitere geoms",
    "text": "3.3 Weitere geoms\nDas geom_point() produziert ein Streudiagramm auch XY-Diagramm (scatter plot). Weiter wichtige Grafiktypen sind\n\ngeom_line(): Linien\ngeom_bar(): Balken"
  },
  {
    "objectID": "03-ggplot.html#scatter",
    "href": "03-ggplot.html#scatter",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (Kontinent)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe continent als auch für die Größe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#histogramm",
    "href": "03-ggplot.html#histogramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Histogramm",
    "text": "3.5 Histogramm\nWie ist das GDP im Jahre 2007 in Afrika und Europa verteilt? Dazu nutzen wir das Histogramm und filtern die Daten vorher entsprechend. Als Ästhetik eignet sich hier fill besser als color.\n\nafrica_europe <- gapminder2007 %>% \n  filter(continent %in% c('Africa', 'Europe'))\n\nggplot(africa_europe, mapping = aes(x = gdpPercap, fill = continent)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "03-ggplot.html#boxplot",
    "href": "03-ggplot.html#boxplot",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.6 Boxplot",
    "text": "3.6 Boxplot\nWie ist das GDP im Jahre 2007 auf verschiedenen Kontinenten verteilt? Ein Histogramm mit allen Kontinenten würde schnell sehr unübersichtlich werden. Das geht mit einem Boxplot besser.\n\nggplot(gapminder2007, mapping = aes(x = continent, y = gdpPercap)) +\n  geom_boxplot()"
  },
  {
    "objectID": "03-ggplot.html#säulendiagramm",
    "href": "03-ggplot.html#säulendiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Säulendiagramm",
    "text": "3.5 Säulendiagramm\nWie viele Einträge gibt es pro Kontinent? Das Säulendiagramm zählt für uns die Einträge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine Häufigkeitstabelle enthalten würde.\n\nggplot(data = gapminder, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "03-ggplot.html#lesestoff",
    "href": "03-ggplot.html#lesestoff",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.6 Lesestoff",
    "text": "3.6 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "03-ggplot.html#aufgaben",
    "href": "03-ggplot.html#aufgaben",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.7 Aufgaben",
    "text": "3.7 Aufgaben\n\n3.7.1 Darstellung von großen Zahlen\nWir verändern die Grafik aus Section 3.2 so, dass die Symbole nach der Größe der Einwohnerzahl skaliert werden. Dazu benutzen wir ein neues Argument in der Funktion aes(size = pop):\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\n\n\nDie Einwohnerzahlen sind sehr groß. Daher stellt R sie in der sogen. wissenschaftlichen Notation dar. Dabei steht z. B. e+08 für \\(10^8\\). Das heißt 2.5e+08 sind 250000000 Einwohner.\nBeschriften Sie die Legende für die Größe der Symbole richtig, indem Sie size = 'Einwohnerzahl' in der Funktion labs() hinzufügen.\n\n\n3.7.2 Grafiken richtig beschriften\nBis auf die Grafik in Section 3.4 fehlen bei den Grafiken oben ordentliche Achsenbeschriftungen und Titel für die Legenden. Ergänzen Sie den Code entsprechend."
  },
  {
    "objectID": "03-ggplot.html#ihre-arbeit-einreichen",
    "href": "03-ggplot.html#ihre-arbeit-einreichen",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.8 Ihre Arbeit einreichen",
    "text": "3.8 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "03-ggplot.html#streudiagramm",
    "href": "03-ggplot.html#streudiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (Kontinent)\nbestimme die Größe der Symbole mithilfe der Variablen pop (Einwohnerzahl)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl für die Farbe continent als auch für die Größe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       size = 'Einwohnerzahl',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#line",
    "href": "03-ggplot.html#line",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen für Frankreich und Deutschland heraus. Weil wir jetzt zwei Länder haben möchten, muss beim Filtern ein Vektor mit Ländernamen angegeben werden und statt == der Operator %in%. Wir werden später noch ausführlich auf diese Operatoren zurückkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "03-ggplot.html#sec-scatter",
    "href": "03-ggplot.html#sec-scatter",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms würde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()\n\n\n\n\nIn Worten könnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz gapminder2007 (data = gapminder2007) und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (x = gdpPercap) (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (y = lifeExp) (Lebenserwartung)\nfärbe ein mithilfe der Variablen continent (color = continent).\n\nStelle das Ganze als geometrisches Objekt Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch erstellt wird. Merke: color innerhalb der Funktion aes() erstellt die Legende automatisch.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichtssagend und müssen verbessert werden. Wir hängen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder für das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#sec-line",
    "href": "03-ggplot.html#sec-line",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen für Frankreich und Deutschland heraus. Weil wir jetzt zwei Länder haben möchten, muss beim Filtern ein Vektor mit Ländernamen angegeben werden und statt == der Operator %in%. Wir werden später noch ausführlich auf diese Operatoren zurückkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "20-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "href": "20-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.2 Einführung in die Darstellung von Daten",
    "text": "A.2 Einführung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen Flossenlänge flipper_length_mm auf der \\(x\\)-Achse und der Variablen Körpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFärben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung 🤓."
  },
  {
    "objectID": "03-ggplot.html#balkendiagramm",
    "href": "03-ggplot.html#balkendiagramm",
    "title": "3  Einführung in die Darstellung von Daten",
    "section": "3.5 Balkendiagramm",
    "text": "3.5 Balkendiagramm\nWie viele Länder gibt es pro Kontinent im Jahr 2007? Das Balkendiagramm zählt für uns die Einträge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine Häufigkeitstabelle enthalten würde.\n\nggplot(data = gapminder2007, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "04-einlesen.html",
    "href": "04-einlesen.html",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "",
    "text": "Daten aus Textdateien in R einlesen\nDie $-Notation\nAnsprechen eines Eintrags im tibble\nDaten als Textdateien aus R speichern"
  },
  {
    "objectID": "04-einlesen.html#lesestoff",
    "href": "04-einlesen.html#lesestoff",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.6 Lesestoff",
    "text": "4.6 Lesestoff\nKapitel 4.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "04-einlesen.html#aufgaben",
    "href": "04-einlesen.html#aufgaben",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.7 Aufgaben",
    "text": "4.7 Aufgaben"
  },
  {
    "objectID": "04-einlesen.html#ihre-arbeit-einreichen",
    "href": "04-einlesen.html#ihre-arbeit-einreichen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.9 Ihre Arbeit einreichen",
    "text": "4.9 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "05-explorative-kategorial.html",
    "href": "05-explorative-kategorial.html",
    "title": "5  Exploration von kategorialen Daten",
    "section": "",
    "text": "Den Pipe-Operator %>%nutzen\nKategoriale Variablen in Faktor umwandeln\nKategoriale Variablen darstellen\nNeue Variablen mit mutate() erstellen\nHäufigkeits- und Kontingenztabellen erstellen"
  },
  {
    "objectID": "05-explorative-kategorial.html#lesestoff",
    "href": "05-explorative-kategorial.html#lesestoff",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.2 Lesestoff",
    "text": "5.2 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "05-explorative-kategorial.html#aufgaben",
    "href": "05-explorative-kategorial.html#aufgaben",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.3 Aufgaben",
    "text": "5.3 Aufgaben\n\n5.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus Section 5.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n5.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ändern Sie die finale Grafik in Section 5.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie ändert sich die Position der Ländernamen?\n\n\n\n5.3.3 Tutorium\nBearbeiten Sie das Tutorium “Einführung in Daten: 1 - Die Sprache der Daten”. Sie können entweder die deutsche Übersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "href": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.4 Ihre Arbeit einreichen",
    "text": "5.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "href": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.1 Daten aus Textdateien in R einlesen",
    "text": "4.1 Daten aus Textdateien in R einlesen\nUm Daten aus Textdateien (z.B. aus .csv, .txt, .dat) in R zu importieren (i.e. einzulesen) werden wir die Bibliothek readr aus tidyverse benutzen. Wir laden erst einmal tidyverse.\n\nlibrary(tidyverse)\n\nWir gehen davon aus, dass die Daten im Ordner Daten gespeichert sind. Falls Ihre Daten an einem anderen Ort abgelegt sind, müssen Sie den Pfad beim Einlesen entsprechend anpassen.\nUm die Daten zu laden, gibt es in der Bibliothek readr verschiedene Funktionen, die alle mit read_ beginnen. Die allgemeinste davon ist read_delim. Darin kann man explizit einstellen, mit welchem Zeichen (z. B. Komma, Strichpunkt etc.) die einzelnen Spalten in der zu importierenden Datei getrennt sind. In der Datei, die wir einlesen, ist das Trennungszeichen ;. Das müssen Sie aber bei jeder Datei, die Sie einlesen, nachsehen.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEin kurzer Blick auf den Datensatz, den Sie aus der ersten Sitzung der Vorlesung erkennen sollten 😄. Es sind die Daten zur Mobilität in Europa aus eurostat, heruntergeladen am 06.11.2022 und vorgefiltert. Die Daten beinhalten die Anzhal der “Personenkraftwagen je 1 000 Einwohner”, online Datencode: ROAD_EQS_CARHAB.\n\ncar_numbers\n\n\n\n  \n\n\n\nDas Ergebnis des Einlesens mit read_ Funktionen ist immer ein tibble."
  },
  {
    "objectID": "04-einlesen.html#einzlene-variablen-ansprechen",
    "href": "04-einlesen.html#einzlene-variablen-ansprechen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzlene Variablen ansprechen",
    "text": "4.2 Einzlene Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen Nutzen, um die Variable anzusprechen. Z. B. könnten wir die Variable geo so ansprechen:\n\ncars$geo\n\n [1] \"Albania\"         \"Albania\"         \"Austria\"         \"Austria\"        \n [5] \"Belgium\"         \"Belgium\"         \"Bulgaria\"        \"Bulgaria\"       \n [9] \"Croatia\"         \"Croatia\"         \"Cyprus\"          \"Cyprus\"         \n[13] \"Czechia\"         \"Czechia\"         \"Denmark\"         \"Denmark\"        \n[17] \"Estonia\"         \"Estonia\"         \"Finland\"         \"Finland\"        \n[21] \"France\"          \"France\"          \"Germany\"         \"Germany\"        \n[25] \"Greece\"          \"Greece\"          \"Hungary\"         \"Hungary\"        \n[29] \"Iceland\"         \"Iceland\"         \"Ireland\"         \"Ireland\"        \n[33] \"Italy\"           \"Italy\"           \"Kosovo\"          \"Kosovo\"         \n[37] \"Latvia\"          \"Latvia\"          \"Liechtenstein\"   \"Liechtenstein\"  \n[41] \"Lithuania\"       \"Lithuania\"       \"Luxembourg\"      \"Luxembourg\"     \n[45] \"Malta\"           \"Malta\"           \"Montenegro\"      \"Montenegro\"     \n[49] \"Netherlands\"     \"Netherlands\"     \"North Macedonia\" \"North Macedonia\"\n[53] \"Norway\"          \"Norway\"          \"Poland\"          \"Poland\"         \n[57] \"Portugal\"        \"Portugal\"        \"Romania\"         \"Romania\"        \n[61] \"Serbia\"          \"Serbia\"          \"Slovakia\"        \"Slovakia\"       \n[65] \"Slovenia\"        \"Slovenia\"        \"Spain\"           \"Spain\"          \n[69] \"Sweden\"          \"Sweden\"          \"Switzerland\"     \"Switzerland\"    \n[73] \"Türkiye\"         \"Türkiye\"         \"United Kingdom\"  \"United Kingdom\" \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 Einträge (Länder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen mehrere Spalten in einem tibble",
    "text": "4.3 Ansprechen mehrere Spalten in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nämlich zwei Indizes: einen Index für die Zeile und einen Index für die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Österreich. Wir können auch ganze Spalten (Variablen) ansprechen. Dafür wird der erste Index (für Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Einträge gemeint sind. So können wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es ähnlich. Wir lassen den Index für die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurück. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "04-einlesen.html#ein-tibble-erstellen",
    "href": "04-einlesen.html#ein-tibble-erstellen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.4 Ein tibble erstellen",
    "text": "4.4 Ein tibble erstellen\nUm ein tibble zu erstellen, nutzen wir die Funktion tibble() und zählen auf, welche Variablen wir dort haben möchten.\n\ncar_numbers_short <- tibble(Land = car_numbers$geo, Zeit = car_numbers$time)\n\nIn dem Datensatz car_numbers_short haben wir jetzt die beiden Variablen geo und time aus dem Datensatz car_numbers als tibble abgespeichert."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-r-speichern",
    "href": "04-einlesen.html#daten-aus-r-speichern",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.5 Daten aus R speichern",
    "text": "4.5 Daten aus R speichern\nWir speichern dieses tibble als Textdatei. Dafür nutzen wir die Funktion write_delim(), die ebenfalls in der Bibliothek readr in tidyverse vorhanden ist. Achten Sie darauf, dass write_delim() nur tibble speichern kann. Wenn Sie einen Vektor (eine einzelne Variable) abspeichern möchten, dann wandeln Sie diesen zuerst in ein tibble um.\n\nwrite_delim(x = car_numbers_short, file = 'Daten/geo.csv', delim = ';')"
  },
  {
    "objectID": "05-explorative-kategorial.html#mobilität-in-europa",
    "href": "05-explorative-kategorial.html#mobilität-in-europa",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.1 Mobilität in Europa",
    "text": "5.1 Mobilität in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. Zunächst laden wir wie immer die nötigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n5.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen können, welche verschiedenen Merkmalsausprägungen die Variable enthält. Zur Erinnerung: Merkmalsausprägungen sind die theoretisch möglichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsächlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse für eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen Merkmalsausprägungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heißt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Übergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben könnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unübersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schön strukturiert, wird er häufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verändern oder löschen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhält man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fügt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun können wir R auch fragen, welche verschiedenen Merkmalsausprägungen (levels) diese Variable enthält:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"         \"Austria\"         \"Belgium\"         \"Bulgaria\"       \n [5] \"Croatia\"         \"Cyprus\"          \"Czechia\"         \"Denmark\"        \n [9] \"Estonia\"         \"Finland\"         \"France\"          \"Germany\"        \n[13] \"Greece\"          \"Hungary\"         \"Iceland\"         \"Ireland\"        \n[17] \"Italy\"           \"Kosovo\"          \"Latvia\"          \"Liechtenstein\"  \n[21] \"Lithuania\"       \"Luxembourg\"      \"Malta\"           \"Montenegro\"     \n[25] \"Netherlands\"     \"North Macedonia\" \"Norway\"          \"Poland\"         \n[29] \"Portugal\"        \"Romania\"         \"Serbia\"          \"Slovakia\"       \n[33] \"Slovenia\"        \"Spain\"           \"Sweden\"          \"Switzerland\"    \n[37] \"Türkiye\"         \"United Kingdom\" \n\n\nDie einzelnen Merkmalsausprägungen sind die verschiedenen Länder. Der Datensatz enthält 38 unterschiedliche Länder.\n\n\n5.1.2 Balkendiagramm mit geom_col()\nWir möchten die Daten als Balkendiagramm darstellen. Das Ziel ist eine ähnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafür müssen wir zuerst eine neue Variable erstellen, die wir zum Einfärben der Jahre nutzen können. Dazu benötigen wir eine zusätzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heißt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum Einfärben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern überschreibt (verändert) die vorhandene Variable time_year. Das ist möglich und gängige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im Kapitel ?sec-ggplot haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der Einträge in einer Variablen auszählen und diese als Balkendiagramm darstellen. Das möchten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht für columns, also Säulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nötig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmäßig ein Stapelbalkendiagramm darstellt (stacked bar plot ). Möchte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie Ländernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall überdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehängt wird. Sie heißt theme(). Der Parameter, der für die Gestaltung der \\(x\\)-Achse zuständig ist, heißt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen Länder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\nWarning: Removed 3 rows containing missing values (geom_col)."
  },
  {
    "objectID": "04-einlesen.html#eine-grafik-speichern",
    "href": "04-einlesen.html#eine-grafik-speichern",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.6 Eine Grafik speichern",
    "text": "4.6 Eine Grafik speichern"
  },
  {
    "objectID": "04-einlesen.html#einzelne-variablen-ansprechen",
    "href": "04-einlesen.html#einzelne-variablen-ansprechen",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzelne Variablen ansprechen",
    "text": "4.2 Einzelne Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen nutzen, um die Variable anzusprechen. Z. B. könnten wir die Variable geo so ansprechen:\n\ncar_numbers$geo\n\n [1] \"Albania\"         \"Albania\"         \"Austria\"         \"Austria\"        \n [5] \"Belgium\"         \"Belgium\"         \"Bulgaria\"        \"Bulgaria\"       \n [9] \"Croatia\"         \"Croatia\"         \"Cyprus\"          \"Cyprus\"         \n[13] \"Czechia\"         \"Czechia\"         \"Denmark\"         \"Denmark\"        \n[17] \"Estonia\"         \"Estonia\"         \"Finland\"         \"Finland\"        \n[21] \"France\"          \"France\"          \"Germany\"         \"Germany\"        \n[25] \"Greece\"          \"Greece\"          \"Hungary\"         \"Hungary\"        \n[29] \"Iceland\"         \"Iceland\"         \"Ireland\"         \"Ireland\"        \n[33] \"Italy\"           \"Italy\"           \"Kosovo\"          \"Kosovo\"         \n[37] \"Latvia\"          \"Latvia\"          \"Liechtenstein\"   \"Liechtenstein\"  \n[41] \"Lithuania\"       \"Lithuania\"       \"Luxembourg\"      \"Luxembourg\"     \n[45] \"Malta\"           \"Malta\"           \"Montenegro\"      \"Montenegro\"     \n[49] \"Netherlands\"     \"Netherlands\"     \"North Macedonia\" \"North Macedonia\"\n[53] \"Norway\"          \"Norway\"          \"Poland\"          \"Poland\"         \n[57] \"Portugal\"        \"Portugal\"        \"Romania\"         \"Romania\"        \n[61] \"Serbia\"          \"Serbia\"          \"Slovakia\"        \"Slovakia\"       \n[65] \"Slovenia\"        \"Slovenia\"        \"Spain\"           \"Spain\"          \n[69] \"Sweden\"          \"Sweden\"          \"Switzerland\"     \"Switzerland\"    \n[73] \"Türkiye\"         \"Türkiye\"         \"United Kingdom\"  \"United Kingdom\" \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 Einträge (Länder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "href": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.8 Die Umfrage aus der ersten Sitzung",
    "text": "4.8 Die Umfrage aus der ersten Sitzung\nLesen Sie die Datei ‘Umfrage_2022_kurz.csv’ ein. Sie enthält die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage ‘Haben Sie schon mal einen Statistikkurs besucht?’\n\n\n\n\nWie viele Einträge enthält der Datensatz?\nWie viele Variablen enthält der Datensatz?\nSind die Variablen numerisch oder kategorial?\nErklären Sie jede Variable. Welche Information enthält sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungefähr)?"
  },
  {
    "objectID": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "href": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "title": "5  Exploration von kategorialen Daten",
    "section": "5.2 Lending Club – Peer-to-Peer-Kredite",
    "text": "5.2 Lending Club – Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen über eine Plattform ermöglicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouse…\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  <fct> Verified, Not Verified, Source Verifi…\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,…\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     <fct> moving, debt_consolidation, other, de…\n$ application_type                 <fct> individual, individual, individual, i…\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87…\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      <fct> Current, Current, Current, Current, C…\n$ initial_listing_status           <fct> whole, whole, fractional, whole, whol…\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,…\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,…\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569…\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.…\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n5.2.1 Häufigkeitstabelle\nWir erstellen eine Häufigkeitstabelle der Variable homeownership. Dazu müssen wir die einzelnen Merkmalswerte auszählen lassen. Das übernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership für die Vorlesung verändert wurde. Es ist nämlich störend, wenn die Merkmalsausprägungen mit Großbuchstaben geschrieben werden. Außerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir ändern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu überschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Änderungen in einem Aufruf zu mutate() durchführen darf. Zuerst macht die Funktion tolower() aus den Großbuchstaben Kleinbuchstaben, danach änder die Funktion fct_relevel() die Reihenfolge der Merkmalsausprägungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n5.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nämlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall möchte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen Fälle, nämlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy 🤓.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die Einträge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die einträge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige ästhetische Griffe ist das jetzt das Gleiche wie in der Vorlesung 😄."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "title": "4  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble",
    "text": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nämlich zwei Indizes: einen Index für die Zeile und einen Index für die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Österreich. Wir können auch ganze Spalten (Variablen) ansprechen. Dafür wird der erste Index (für Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Einträge gemeint sind. So können wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es ähnlich. Wir lassen den Index für die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurück. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen Oberflächen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante Datensätze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Übung lernen Sie das Paket haven kennen, dass solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschäftigen uns mit dem Datensatz “Politbarometer 2021”. Die Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen für das ZDF durchgeführt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind für Lehre und Forschung frei. Sie müssen Sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter “Downloads” (rechts oben) den Datensatz “ZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MB” herunter. Dafür werden Sie sich einmalig (und kostenlos) anmelden müssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem “Daten”-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei “ZA7856_v1-0-0.dta” finden. Das ist der eigentliche Datensatz.\n\nDatensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich für die Übung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthält der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der “Tabelle 1: Variablenkorrespondenzliste Politbarometer 2021” gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren ändern. Gehen Sie durch den Code Zeile für Zeile durch und erklären Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenüber dem ursprünglichen Datensatz gesis verändert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse für Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Übung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie müssen vorher natürlich diese Bibliothek mit library() laden.\n\n\n\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir müssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der Merkmalsausprägungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmäßig so, wie diese im Datensatz erscheinen. Das ist für die Bundesländer ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den Bundesländern ausgeprägt ist. Dafür sehen wir uns die Antworten auf die Frage “Wie stark interessieren Sie sich für Politik, …”. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der Merkmalsausprägungen ist unlogisch. Das müssen wir ändern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht für keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der Merkmalsausprägungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den Bundesländern. Ist das Interesse der Bürger ähnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen Häufigkeiten heran. Was macht der nachfolgende Code. Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nächste Schritt ist es, die relativen Häufigkeiten (Anteile) für jedes Bundesland auszurechnen, um die obige Frage zu beantworten. Erklären Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurück zu unserer Frage: Ist das Interesse der Bürger in allen Bundesländern ähnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafür können Sie folgende Code-Fragmente ergänzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +\n  labs(___)\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner’s Guide to R. Springer."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html",
    "href": "30-lab-02-intro-to-data.html",
    "title": "8  Lab 02: Pünktlichkeit von Flügen",
    "section": "",
    "text": "Das ist die deutsche Übersetzung des “OpenIntro Labs for R and tidyverse” 2. Intro to data. Es ist Teil des Buches von Çetinkaya-Rundel et al., Introduction to Modern Statistics, lizenziert unter CC-BY-SA 3.0. Übersetzt mit www.DeepL.com/Translator, bearbeitet und ergänzt von C. Bogner und L. Dedeke.\nManche definieren Statistik als das Gebiet, das sich darauf konzentriert, Informationen in Wissen zu verwandeln. Der erste Schritt in diesem Prozess ist die Zusammenfassung und Beschreibung der Rohinformationen - der Daten. In dieser Übung untersuchen wir Flüge, insbesondere eine Zufallsstichprobe von Inlandsflügen, die im Jahr 2013 von den drei großen Flughäfen in New York City abgeflogen sind. Wir werden einfache grafische und numerische Zusammenfassungen der Daten zu diesen Flügen erstellen und die Verspätungszeiten untersuchen. Da es sich um einen großen Datensatz handelt, werden Sie nebenbei auch die unverzichtbaren Fertigkeiten der Datenverarbeitung und -unterteilung erlernen."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#mobilität-in-europa",
    "href": "30-lab-02-intro-to-data.html#mobilität-in-europa",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.1 Mobilität in Europa",
    "text": "6.1 Mobilität in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. Zunächst laden wir wie immer die nötigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n6.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen können, welche verschiedenen Merkmalsausprägungen die Variable enthält. Zur Erinnerung: Merkmalsausprägungen sind die theoretisch möglichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsächlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse für eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen Merkmalsausprägungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heißt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Übergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben könnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unübersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schön strukturiert, wird er häufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verändern oder löschen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhält man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fügt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun können wir R auch fragen, welche verschiedenen Merkmalsausprägungen (levels) diese Variable enthält:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"         \"Austria\"         \"Belgium\"         \"Bulgaria\"       \n [5] \"Croatia\"         \"Cyprus\"          \"Czechia\"         \"Denmark\"        \n [9] \"Estonia\"         \"Finland\"         \"France\"          \"Germany\"        \n[13] \"Greece\"          \"Hungary\"         \"Iceland\"         \"Ireland\"        \n[17] \"Italy\"           \"Kosovo\"          \"Latvia\"          \"Liechtenstein\"  \n[21] \"Lithuania\"       \"Luxembourg\"      \"Malta\"           \"Montenegro\"     \n[25] \"Netherlands\"     \"North Macedonia\" \"Norway\"          \"Poland\"         \n[29] \"Portugal\"        \"Romania\"         \"Serbia\"          \"Slovakia\"       \n[33] \"Slovenia\"        \"Spain\"           \"Sweden\"          \"Switzerland\"    \n[37] \"Türkiye\"         \"United Kingdom\" \n\n\nDie einzelnen Merkmalsausprägungen sind die verschiedenen Länder. Der Datensatz enthält 38 unterschiedliche Länder.\n\n\n6.1.2 Balkendiagramm mit geom_col()\nWir möchten die Daten als Balkendiagramm darstellen. Das Ziel ist eine ähnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafür müssen wir zuerst eine neue Variable erstellen, die wir zum Einfärben der Jahre nutzen können. Dazu benötigen wir eine zusätzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heißt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum Einfärben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern überschreibt (verändert) die vorhandene Variable time_year. Das ist möglich und gängige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im Kapitel ?sec-ggplot haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der Einträge in einer Variablen auszählen und diese als Balkendiagramm darstellen. Das möchten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht für columns, also Säulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nötig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmäßig ein Stapelbalkendiagramm darstellt (stacked bar plot ). Möchte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie Ländernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall überdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehängt wird. Sie heißt theme(). Der Parameter, der für die Gestaltung der \\(x\\)-Achse zuständig ist, heißt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen Länder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\nWarning: Removed 3 rows containing missing values (geom_col)."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "href": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.2 Lending Club – Peer-to-Peer-Kredite",
    "text": "6.2 Lending Club – Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen über eine Plattform ermöglicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouse…\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  <fct> Verified, Not Verified, Source Verifi…\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,…\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     <fct> moving, debt_consolidation, other, de…\n$ application_type                 <fct> individual, individual, individual, i…\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87…\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      <fct> Current, Current, Current, Current, C…\n$ initial_listing_status           <fct> whole, whole, fractional, whole, whol…\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,…\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,…\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569…\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.…\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n6.2.1 Häufigkeitstabelle\nWir erstellen eine Häufigkeitstabelle der Variable homeownership. Dazu müssen wir die einzelnen Merkmalswerte auszählen lassen. Das übernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership für die Vorlesung verändert wurde. Es ist nämlich störend, wenn die Merkmalsausprägungen mit Großbuchstaben geschrieben werden. Außerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir ändern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu überschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Änderungen in einem Aufruf zu mutate() durchführen darf. Zuerst macht die Funktion tolower() aus den Großbuchstaben Kleinbuchstaben, danach änder die Funktion fct_relevel() die Reihenfolge der Merkmalsausprägungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n6.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nämlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall möchte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen Fälle, nämlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy 🤓.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die Einträge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die einträge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige ästhetische Griffe ist das jetzt das Gleiche wie in der Vorlesung 😄."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#aufgaben",
    "href": "30-lab-02-intro-to-data.html#aufgaben",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.3 Aufgaben",
    "text": "6.3 Aufgaben\n\n6.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus Section 6.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n6.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ändern Sie die finale Grafik in Section 6.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie ändert sich die Position der Ländernamen?\n\n\n\n6.3.3 Tutorium\nBearbeiten Sie das Tutorium “Einführung in Daten: 1 - Die Sprache der Daten”. Sie können entweder die deutsche Übersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "href": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "title": "6  Lab 02: Einführung in Daten",
    "section": "6.4 Ihre Arbeit einreichen",
    "text": "6.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen."
  },
  {
    "objectID": "100-aufgabensammlung.html",
    "href": "100-aufgabensammlung.html",
    "title": "Appendix A — Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009a). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele Vögel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFühren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "href": "100-aufgabensammlung.html#einführung-in-die-darstellung-von-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.2 Einführung in die Darstellung von Daten",
    "text": "A.2 Einführung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen Flossenlänge flipper_length_mm auf der \\(x\\)-Achse und der Variablen Körpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFärben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung 🤓."
  },
  {
    "objectID": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen Oberflächen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante Datensätze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Übung lernen Sie das Paket haven kennen, dass solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschäftigen uns mit dem Datensatz “Politbarometer 2021”. Die Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen für das ZDF durchgeführt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind für Lehre und Forschung frei. Sie müssen Sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter “Downloads” (rechts oben) den Datensatz “ZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MB” herunter. Dafür werden Sie sich einmalig (und kostenlos) anmelden müssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem “Daten”-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei “ZA7856_v1-0-0.dta” finden. Das ist der eigentliche Datensatz.\n\nDatensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich für die Übung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthält der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der “Tabelle 1: Variablenkorrespondenzliste Politbarometer 2021” gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren ändern. Gehen Sie durch den Code Zeile für Zeile durch und erklären Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenüber dem ursprünglichen Datensatz gesis verändert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse für Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Übung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie müssen vorher natürlich diese Bibliothek mit library() laden.\n\n\n\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir müssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der Merkmalsausprägungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmäßig so, wie diese im Datensatz erscheinen. Das ist für die Bundesländer ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den Bundesländern ausgeprägt ist. Dafür sehen wir uns die Antworten auf die Frage “Wie stark interessieren Sie sich für Politik, …”. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der Merkmalsausprägungen ist unlogisch. Das müssen wir ändern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht für keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der Merkmalsausprägungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den Bundesländern. Ist das Interesse der Bürger ähnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen Häufigkeiten heran. Was macht der nachfolgende Code. Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nächste Schritt ist es, die relativen Häufigkeiten (Anteile) für jedes Bundesland auszurechnen, um die obige Frage zu beantworten. Erklären Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurück zu unserer Frage: Ist das Interesse der Bürger in allen Bundesländern ähnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafür können Sie folgende Code-Fragmente ergänzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +\n  labs(___)\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#erste-schritte",
    "href": "30-lab-02-intro-to-data.html#erste-schritte",
    "title": "9  Lab 02: Pünktlichkeit von Flügen",
    "section": "9.1 Erste Schritte",
    "text": "9.1 Erste Schritte\n\n9.1.1 Pakete laden\nIn dieser Übung werden wir die Daten mithilfe der Paketsammlung tidyverse untersuchen und visualisieren. Die Daten befinden sich im Begleitpaket für OpenIntro-Übungen, openintro.\nLassen Sie uns die Pakete laden.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n\n9.1.2 Erstellen eines reproduzierbaren Berichts\nDenken Sie daran, dass wir R Markdown verwenden werden, um reproduzierbare Berichte zu erstellen. Gehen Sie in RStudio zu New File -> R Markdown… Wählen Sie dann From Template und wählen Sie dann Lab Report for OpenIntro Statistics Labs aus der Liste der Vorlagen. Oder verfahren Sie so, wie wir es in den Übungen gelernt haben New File -> R Notebook… Beide Varianten sind in Ordnung. Wenn Sie die Variante mit R Markdown wählen, gibt es keinen Button “Preview”, sondern Sie müssen das Dokument “knitten” über den Button mit dem Wollknäuel.\nSehen Sie sich das folgende Video an, in dem beschrieben wird, wie Sie mit der Erstellung dieser Berichte für dieses und alle zukünftigen Labs beginnen können:\nGrundlegendes zu R Markdown mit einer OpenIntro-Übung \n\n\n9.1.3 Die Daten\nDas Bureau of Transportation Statistics (BTS) ist eine Statistikbehörde, die zur Research and Innovative Technology Administration (RITA) gehört. Wie der Name schon sagt, sammelt das BTS Verkehrsdaten und stellt sie zur Verfügung, wie z. B. die Flugdaten, mit denen wir in diesem Labor arbeiten werden.\nAls Erstes werden wir uns den Datensatz nycflights ansehen. Geben Sie Folgendes in Ihre Konsole ein, um die Daten zu laden:\n\ndata(nycflights)\n\nDer Datensatz nycflights, der in Ihrem Arbeitsbereich angezeigt wird, ist eine Datenmatrix oder Datentabelle, wobei jede Zeile eine Beobachtung und jede Spalte eine Variable darstellt. In R wird dieses Datenformat als Dataframe bezeichnet, ein Begriff, der in den Übungen immer wieder verwendet wird. Bei diesem Datensatz ist jede Beobachtung ein einzelner Flug.\nUm die Namen der Variablen anzuzeigen, geben Sie den Befehl\n\nnames(nycflights)\n\nDies gibt die Namen der Variablen in diesem Datenrahmen zurück. Das Codebuch (Beschreibung der Variablen) kann über die Hilfedatei abgerufen werden:\n\n?nycflights\n\nEine der Variablen bezieht sich auf die Fluggesellschaft des Fluges, die nach folgendem System kodiert wird.\n\ncarrier (Fluggesellschaft): Zweibuchstabiges Kürzel der Fluggesellschaft.\n\n9E: Endeavor Air Inc.\nAA: American Airlines Inc.\nAS: Alaska Airlines Inc.\nB6: JetBlue Airways\nDL: Delta Air Lines Inc.\nEV: ExpressJet Fluggesellschaften Inc.\nF9: Frontier Airlines Inc.\nFL: AirTran Airways Corporation\nHA: Hawaiian Airlines Inc.\nMQ: Envoy Air\nOO: SkyWest Airlines Inc.\nUA: United Air Lines Inc.\nUS: US Airways Inc.\nVX: Virgin America\nWN: Southwest Airlines Co.\nYV: Mesa Airlines Inc.\n\n\nDenken Sie daran, dass Sie die Funktion glipmse() nutzen können, um einen Überblick über die Daten zu erhalten und somit deren Inhalt besser zu verstehen.\n\nglimpse(nycflights)\n\nDer Datensatz nycflights ist eine riesige Fundgrube an Informationen. Lassen Sie uns über einige Fragen nachdenken, die wir mit diesen Daten beantworten wollen:\n\nWie verspätet waren die Flüge nach Los Angeles?\nWie unterscheiden sich die Abflugverspätungen je nach Monat?\nWelcher der drei großen Flughäfen in New York hat den besten Prozentsatz an pünktlichen Abflügen?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#analyse",
    "href": "30-lab-02-intro-to-data.html#analyse",
    "title": "9  Lab 02: Pünktlichkeit von Flügen",
    "section": "9.2 Analyse",
    "text": "9.2 Analyse\n\n9.2.1 Bericht\nUm Ihre Analyse in einem reproduzierbaren Bericht festzuhalten, können Sie die allgemeine Vorlage für Berichte aus dem Paket openintro anpassen. Sehen Sie sich das Video oben an, um zu erfahren, wie das geht.\n\n\n9.2.2 Abflugverspätungen\nBeginnen wir damit, die Verteilung der Abflugverspätungen aller Flüge mit einem Histogramm zu untersuchen.\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram()\n\nMit dieser Funktion wird die Variable dep_delay aus dem Dataframe nycflights auf der \\(x\\)-Achse dargestellt. Sie definiert auch ein geom (kurz für geometrisches Objekt), das die Art der Darstellung beschreibt, die Sie erzeugen werden.\nHistogramme eignen sich im Allgemeinen sehr gut, um die Form der Verteilung einer einzelnen numerischen Variablen zu sehen, aber diese Form kann sich ändern, je nachdem, wie die Daten auf die verschiedenen Bins aufgeteilt sind. Sie können die zu verwendende Bin-Breite einfach festlegen:\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)\n\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 150)\n\n\n\nSchauen Sie sich diese drei Histogramme genau an. Wie lassen sie sich vergleichen? Sind in einem Histogramm Merkmale zu erkennen, die in einem anderen verdeckt sind?\n\n\nWenn Sie nur die Verspätungen von Flügen nach Los Angeles anzeigen möchten, müssen Sie zunächst die Daten nach Flügen mit diesem Ziel filter()n (dest == \"LAX\") und dann ein Histogramm der Abflugverspätungen nur dieser Flüge erstellen.\n\nlax_flights <- nycflights %>%\n  filter(dest == \"LAX\")\nggplot(data = lax_flights, aes(x = dep_delay)) +\n  geom_histogram()\n\nLassen Sie uns diese beiden Befehle entschlüsseln (OK, es sieht vielleicht nach vier Zeilen aus, aber die ersten beiden physischen Codezeilen sind tatsächlich Teil desselben Befehls. Es ist üblich, nach %>% einen Zeilenumbruch einzufügen, um die Lesbarkeit zu verbessern).\n\nBefehl 1: Nehmen Sie den Dataframe nycflights, filter()n Sie nach Flügen zum LAX und speichern Sie das Ergebnis als neuen Datenrahmen namens lax_flights.\n\n== bedeutet “wenn es gleich ist mit”.\nLAX steht in Anführungszeichen, da es sich um eine Zeichenkette handelt.\n\nBefehl 2: Im Grunde derselbe ggplot-Aufruf wie bei der Erstellung eines Histogramms, nur dass hier das kleinere Dataframe für Flüge mit Ziel LAX anstelle aller Flüge verwendet wird.\n\n\nLogische Operatoren: Das Filtern nach bestimmten Beobachtungen (z. B. Flüge von einem bestimmten Flughafen) ist in Dataframes oft von Interesse, wenn wir Beobachtungen mit bestimmten Merkmalsausprägungen getrennt vom Rest der Daten untersuchen möchten. Zu diesem Zweck können Sie die Filterfunktion und eine Reihe von logischen Operatoren verwenden. Die am häufigsten verwendeten logischen Operatoren für die Datenanalyse sind die folgenden:\n\n== bedeutet “gleich”\n!= bedeutet “nicht gleich”\n> oder < bedeutet “größer als” oder “kleiner als”.\n>= oder <= bedeutet “größer als oder gleich” oder “kleiner als oder gleich”.\n\n\nSie können auch numerische Zusammenfassungen für diese Flüge erhalten:\n\nlax_flights %>%\n  summarise(mean_dd   = mean(dep_delay), \n            median_dd = median(dep_delay), \n            n         = n())\n\nBeachten Sie, dass Sie in der Funktion summarise() eine Liste mit drei verschiedenen numerischen Zusammenfassungen erstellt haben, an denen Sie interessiert waren. Die Namen dieser Elemente sind benutzerdefiniert, wie mean_dd, median_dd, n, und Sie können diese Namen nach Belieben anpassen (verwenden Sie nur keine Leerzeichen in Ihren Namen). Für die Berechnung dieser zusammenfassenden Statistiken müssen Sie auch die Funktionsaufrufe kennen. Beachten Sie, dass n() den Stichprobenumfang angibt.\n\nZusammenfassende Statistiken aka statistische Lage- und Streumaße: Einige nützliche Funktionsaufrufe für zusammenfassende Statistiken für eine einzelne numerische Variable sind wie folgt:\n\nMittelwert: mean()\nMedian: median()\nStandardabweichung: sd()\nVarianz: var()\nInterquartilabstand: IQR()\nKleinster Wert: min()\nGrößter Wert: max()\n\nBeachten Sie, dass jede dieser Funktionen einen einzelnen Vektor als Argument annimmt und einen einzelnen Wert zurückgibt.\n\nSie können auch nach mehreren Kriterien filtern. Angenommen, Sie sind an Flügen nach San Francisco (SFO) im Februar interessiert:\n\nsfo_feb_flights <- nycflights %>%\n  filter(dest == \"SFO\", month == 2)\n\nBeachten Sie, dass Sie die Bedingungen durch Kommas trennen können, wenn Sie Flüge sowohl nach SFO als auch im Februar suchen. Wenn Sie entweder an Flügen nach SFO oder an Flügen im Februar interessiert sind, können Sie das | anstelle des Kommas verwenden.\n\n\nErstellen Sie ein neues Dataframe, das Flüge nach SFO im Februar enthält, und speichern Sie diesen Datenrahmen als sfo_feb_flights. Wie viele Flüge erfüllen diese Kriterien?\nBeschreiben Sie die Verteilung der Ankunftsverspätungen arr_delay dieser Flüge anhand eines Histogramms und geeigneter zusammenfassender Statistiken. Tipp: Die von Ihnen verwendete zusammenfassende Statistik sollte von der Form der Verteilung abhängen.\n\n\nEine weitere nützliche Methode ist die schnelle Berechnung von zusammenfassenden Statistiken für verschiedene Gruppen in Ihrem Dataframe. Wir können den obigen Befehl etwa mit der Funktion group_by() modifizieren, um die gleiche zusammenfassende Statistik für jeden Herkunftsflughafen zu erhalten:\n\nsfo_feb_flights %>%\n  group_by(origin) %>%\n  summarise(median_dd = median(dep_delay), iqr_dd = IQR(dep_delay), n_flights = n())\n\nHier haben wir die Daten zunächst nach Herkunft gruppiert und dann die zusammenfassenden Statistiken berechnet.\n\n\nBerechnen Sie den Median und den Interquartilsabstand für arr_delays der Flüge im Datenrahmen sfo_feb_flights, gruppiert nach Fluggesellschaft. Welche Fluggesellschaft hat Ankunftsverspätungen mit der größten Variabilität?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#abflugverspätungen-nach-monaten",
    "href": "30-lab-02-intro-to-data.html#abflugverspätungen-nach-monaten",
    "title": "9  Lab 02: Pünktlichkeit von Flügen",
    "section": "9.3 Abflugverspätungen nach Monaten",
    "text": "9.3 Abflugverspätungen nach Monaten\nIn welchem Monat würden Sie die höchste durchschnittliche Verspätung bei Abflügen von einem New Yorker Flughafen erwarten?\nLassen Sie uns überlegen, wie Sie diese Frage beantworten können:\n\nBerechnen Sie zunächst die monatlichen Durchschnittswerte für Abflugverspätungen. Mit der neuen Sprache, die Sie gerade lernen, könnten Sie\n\ngroup_by() nach Monaten, dann\ndie durchschnittlichen Abflugverspätungen zusammenfassen mit summarise().\n\nDann könnten Sie diese durchschnittlichen Verspätungen in absteigender Reihenfolge mit arrange()anordnen\n\n\nnycflights %>%\n  group_by(month) %>%\n  summarise(mean_dd = mean(dep_delay)) %>%\n  arrange(desc(mean_dd))\n\n\n\nAngenommen, Sie mögen keine Verspätungen bei der Abreise und möchten Ihre Reise in einem Monat planen, der Ihre mögliche Verspätung bei der Abreise aus New York minimiert. Eine Möglichkeit ist, den Monat mit dem geringsten Mittelwerten der Abflugverspätung zu wählen. Eine andere Möglichkeit ist, den Monat mit dem geringsten Median der Abflugverspätung zu wählen. Was sind die Vor- und Nachteile dieser beiden Möglichkeiten?\n\n\n\n9.3.1 Pünktliche Abflugrate für NYC-Flughäfen\nAngenommen, Sie fliegen von New York City aus und möchten wissen, welcher der drei großen Flughäfen in New York City die beste Pünktlichkeitsrate bei abgehenden Flügen aufweist. Nehmen wir weiter an, dass für Sie ein Flug, der weniger als 5 Minuten Verspätung hat, grundsätzlich “pünktlich” (“on time”) ist. Sie betrachten jeden Flug, der mehr als 5 Minuten Verspätung hat, als “verspätet” (“delayed”).\nUm festzustellen, welcher Flughafen die beste Pünktlichkeitsquote hat, können Sie\n\nzunächst jeden Flug als “on time” oder “delayed” einstufen,\ndann die Flüge nach Herkunftsflughafen gruppieren,\ndann die Rate der pünktlichen Abflüge für jeden Herkunftsflughafen berechnen,\nund schließlich die Flughäfen in absteigender Reihenfolge nach dem Prozentsatz der pünktlichen Abflüge ordnen.\n\nBeginnen wir mit der Klassifizierung der einzelnen Flüge als “on time” oder “delayed”, indem wir mit der Funktion mutate() eine neue Variable erstellen.\n\nnycflights <- nycflights %>%\n  mutate(dep_type = ifelse(dep_delay < 5, \"on time\", \"delayed\"))\n\nDas erste Argument in der Funktion mutate() ist der Name der neuen Variable, die wir erstellen wollen, in diesem Fall dep_type. Wenn dep_delay < 5 ist, klassifizieren wir den Flug als “on time”, wenn nicht, als “delayed”, d. h. wenn der Flug 5 oder mehr Minuten verspätet ist.\nBeachten Sie, dass wir auch das Dataframe nycflights mit der neuen Version dieses Dataframes überschreiben, der die neue Variable dep_type enthält.\nAlle übrigen Schritte können wir in einem einzigen Code-Chunk erledigen:\n\nnycflights %>%\n  group_by(origin) %>%\n  summarise(ot_dep_rate = sum(dep_type == \"on time\") / n()) %>%\n  arrange(desc(ot_dep_rate))\n\n\n\nWenn Sie einen Flughafen nur aufgrund des prozentualen Anteils der Abflüge in der Zeit auswählen würden, welchen Flughafen in NYC würden Sie dann wählen?\n\n\nSie können auch die Verteilung der pünktlichen Abflugrate auf die drei Flughäfen mithilfe eines Balkendiagramms visualisieren.\n\nggplot(data = nycflights, aes(x = origin, fill = dep_type)) +\n  geom_bar()"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#weitere-übungen",
    "href": "30-lab-02-intro-to-data.html#weitere-übungen",
    "title": "9  Lab 02: Pünktlichkeit von Flügen",
    "section": "9.4 Weitere Übungen",
    "text": "9.4 Weitere Übungen\n\n\nÄndern Sie das Dataframe so, dass es eine neue Variable enthält, die die Durchschnittsgeschwindigkeit, avg_speed, die das Flugzeug bei jedem Flug zurückgelegt hat (in mph), angibt. Tipp: Die Durchschnittsgeschwindigkeit kann als Entfernung geteilt durch die Anzahl der Flugstunden berechnet werden, und beachten Sie, dass die Flugzeit air_time in Minuten angegeben wird.\nErstellen Sie ein Streudiagramm von der Durchschnittsgeschwindigkeit avg_speed und Entfernung distance. Beschreiben Sie die Beziehung zwischen Durchschnittsgeschwindigkeit und Entfernung. Tipp: Verwenden Sie geom_point().\nBauen Sie die folgende Darstellung nach. Tipp: Das dargestellte Dataframe enthält nur Flüge von American Airlines, Delta Airlines und United Airlines, und die Punkte sind nach Fluggesellschaft carrier eingefärbt (colored). Ermitteln Sie nach dem Plotten (grob) den Grenzwert für Abflugverspätungen, bei dem Sie noch erwarten können, Ihr Ziel rechtzeitig zu erreichen."
  },
  {
    "objectID": "06-explorative-numerisch.html",
    "href": "06-explorative-numerisch.html",
    "title": "6  Exploration von numerischen Daten",
    "section": "",
    "text": "Kernpakete aus tidyverse benennen\nein Workflow (Daten einlesen, zusammenfassen, darstellen) mit tidyverse durchführen\nFunktionen des Pakets dplyr für Datentransformation anwenden\ntidyverse ist eine Sammlung von R-Paketen, die explizit für Datenanalyse entwickelt wurden (https://www.tidyverse.org/). tidyverse versucht durch gemeinsame Philosophie in Design, Grammatik und Datenstruktur die Datenanalyse zu erleichtern (https://design.tidyverse.org/). Auch wenn tidyverse auf den ersten Blick etwas fremd erscheint, es ist ein Teil von R, kein eigenes Universum. Es ist also völlig in Ordnung, R-Basisfunktionen mit Funktionen aus tidyverse zu mischen.\nDas wichtigste Einführungsbuch zu tidyverse ist sicherlich R4DS: “R for Data Science” (Wickham and Grolemund 2021), das Sie kostenlos online lesen können (https://r4ds.had.co.nz/)."
  },
  {
    "objectID": "06-explorative-numerisch.html#grundpakete",
    "href": "06-explorative-numerisch.html#grundpakete",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.1 Grundpakete",
    "text": "6.1 Grundpakete\ntidyverse enthält folgende Grundpakete, die alle installiert werden, wenn Sie install.packages('tidyverse') ausführen.\n\n\n\nPaketname\nKurzbeschreibung\n\n\n\n\nggplot2\nVisualisierung\n\n\ndplyr\nDatentransformation\n\n\ntidyr\nDatenbereinigung\n\n\nreadr\nDaten einlesen\n\n\npurrr\nFunktionale Programmierung (Funktionen auf Objekte anwenden)\n\n\ntibble\nErweiterung von data.frame\n\n\nstringr\nFunktionen für Strings, d. h. Textvariablen\n\n\nforcats\nFunktionen für factor\n\n\n\nJedes dieser Pakete hat ein Cheat Sheet, eine übersichtliche Zusammenstellung der Funktionen des Pakets. Sie bekommen die Cheet Sheats über die tidyverse-Seite (https://www.tidyverse.org/packages/), indem Sie auf das jeweilige Paket klicken und zum Abschnitt ‘Cheatsheet’ scrollen."
  },
  {
    "objectID": "06-explorative-numerisch.html#der-explorative-workflow",
    "href": "06-explorative-numerisch.html#der-explorative-workflow",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.2 Der explorative Workflow",
    "text": "6.2 Der explorative Workflow\n\n6.2.1 Daten einlesen, revisited\nAls Erstes laden wir die Bibliothek tidyverse.\n\nlibrary(tidyverse)\n\nSie kennen bereits die Funktion read_delim() zum Einlesen von Textdateien. Die Funktion ist die allgemeinste Funktion der read_* Familie aus readr in tidyverse; read_csv() und read_csv2() sind jeweils für komma- und strichpunkt-getrennte Datensätze gedacht. In der Basisinstallation von R (also außerhalb von tidyverse) gibt die sehr umfangreiche Funktion read.table(), die ebenfalls zum Einlesen von Textdateien verwendet wird. Man könnte berechtigterweise fragen, warum neue Funktion (read_*) für etwas erfinden, was es schon gibt. Die Autoren von tidyverse versprechen Konsistenz und Geschwindigkeit. Ersteres war schon immer ein Problem von R, da es nicht von Computerspezialisten, sondern von Anwendern erfunden wurde. Daher ist eine Vereinheitlichung durch tidyverse mehr als willkommen. Und Geschwindigkeit ist spätestens bei größeren Datensätzen ein wichtiger Punkt.\nWir sehen uns Daten des Deutschen Wetterdienstes an, die ich am 24. Mai 2020 heruntergeladen habe (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). Der Datensatz enthält Stundenwerte für relative Luftfeuchte (%) und Lufttemperatur (°C) von drei Wetterstationen, nämlich Hof, Frankfurt und Köln-Bonn. Die Daten sind in der Datei “Drei_Stationen.csv” gespeichert.\nBeim Einlesen zeigt Ihnen read_delim() bereits, welche Spalten und welche Datentypen es erkennt, mit trim_ws = T werden Leerzeichen aus Spalten entfernt, weil die Daten sonst falsch eingelesen werden.\n\ntemp_humid <- read_delim('Daten/Drei_Stationen.csv', delim = ';', trim_ws = T)\n\nRows: 39600 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): eor\ndbl (5): STATIONS_ID, MESS_DATUM, QN_9, TT_TU, RF_TU\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEs sollte für Sie bereits Routine sein, das Ergebnis des Einlesens zu kontrollieren.\n\ntemp_humid\n\n\n\n  \n\n\n\nAlternative können Sie die Funktion glimpse() verwenden.\n\nglimpse(temp_humid)\n\nRows: 39,600\nColumns: 6\n$ STATIONS_ID <dbl> 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261…\n$ MESS_DATUM  <dbl> 2018111900, 2018111901, 2018111902, 2018111903, 2018111904…\n$ QN_9        <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ TT_TU       <dbl> -2.8, -2.5, -2.3, -2.0, -1.9, -2.1, -1.8, -1.5, -1.1, -0.6…\n$ RF_TU       <dbl> 99, 100, 100, 100, 99, 99, 99, 99, 99, 97, 95, 93, 94, 88,…\n$ eor         <chr> \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"e…\n\n\nIn diesem Datensatz sind folgende Variablen (Spalten) enthalten (s. Datensatzbeschreibung des DWDs)\n\n\n\nVariablen\nBeschreibung\n\n\n\n\nSTATIONS_ID\nStationsidentifikationsnummer\n\n\nMESS_DATUM\nZeitstempel im Format yyyymmddhh\n\n\nQN_9\nQualitätsniveau der nachfolgenden Spalten\n\n\nTT_TU\nLufttemperatur in 2 m Höhe °C\n\n\nRF_TU\nrelative Feuchte %\n\n\neor\nEnde data record"
  },
  {
    "objectID": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "href": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.3 Geschickter Umgang mit Zeit und Datum",
    "text": "6.3 Geschickter Umgang mit Zeit und Datum\nEin weiteres Paket, das zwar nicht zum Kern von tidyverse gehört, jedoch trotzdem extrem nützlich ist, heißt lubridate. Das haben wir bereits im letzten Kapitel verwendet, um aus einem Datum das Jahr zu extrahieren. lubridate hilft aber auch, Text sehr einfach in richtige Datums-Objekte zu transformieren. Wir transformieren die Spalte temp_humid$MESS_DATUM in ein richtiges Datum mit Uhrzeit. Die Funktion ymd_h() kann character in ein richtiges Datumsformat transformieren, wenn das Datum als year, month, day, hour codiert ist. Es gibt noch weitere Varianten der Codierung, die Sie bei Bedarf in der Hilfe nachschlagen sollten.\n\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid\n\n\n\n  \n\n\n\n\n6.3.1 Daten zusammenfassen\nDie drei Wetterstationen haben folgende IDs:\n\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\n\nWir zählen nach, wie viele Messpunkte es pro Station gibt. Die Funktion count() kennen Sie bereits. Sie zählt, wie häufig unterschiedlichen Merkmalsausprägungen vorkommen:\n\ntemp_humid %>% \n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDie Zeichenkombination %>% heißt Pipe-Operator (pipe) und wird als ‘und dann’ gelesen (then). Diesen Operator haben wir bereits im letzten Kapitel verwendet. Der Ausdruck temp_humid %>% count(STATIONS_ID) heißt also: nimm das Objekt temp_humid, und zähle dann die Anzahl der verschiedenen Merkmalsausprägungen zusammen. Der Pipe-Operator ist die Kernphilosophie von tidyverse und wird Ihnen überall begegnen. Der Operator stammt aus dem Paket magrittr (https://magrittr.tidyverse.org/). Seine Hauptaufgabe ist es, den Code übersichtlicher und besser lesbar zu machen (vielleicht nicht gleich zu Beginn der Lernkurve, aber schon bald 😎)."
  },
  {
    "objectID": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "href": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.4 Die Grammatik der Datenmanipulation – dplyr",
    "text": "6.4 Die Grammatik der Datenmanipulation – dplyr\nDie Funktion count() gehört zum Paket dplyr, das für Datentransformationen zuständig ist. Es ist mal wieder eine Grammatik. Dieses Paket enthält 5 Grundfunktionen (alle nach Verben benannt, damit man gleich weiß, was frau tut 😄):\n\n\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nfilter()\nWähle Daten anhand ihrer Werte\n\n\narrange()\nSortiere Zeilen\n\n\nselect()\nWähle Variablen anhand ihrer Namen\n\n\nmutate()\nErstelle neue Variablen als Funktionen vorhandener Variablen\n\n\nsummarize()\nFasse Daten zusammen\n\n\n\nWenn wir nur von einer bestimmten Station die Anzahl der Messwerte wissen möchten, dann filtern wir vorher.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nBeim Filtern läuft eine logische Abfrage. D. h. es wird bei jeden Eintrag in STATION_ID nachgesehen, ob da der Wert 2667 steht. Wenn da 2667 steht, dann gibt == ein TRUE zurück, wenn da etwas anderes steht, dann gibt == ein FALSE zurück. Und die Funktion filter() behält nur die Zeilen, bei denen == ein TRUE zurückgegeben hat.\nWeiter wichtige logische und relationale Operatoren finden Sie hier in der Hilfe zu filter(). Hier ein paar einfache Beispiele\n\n\n\n\n\n\n\nOperator\nBedeutung\n\n\n\n\n==/ > / >=\nist die linke Seite gleich / größer / größer-gleich als die rechte Seite\n\n\n!=\nist die linke Seite ungleich der rechten Seite\n\n\n\nZudem kann man bei filter() die Anfragen auch kombinieren. Wir wollen z. B. die Stationen Köln und Hof haben. | ist der logische Operator oder. Wenn man also sowohl Köln als auch Hof haben will, sagt man: finde alles, was entweder gleich Köln oder gleich Hof ist.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDas Gleiche erreicht man mit folgendem Code, indem man Frankfurt ausschließt:\n\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nAlternative kann man auch den Operator %in% verwenden. Dieser ist sehr nützlich, wenn man anhand einer einzelnen Variablen filtert, aber unterschiedliche Einträge auswählen möchte (z. B. zwei Messstationen). Es wird bei jeder Zeile in der Variablen STATIONS_ID nun überprüft, ob hier entweder 2667 oder 2261 stehen.\n\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\n\n6.4.1 Daten plotten\nWir sehen uns die Daten erst mal an, bevor wir weiter machen. Wir plotten die Temperatur. Weil es sich um Zeitreihen handelt, kommt auf die \\(x\\)-Achse die Zeit.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU, color = as_factor(STATIONS_ID))) + \n  geom_line() +\n  labs(x = 'Zeit', y = 'Temperatur (°C)', color = 'Stationen')\n\n\n\n\nBeachten Sie, dass wir die Variable zum Einfärben, nämlichSTATIONS_ID, direkt in ggplot() in eine kategoriale Variable umgewandelt haben. Sonst werden die Farben als Farbeverlauf statt drei unterschiedliche Farben, dargestellt.\nDa man erwarten kann, dass sich der Temperaturverlauf innerhalb Deutschlands nicht so stark unterscheidet, überdecken sich die Zeitreihen. Das ist für die Darstellung ungünstig. Daher wäre es besser, wenn wir die Zeitreihen in getrennte Grafiken je Station plotten würden. Dafür gibt es eine neue Funktion aus dem Paket ggplot2, nämlich facet_wrap(). Sie kann eine Grafik mithilfe einer kategorialen Variablen in Teilgrafiken aufteilen.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nDa wir die Teilgrafiken untereinander darstellen möchten, setzen wir bei facet_wrap() den Parameter nrow = 3. Bei Teilgrafiken kann man auf die Färbung der Zeitreihen verzichten.\n\n\n6.4.2 Jahresdurchschnittstemperatur\nWie hoch war die Jahresdurchschnittstemperatur auf den drei Stationen? Um diese Frage zu beantworten, erstellen wir zunächst eine neue Variable mit dem Jahr der Messungen. Das kennen Sie bereits aus dem letzten Kapitel. Die Funktion year() gehört zur Bibliothek lubridate. Die Funktion mutate() erstellt die neue Spalte und hängt sie an das Ende des Dataframes.\n\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM))\n\nDa wir die Durchschnittstemperatur für jede Station und jedes Jahr separat berechnen wollen, müssen wir unseren Datensatz nach den Stationen gruppieren. Durch die Gruppierung entstehen intern Gruppen, für die Berechnungen getrennt laufen werden. An den Daten selbst ändert sich nichts.\nAls zweiten Schritt nutzen wir dann die Funktion summerise(), die verschiedene statistische Zusammenfassungen der Daten berechnen kann. In diesem Fall möchten wir mithilfe der Funktion mean() den Mittelwert berechnen. Wir nennen den neu berechneten Datensatz yearly_means.\n\nyearly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year) %>% \n  summarize(mean_T = mean(TT_TU))\n\n`summarise()` has grouped output by 'STATIONS_ID'. You can override using the\n`.groups` argument.\n\n\nWir erhalten einen Datensatz, der pro Jahr und Station einen Mittelwert der Temperatur enthält. Die Variable, die die mittlere Temperatur enthält, haben wir mean_T genannt. Sie steht in der Zeile summarize(mean_T = mean(TT_TU)) links vom Aufruf der Funktion mean(). Der Code mean(TT_TU) berechnet den Mittelwert der Variablen TT_TU, also der Temperatur.\n\nyearly_means\n\n\n\n  \n\n\n\nDie Berechnung der Jahresmittelwerte ist sehr kritisch zu sehen. Nicht alle berechneten Werte machen Sinn. Diskutieren Sie in der Hausaufgabe warum.\n\n\n6.4.3 Monatliche Durchschnittstemperatur und ihre Variabilität\nWie hoch war die monatliche Durchschnittstemperatur auf den verschiedenen Stationen und wie stark schwankte sie? Diese Frage können wir beantworten, indem wir Mittelwerte und Standardabweichungen für jeden Monat eines jeden Jahres und jede Station berechnen. Für die Berechnung erstellen wir eine weite Spalte mit dem Monat. Die Funktion month() gehört ebenfalls zur Bibliothek lubridate und extrahiert den Monat aus MESS_DATUM.\n\ntemp_humid <- temp_humid %>% \n  mutate(month = month(MESS_DATUM))\n\ntemp_humid\n\n\n\n  \n\n\n\nJetzt können wir die Mittelwerte und die Standardabweichungen mit der Funktion summarise() berechnen. Diese Funktion kann gleichzeitig verschiedene statistische Zusammenfassungen berechnen. Den Mittelwert berechnen wir erneut mit der Funktion mean() und die Standardabweichung mit der Funktion sd().\nFür die Berechnung gruppieren wir die Daten nach STATIONS_ID, year und month mit der Funktion group_by(). Die Mittelwerte sollen ja je Station, Jahr und Monat berechnet werden. Beim Gruppieren gibt man die Variablennamen ohne Anführungszeichen durch Kommas getrennt an. Man kann nach einer oder mehreren Variablen gruppieren, die Logik bleibt immer die gleiche, nämlich group_by(VARIABLE_1) fürs Gruppieren mit einer Variablen oder group_by(VARIABLE_1, VARIABLE_2, VARIABLE_3) für z. B. gruppieren nach drei Variablen.\n\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), sd_T = sd(TT_TU))\n\n`summarise()` has grouped output by 'STATIONS_ID', 'year'. You can override\nusing the `.groups` argument.\n\nmonthly_means\n\n\n\n  \n\n\n\nDie Variable, die die Standardabweichung enthält, haben wir sd_T genannt.\nDas Dataframe monthly_means ist ein gruppiertes tibble. Das ist für die meisten Anwendungen nicht von Belang. Insbesondere ändert es nicht die Daten selbst, sondern nur die interne Organisation des tibble. Manchmal stört die Gruppierung jedoch beim Rechnen mit dem Datensatz und wir lösen sie wieder auf.\n\nmonthly_means <- ungroup(monthly_means)\n\nUm die monatlichen Daten als Zeitreihen zu plotten, brauchen wir noch eine Variable mit dem dazugehörigen Datum. Die Funktion parse_date_time() kann aus character richtige Datums- und Zeitobjekte erstellen. Sie ist allgemeiner als die oben verwendete ymd_h() Funktion, da man hier das Format explizit angeben kann. In unserem Fall ist das Format ‘ym’ für Jahr und Monat.\n\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET'))\n\nmonthly_means\n\n\n\n  \n\n\n\nDer Code paste0(year, month) “klebt” die Daten in der Variablen year und month zusammen. Das ist nötig, da die Funktion parse_date_time() einen zusammenhängenden Text als Input erwartet und keine zwei getrennten Spalten. Da das Datum außer dem Jahr und dem Monat noch einen Tag braucht, hat parse_date_time() automatisch den Ersten eines jeden Monats genommen. Beim Erstellen von korrekten Zeitangaben kommt es auch auf die Zeitzone an. Wir sind in Deutschland, da gilt die mitteleuropäische Zeit (engl. central European time, CET). Die Zeitzone ist für unsere Daten zwar nicht wirklich relevant, da wir hier Monatsdaten darstellen. Ich würde sie aber trotzdem richtig setzten, da die Standardeinstellung der Funktion parse_date_time(tz = \"UTC\") lautet und für Deutschland falsch ist.\n\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Zeit', y = 'Temperatur (°C)', color = 'Messstation')\n\n\n\n\nAlternativ können wir die Mittelwerte mit den Standardabweichungen darstellen.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nOder, weil es gerade Spaß macht, als halb-transparentes Band 😎.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')\n\n\n\n\nEin letzter Trick. Die Überschriften für die Teilgrafiken sind ungeschickt, da man die IDs als Mensch einfach nicht zuordnen kann. Weiter oben haben wir einen benannten Vektor definiert, der die Klarnamen enthält.\n\nstation_ids\n\n       2261        1420        2667 \n      \"Hof\" \"Frankfurt\"     \"Koeln\" \n\n\nDiesen Vektor nutzen wir als Titel.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Zeit', y = 'Temperatur (°C)')"
  },
  {
    "objectID": "06-explorative-numerisch.html#weiterführende-literatur-und-videos",
    "href": "06-explorative-numerisch.html#weiterführende-literatur-und-videos",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.5 Weiterführende Literatur und Videos",
    "text": "6.5 Weiterführende Literatur und Videos\n\nR4DS Wickham and Grolemund (2021): Kapitel 5 “Data transformation”\nEine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt 😄."
  },
  {
    "objectID": "06-explorative-numerisch.html#aufgaben",
    "href": "06-explorative-numerisch.html#aufgaben",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\n6.6.1 Was bedeutet der Code?\nWas bedeuten die Parameter ymin und ymax im folgenden Code?\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T))\n\n\n\n6.6.2 Welche Mittelwerte machen Sinn?\nDiskutieren Sie kritisch, welche mittleren Jahrestemperaturen Sinn machen und interpretiert werden können. Begründen Sie.\n\n\n6.6.3 Politbarometer\nBearbeiten Sie die Aufgaben Section A.3.1 und Section A.4.1 aus der Aufgabensammlung."
  },
  {
    "objectID": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "href": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "title": "6  Exploration von numerischen Daten",
    "section": "6.7 Ihre Arbeit einreichen",
    "text": "6.7 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "title": "Appendix A — Aufgabensammlung",
    "section": "A.5 Exploration von numerischen Daten",
    "text": "A.5 Exploration von numerischen Daten\n\nA.5.1 Umweltdaten entlang der dänischen Küste\nDie Datei “Temperatur.csv” aus Zuur, Ieno, and Meesters (2009b) enthält Messungen von Temperatur, Salinität und Chlorophyll a an 31 Orten entlang der dänischen Küste. Der Datensatz kann hier heruntergeladen werden. Sie bekommen ihn aber bereits über ILIAS gestellt. Die Daten stammen vom dänischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgeführt, mit einer Häufigkeit von 0–4 mal pro Monat je nach Jahreszeit.\n\nLesen Sie den Datensatz “Temperatur.csv” (auf ILIAS) ein.\nKonvertieren Sie die Spalte Date in ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (facet_wrap()) als Zeitreihen.\nBerechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur für alle Stationen, sowie die Standardabweichungen. Tipp: innerhalb von summarize() müssen Sie n = n() schreiben, um die Anzahl der Messwerte zu erhalten.\nStellen Sie die Monatsmittel der Temperatur als Linien dar. Tipp: Um die Monate mit ihren Namen darzustellen, nutzen Sie den folgenden Code scale_x_discrete(limits = as_factor(1:12), labels = month.abb). Hängen Sie ihn mit einem + an. Was macht dieser Code?\nBeschriften Sie die Grafik sinnvoll.\nFügen Sie die Standardabweichungen als Band hinzu.\n\n\n\nA.5.2 Quantile\nWir beschäftigen uns mit dem Datensatz possum im Paket openintro.\n\nLaden Sie die Biblothek und anschließend den Datensatz.\nBerechnen Sie\n\n\nDas 1. Quartil\nDas 3. Quartil\nDen Median\n\nDer Körper- und Kopflängen.\n\nStellen Sie die Körper- und Kopflängen als Boxplots nebeneinander dar. Nutzen Sie dazu die Bibliothek patchwork.\nStellen Sie die beiden Variablen als Streudiagramm dar (Körperlängen auf die \\(x\\)-Achse).\nBerechnen Sie den linearen Korrelationskoeffizienten mit der Funktion cor().\n\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009a. A Beginner’s Guide to R. Springer.\n\n\n———. 2009b. A Beginner’s Guide to R. Springer."
  },
  {
    "objectID": "07-lineare-regression.html",
    "href": "07-lineare-regression.html",
    "title": "7  Lineare Regression",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklären.\nLineare Regression mit einer und mehreren erklärenden Variablen selbst in R durchführen.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression.html#begriff-regression",
    "href": "07-lineare-regression.html#begriff-regression",
    "title": "7  Lineare Regression",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prägte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem für den Zusammenhang zwischen der durchschnittlichen Körpergröße der Eltern und der Körpergröße ihrer erwachsenen Kinder. Leider war er nicht nur einer der Väter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher größer waren und umgekehrt, Kinder von überdurchschnittlich großen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (Rückkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression.html#idee-der-regression",
    "href": "07-lineare-regression.html#idee-der-regression",
    "title": "7  Lineare Regression",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschließlich mit solchen linearen Modellen beschäftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklärenden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklärende Variable, nämlich die Durchschnittsgröße der Eltern. Die Zielvariable war die zu erwartende Größe der Kinder. Es ging also nicht darum, die exakte Größe eines bestimmten Kindes zu berechnen, sondern den Einfluss der Durchschnittsgröße der Eltern auf die zu erwartende (oder eben mittlere) Größe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die Körpergröße sein. Sie kann binär, kategorial oder eine Zählvariable sein. Auch die erklärenden Variablen können stetig, binär oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschäftigen."
  },
  {
    "objectID": "07-lineare-regression.html#lineare-regression-mit-einer-erklärenden-variablen",
    "href": "07-lineare-regression.html#lineare-regression-mit-einer-erklärenden-variablen",
    "title": "7  Lineare Regression",
    "section": "7.3 Lineare Regression mit einer erklärenden Variablen",
    "text": "7.3 Lineare Regression mit einer erklärenden Variablen\nDie Formel für die lineare Regression mit einer erklärenden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklärende Variable oder Prädiktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklärenden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKönnen wir aus der Körpermasse der Pinguine deren mittlere Flügellänge vorhersagen?\nAls Erstes müssen wir untersuchen, ob es überhaupt einen plausiblen linearen Zusammenhang zwischen Körpermassen und Flügellängen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklärende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir können für die Visualisierung gleich die Gerade hinzu plotten. Das übernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst später kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu können, nutzen wir die Funktion lm(). Das steht für engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ Prädiktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen für die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthält sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigun der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt für ein schönes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kümmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls Nächstes müssen wir überprüfen, ob die Residuen in unserem Modell irgendwelche auffälligen Muster zeigen. Das wäre ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklärende Variable nicht berücksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werde auf der \\(x\\)-Achse die vom Modell angepassten Werte, d. h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthält. Die Streuung der Residuen sieht gleich aus für den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafür, dass das Modell soweit plausibel für unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein Gütemaß für das angepasste Modell. Er zeigt, wie viel Variabilität der Zielvariablen, hier also der Flügellängen, wird vom Modell erklärt. Mit anderen Worten, wenn wir das Modell verwenden und die Information über die Körpermasse der Tiere nutzen, um wie viel sinkt dann die Variabilität unserer Vorhersagen der Flügellängen.\nDen Determinationskoeffizienten \\(R^2\\) können wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der Variabilität der Flügellängen erklärt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche Flügellänge sich ändert, wenn die Körpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche Flügellänge, wenn die Körpermasse 0 ist. Das ist keine relevante Größe, da Körpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression.html#aufgaben",
    "href": "07-lineare-regression.html#aufgaben",
    "title": "7  Lineare Regression",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Vertiefung des linearen Modells\nArbeiten Sie das Tutorial Regression modeling: 4 - Interpreting regression models durch.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorial durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie für einen Pinguin mit der Körpermasse 5000 g die zu erwartende Flügellänge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:"
  },
  {
    "objectID": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "title": "7  Lineare Regression",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html",
    "href": "07-lineare-regression-ein-pred.html",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklären.\nLineare Regression mit einer erklärenden Variablen selbst in R durchführen.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#begriff-regression",
    "href": "07-lineare-regression-ein-pred.html#begriff-regression",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prägte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem für den Zusammenhang zwischen der durchschnittlichen Körpergröße der Eltern und der Körpergröße ihrer erwachsenen Kinder. Leider war er nicht nur einer der Väter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher größer waren und umgekehrt, Kinder von überdurchschnittlich großen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (Rückkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "href": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschließlich mit solchen linearen Modellen beschäftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklärenden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklärende Variable, nämlich die Durchschnittsgröße der Eltern. Die Zielvariable war die zu erwartende Größe der Kinder. Es ging also nicht darum, die exakte Größe eines bestimmten Kindes zu berechnen, sondern den Einfluss der Durchschnittsgröße der Eltern auf die zu erwartende (oder eben mittlere) Größe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die Körpergröße sein. Sie kann binär, kategorial oder eine Zählvariable sein. Auch die erklärenden Variablen können stetig, binär oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschäftigen."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklärenden-variablen",
    "href": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklärenden-variablen",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.3 Lineare Regression mit einer numerischen erklärenden Variablen",
    "text": "7.3 Lineare Regression mit einer numerischen erklärenden Variablen\nDie Formel für die lineare Regression mit einer erklärenden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklärende Variable oder Prädiktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklärenden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKönnen wir aus der Körpermasse der Pinguine deren mittlere Flügellänge vorhersagen?\nAls Erstes müssen wir untersuchen, ob es überhaupt einen plausiblen linearen Zusammenhang zwischen Körpermassen und Flügellängen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklärende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir können für die Visualisierung gleich die Gerade hinzu plotten. Das übernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst später kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu können, nutzen wir die Funktion lm(). Das steht für engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ Prädiktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen für die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthält sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigung der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt für ein schönes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kümmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls Nächstes müssen wir überprüfen, ob die Residuen in unserem Modell irgendwelche auffälligen Muster zeigen. Das wäre ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklärende Variable nicht berücksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werden auf der \\(x\\)-Achse die vom Modell angepassten Werte, d. h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthält. Die Streuung der Residuen sieht gleich aus für den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafür, dass das Modell soweit plausibel für unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein Gütemaß für das angepasste Modell. Er zeigt, wie viel Variabilität der Zielvariablen, hier also der Flügellängen, wird vom Modell erklärt. Mit anderen Worten, wenn wir das Modell verwenden und die Information über die Körpermasse der Tiere nutzen, um wie viel sinkt dann die Variabilität unserer Vorhersagen der Flügellängen.\nDen Determinationskoeffizienten \\(R^2\\) können wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der Variabilität der Flügellängen erklärt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche Flügellänge sich ändert, wenn die Körpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche Flügellänge, wenn die Körpermasse 0 ist. Das ist keine relevante Größe, da Körpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#aufgaben",
    "href": "07-lineare-regression-ein-pred.html#aufgaben",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Vertiefung des linearen Modells\nArbeiten Sie das Tutorial Regression modeling: 4 - Interpreting regression models durch.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorial durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie für einen Pinguin mit der Körpermasse 5000 g die zu erwartende Flügellänge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:"
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "title": "7  Lineare Regression mit einer erklärenden Variablen",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterlösung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "index.html#lernergebnisse-intended-learning-outcomes",
    "href": "index.html#lernergebnisse-intended-learning-outcomes",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Lernergebnisse (intended learning outcomes)",
    "text": "Lernergebnisse (intended learning outcomes)\n\nDatenanalyse\n\nDaten für statistische Analysen aufbereiten\nExplorative (beschreibende) Datenanalyse durchführen\nDaten visualisieren\nErgebnisse der Analysen reproduzierbar darstellen\n\nStatistische Methoden\n\nEinfache statistische Kenngrößen (Mittelwert, Standardabweichung etc.) berechnen\nEine Korrelation zwischen zwei Datensätzen berechnen\nHypothesentests durchführen und die Ergebnisse richtig berichten und interpretieren\nKonfidenzintervalle berechnen und interpretieren\nEin lineares Modell berechnen, die Ergebnisse darstellen und interpretieren"
  },
  {
    "objectID": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPünktlichkeit bei Präsenz- und Zoomsitzungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenüber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen 😄"
  },
  {
    "objectID": "index.html#sinn-und-unsinn-dieses-skripts",
    "href": "index.html#sinn-und-unsinn-dieses-skripts",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Sinn und Unsinn dieses Skripts",
    "text": "Sinn und Unsinn dieses Skripts\nDieses Skript ist ein lebendiges Begleitdokument des Kurses. Es wird laufend angepasst und aktualisiert.\nIch nutze verschiedenfarbige Blöcke, um wichtige Stellen hervorzuheben:\n\nInfoblock\n\n\n\nAchtung, wichtig!\n\n\n\nDefinition\n\n\n\nLernziele"
  },
  {
    "objectID": "index.html#inspiration-quellen-und-danksagung",
    "href": "index.html#inspiration-quellen-und-danksagung",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Inspiration, Quellen und Danksagung",
    "text": "Inspiration, Quellen und Danksagung\nDieses Skript baut stark auf folgenden freien Quellen auf:\n\nr4ds: Wickham and Grolemund (2021)\nggplot2: Wickham (2020)\nModernDive: Ismay and Kim (2021)\nIntroduction to Modern Statistics: Çetinkaya-Rundel and Hardin (2022)\n\nDen Autoren dieser Bücher gilt ein großer Dank für Ihren Beitrag zur -Community !"
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "Übung zur Vorlesung Statistik und Datenanalyse",
    "section": "Reproduzierbarkeit",
    "text": "Reproduzierbarkeit\nDieses Skript wurde in RStudio mit Quarto geschrieben und in R version 4.2.2 Patched (2022-11-10 r83330) gebaut. Folgende Pakete werden für die Beispiele und Übungen benötigt:\n\n\n\n\n\n\n\n\n\n\n\n\npackage\nversion\nsource\n\n\n\n\ndabestr\n0.3.0\nGithub (ACCLAB/dabestr@8775899f7eba743a6a32bd2fdab5f57e79401fd6)\n\n\nemojifont\n0.5.5\nCRAN (R 4.2.0)\n\n\nfontawesome\n0.3.0\nCRAN (R 4.2.1)\n\n\ngapminder\n0.3.0\nCRAN (R 4.2.2)\n\n\ninfer\n1.0.3\nCRAN (R 4.2.2)\n\n\nlubridate\n1.8.0\nCRAN (R 4.2.0)\n\n\nmoderndive\n0.5.3\nCRAN (R 4.2.0)\n\n\ntidyverse\n1.3.1\nCRAN (R 4.2.0)\n\n\n\n\nDie komplette Information zur Session lautet:\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.1 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3\nLAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3\n\nlocale:\n [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] rstudioapi_0.13   knitr_1.39        magrittr_2.0.3    R6_2.5.1         \n [5] rlang_1.0.6       fastmap_1.1.0     fansi_1.0.3       highr_0.9        \n [9] stringr_1.4.0     tools_4.2.2       xfun_0.31         sessioninfo_1.2.2\n[13] utf8_1.2.2        cli_3.4.1         ellipsis_0.3.2    htmltools_0.5.2  \n[17] yaml_2.3.5        digest_0.6.29     assertthat_0.2.1  rprojroot_2.0.3  \n[21] lifecycle_1.0.3   tibble_3.1.7      fontawesome_0.3.0 crayon_1.5.1     \n[25] purrr_0.3.4       vctrs_0.5.1       htmlwidgets_1.5.4 glue_1.6.2       \n[29] evaluate_0.15     rmarkdown_2.14    emo_0.0.0.9000    stringi_1.7.6    \n[33] pillar_1.7.0      compiler_4.2.2    desc_1.4.1        generics_0.1.2   \n[37] jsonlite_1.8.0    lubridate_1.8.0   pkgconfig_2.0.3  \n\n\n\nDieses Skript ist lizenziert unter Creative Commons Namensnennung - Nicht-kommerziell - Weitergabe unter gleichen Bedingungen 4.0 International.\n\n\n\n\nÇetinkaya-Rundel, Mine, and Johanna Hardin. 2022. Introduction to Modern Statistics. https://openintro-ims.netlify.app/.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for Data Analysis. 3rd, in progress.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "09-tests-infer.html#workflow-in-infer",
    "href": "09-tests-infer.html#workflow-in-infer",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.2 Workflow in infer",
    "text": "8.2 Workflow in infer\nDas Paket infer bietet ein einheitliches Framework für Hypothesentests (Figure 8.1). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen und ein Verb für die Visualisierung der Ergebnisse:\n\nspecify() Variablen festlegen\nhypothesize() Nullhypothese definieren\ngenerate() Daten unter der Nullhypothese generieren\ncalculate() Stichprobenverteilung (d.h. Verteilung der Teststatistik) berechnen\nvisualize() Stichprobenverteilung darstellen\n\nMit get_p_value kann man den \\(p\\)-Wert berechnen und mit shade_p_value diesen darstellen lassen.\n\n\n\nFigure 8.1: Allgemeines Vorgehen bei Hypothesentests (Quelle: https://infer.netlify.app/)."
  },
  {
    "objectID": "09-tests-infer.html#aufgaben",
    "href": "09-tests-infer.html#aufgaben",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.4 Aufgaben",
    "text": "8.4 Aufgaben\n\n8.4.1 Vertiefung des Themas Zufall und Variabilität\nArbeiten Sie das Tutorial Foundations of inference: 1 - Sampling Variability durch."
  },
  {
    "objectID": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "href": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.1 Studiendauer in Werdeschlau",
    "text": "8.1 Studiendauer in Werdeschlau\nWir beschäftigen uns mit einem fiktiven Beispiel.\nAn der (kleinen) Universität Werdeschlau möchte man wissen, ob die vor einiger Zeit eingeführte Studienordnung die Studiendauer verändert hat. Dazu werden 300 Studierende zufällig über die Dauer ihres Studiums befragt. Zusätzlich werden noch andere Daten erhoben, aber mit diesen beschäftigen wir uns in einer andern Übung.\n\n8.1.1 Simulation der Grundgesamtheit\nBei statistischer Inferenz geht es unter anderem darum, die Begriffe Zufall und Variabilität zu quantifizieren. Um diese Konzepte zu verstehen, helfen Computerexperimente. Dafür erstellen wir uns unsere eigene Grundgesamtheit aller Studierenden an der Universität Werdeschlau. Das hat den Vorteil, dass wir viele verschiedene Befragungen durchführen können, die Variabilität der Antworten analysieren und dabei immer mit den wahren Parametern der Grundgesamtheit vergleichen können.\nWir erstellen zunächst die Grundgesamtheit. Die Zeile set.seed(123) sorgt für reproduzierbare Ergebnisse.\n\nset.seed(123)\n\npop_size <- 12000\nstudent_id <- 1:pop_size\n  \nanreise <- c(runif(n = pop_size * 0.8, min = 5, max = 40),\n             runif(n = pop_size * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = pop_size, replace = TRUE)\n\nstudienordnung <- sample(c('alt', 'neu'), size = pop_size, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nstudiendauer <- rnorm(n = pop_size, mean = 3.5, sd = 0.6)\n\nWir setzen geschlecht, wohnort, studiendauer, studienordnung und anreise zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\ngrundgesamtheit <- tibble(geschlecht, wohnort, studiendauer, studienordnung, anreise)\n\n\n\n8.1.2 Befragung simulieren\nIn der Realität werden natürlich nicht alle 12000 Studierende befragt (wer hat schon so viele Kapazitäten?), sondern eine zufällige Stichprobe erhoben, also eine Teilmenge der Grundgesamtheit.\nUm unsere Stichprobe zu erstellen, ziehen wir 300 Studierende ohne Zurücklegen aus unserer Grundgesamtheit. Das entspricht einer einmaligen Befragung von 300 zufällig ausgewählten Studierenden.\n\nset.seed(345)\n\nbefragung_size <- 300\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nWir berechnen den Mittelwert der Studiendauer, jeweils für die alte und neue Studienordnung.\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nWie groß ist die Differenz der Mittelwerte?\n\nstat_obs$dauer[1] - stat_obs$dauer[2]\n\n[1] -0.1183631\n\n\nWie verändert sich die Differenz, wenn wir zufälligerweise andere Studierende befragt hätten? Wir wählen neue Studierende aus und wiederholen die Berechnung des Mittelwerts der Studiendauer.\n\nset.seed(987)\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nFür diese Gruppe der Befragten beträgt die Differenz der Mittelwerte 0.0323477."
  },
  {
    "objectID": "09-tests-infer.html#hypothesentest-durchführen",
    "href": "09-tests-infer.html#hypothesentest-durchführen",
    "title": "8  Hypothesentests mit Randomisierung",
    "section": "8.3 Hypothesentest durchführen",
    "text": "8.3 Hypothesentest durchführen\n\n8.3.1 Schritt 1: Nullhypothese und Alternativhypothese festlegen\nUnsere Forschungsfrage lautet: Hat sich die Studiendauer durch die Einführung der neuen Studienordnung verändert? Daraus ergeben sich folgende Hypothesen:\n\nNullhypothese H\\(_0\\): Die Studiendauer hat sich durch die Einführung der neuen Studienordnung nicht verändert. Sie ist gleich geblieben.\nAlternativhypothese H\\(_A\\): Die Studiendauer hat sich durch die Einführung der neuen Studienordnung verändert.\n\nDie Alternativhypothese ist unsere eigentliche Forschungsfrage. Da wir nicht wissen, in welche Richtung die Änderungen erfolgt sein könnte (Verlängerung oder Verkürzung der Studiendauer), formulieren wir eine sogenannte beidseitige Alternativhypothese. Beidseitig heißt, dass Änderungen in beide Richtungen interessant sind.\nWir berechnen zunächst die tatsächlich in den Daten (der Befragung) beobachtete Differenz zwischen den Studiendauern nach der alten und der neuen Studienordnung, also unsere Teststatistik. Die Differenz wird als alt \\(-\\) neu berechnet. Die Funktion observe() im Paket infer berechnet diese Teststatistik.\n\nd_hat <- befragung %>% \n  observe(formula = studiendauer ~ studienordnung,\n          stat = \"diff in means\", \n          order = c('alt', 'neu'))\n\nd_hat\n\n\n\n  \n\n\n\n\n\n8.3.2 Schritt 2: Simulationsexperimente durchführen\nUm Daten unter der Nullhypothese, d. h. wenn die Nullhypothese gilt, zu produzieren, permutieren wir 10000 Mal die Variable studienordnung. Denn, wenn die Studiendauer nicht von der Studienordnung abhängt, dann sind diese beiden Variablen unabhängig. Das legt die Zeile hypothesize(null = \"independence\") fest.\n\nnull_dist <- befragung %>%\n  specify(studiendauer ~ studienordnung) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 10000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c('alt', 'neu'))\n\n\n\n8.3.3 Schritt 3: Ergebnisse darstellen\nWir stellen die Verteilung der Teststatistiken unter der Nullhypothese als ein Histogramm dar und zeichnen zusätzlich ein, wo sich die beobachtete Teststatistik (d. h. der beobachtete Unterschied der Mittelwerte) befindet als vertikale rote Linie. Die schattierten Bereiche zeigen Teststatistiken aus den Permutationen, die so extrem oder noch extremer sind, als die beobachtete Teststatistik von 0.0323477. Da unsere Alternativhypothese lautet, dass sich die Studiendauer verändert hat, betrachten wir extreme Werte sowohl bei der Verlängerung als auch bei der Verkürzung der Studiendauer als Evidenz gegen die Nullhypothese und zugunsten der Alternativhypothese. Daher färben wird die Bereiche links und spiegelbildlich rechts der beobachteten Teststatistik ein.\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n\n\n\n8.3.4 Schritt 4: \\(p\\)-Wert berechnen und Schlussfolgerungen ziehen\nDer folgende Code berechnet den \\(p\\)-Wert. Der \\(p\\)-Wert gibt uns die Wahrscheinlichkeit an, eine Teststatistik (also die Differenz der Mittelwerte) so extrem oder noch extremer als 0.0323477 zu beobachten, wenn die Nullhypothese tatsächlich korrekt ist. In anderen Worten, wenn wir in infer Daten generieren unter der Nullhypothese (d. h. übereinstimmend mit der Nullhypothese), dann kommt eine Differenz von 0.0323477 oder noch größer und spiegelbildlich von -0.0323477 oder noch kleiner mit einer Wahrscheinlichkeit von \\(p\\) vor. Um den \\(p\\)-Wert zu berechnen, rechnen wir den Anteil der eingefärbten Bereiche aus.\n\nnull_dist %>%\n  get_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n  \n\n\n\nWir sehen also, dass Differenzen zwischen den Mittelwerten von 0.0323477 oder noch größer oder und spiegelbildlich von -0.0323477 oder noch kleiner in 63.18% der Fälle vorkommen, wenn die Nullhypothese gilt. So eine Differenz ist also nichts Besonderes. Unser Signifikanzniveau ist \\(\\alpha = 0.05\\). Da \\(p > \\alpha\\), behalten wir die Nullhypothese bei. Es gibt also keinen Unterschied in der Studiendauer zwischen der alten und der neuen Studienordnung."
  }
]