[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "",
    "text": "Vorwort\nIn dieser Veranstaltung werden wir folgende Werkzeuge verwenden:\nILIAS: die Online-Lernplattform der UzK. Sie sollten alle bereits registriert sein.\nCampuswire: die Chatplattform dient der allgemeinen Kommunikation und der Selbstorganisation des Lernens. Verwenden Sie diese, um Fragen mit Ihren Kommilitonen*innen und mir zu diskutieren. Sie sollten eine Einladungsmail zu Campuswire erhalten haben."
  },
  {
    "objectID": "01-einfuehrung.html",
    "href": "01-einfuehrung.html",
    "title": "1Â  Die Ãœbung",
    "section": "",
    "text": "Note\n\n\n\n\nDaten fÃ¼r Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchfÃ¼hren\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#lernziele-des-kurses",
    "href": "01-einfuehrung.html#lernziele-des-kurses",
    "title": "1Â  Der Kurs",
    "section": "Lernziele des Kurses",
    "text": "Lernziele des Kurses\n\n\n\n\n\n\nNote\n\n\n\n\nDaten fÃ¼r Analysen vorbereiten\nDaten einlesen und visualisieren\nCode und Dokumentation in R Markdown schreiben\neigene Funktionen schreiben\nreproduzierbare Datenanalysen durchfÃ¼hren\ngelernte Methoden auf einen neuen Datensatz anwenden\nErgebnisse reproduzierbar im Praktikumsbericht darstellen"
  },
  {
    "objectID": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "01-einfuehrung.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "1Â  Die Ãœbung",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPÃ¼nktlichkeit bei PrÃ¤senz- und Zoomsitzungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenÃ¼ber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen ğŸ˜„"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Ã‡etinkaya-Rundel, Mine, and Johanna Hardin. 2021. Introduction to\nModern Statistics. https://openintro-ims.netlify.app/.\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression.\nSpringer. http://link.springer.com/book/10.1007/978-3-642-01837-4.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. â€œR: A\nLanguage for Data Analysis and\nGraphics.â€ Journal of Computational and\nGraphical Statistics 5 (3): 299â€“314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive:\nStatistical Inference via Data Science.\nhttps://moderndive.com/.\n\n\nKnuth, D. E. 1984. â€œLiterate Programming.â€\nThe Computer Journal 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for\nData Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine Ã‡etinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science (2e). https://r4ds.hadley.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R\nMarkdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/.\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginnerâ€™s Guide to\nR. Springer."
  },
  {
    "objectID": "01-erste-schritte.html",
    "href": "01-erste-schritte.html",
    "title": "1Â  Erste Schritte in R",
    "section": "",
    "text": "â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.1 â”€â”€\n\n\nâœ” ggplot2 3.3.6     âœ” purrr   0.3.4\nâœ” tibble  3.1.7     âœ” dplyr   1.0.9\nâœ” tidyr   1.2.0     âœ” stringr 1.4.0\nâœ” readr   2.1.2     âœ” forcats 0.5.1\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\n\n\n\nAttache Paket: 'kableExtra'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "01-erste-schritte.html#was-ist",
    "href": "01-erste-schritte.html#was-ist",
    "title": "1Â  Erste Schritte in R",
    "section": "1.1 Was ist ?",
    "text": "1.1 Was ist ?\nR ist eine Programmiersprache fÃ¼r Datenanalyse und statistische Modellierung. Es ist frei verfÃ¼gbar (open source software) und neben Python einer der am meisten benutzten Programmiersprachen zur Datenanalyse und -visualisierung. R wurde von Ross Ihaka und Robert Gentleman 1996 verÃ¶ffentlicht (Ihaka and Gentleman 1996). Es gibt fÃ¼r R eine Vielzahl von Zusatzpaketen, die die FunktionalitÃ¤t und die EinsatzmÃ¶glichkeiten enorm erweitern.\nSie kÃ¶nnen R fÃ¼r Ihren Computer auf der offiziellen R-Seite https://www.r-project.org/ herunterladen und installieren. Eine kurze Anleitung finden Sie auf ILIAS, zusammen mit der Liste der Pakete, die wir in diesem Kurs benÃ¶tigen. ZusÃ¤tzlich kÃ¶nnen Sie sich hier ein Video zur Installation ansehen.\nAuf der offiziellen R-Seite finden Sie auch zusÃ¤tzliche Pakete, und zwar unter CRAN (The Comprehensive R Archive Network). Manche Pakete sind auf den CRAN-Seiten thematisch in sogen. CRAN Task Views gegliedert. FÃ¼r den Umweltbereich sind folgende Paketsammlungen besonders relevant:\n\nEnvironmetrics: Analyse von Umweltdaten\nMultivariate: Multivariate Statistik\nSpatial: Analyse von rÃ¤umlichen Daten\nTimeSeries: Zeitreihenanalyse\n\nZu Beginn des Kurses werden wir jedoch nicht auf Ihren lokalen Rechnern arbeiten, sondern auf den bereits eingerichteten Uni-Rechnern in den EDV-RÃ¤umen. Daher biete ich zu diesem frÃ¼hen Zeitpunkt im Kurs keine UnterstÃ¼tzung bei der Installation von R auf Ihren Privatrechnern. FÃ¼r die ganz Ungeduldigen gibt es hier eine kurze Einleitung zur Installation."
  },
  {
    "objectID": "01-erste-schritte.html#was-ist-rstudio",
    "href": "01-erste-schritte.html#was-ist-rstudio",
    "title": "1Â  Erste Schritte in R",
    "section": "1.2 Was ist RStudio?",
    "text": "1.2 Was ist RStudio?\nRStudio Desktop ist eine Entwicklungsumgebung fÃ¼r R. Wichtig: RStudio wird erst nach R installiert und ergibt ohne R keinen Sinn. Sie kÃ¶nnen die open source Version kostenlos fÃ¼r Ihren Rechner hier herunterladen, falls Sie sich entscheiden, (spÃ¤ter) R auf Ihrem Rechner zu installieren. Es gibt eine live EinfÃ¼hrung in RStudio im Kurs. ZusÃ¤tzlich kÃ¶nnen Sie hier ein Video dazu ansehen.\nDie OberflÃ¤che von RStudio ist in vier Bereiche unterteilt (AbbildungÂ 1.1).\n\n\n\nAbbildungÂ 1.1: Aufbau von RStudio\n\n\nSie sollten auch auf Ihrem eigenen Rechner einen Ordner fÃ¼r die Veranstaltung anlegen und darin jeweils einen Ordner fÃ¼r Folien, Daten und Notebooks."
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff",
    "href": "01-erste-schritte.html#lesestoff",
    "title": "1Â  Erste Schritte in R",
    "section": "1.3 Lesestoff",
    "text": "1.3 Lesestoff\nKapitel 1.1 und 1.2 in Ismay and Kim (2021)."
  },
  {
    "objectID": "01-erste-schritte.html#aufgaben",
    "href": "01-erste-schritte.html#aufgaben",
    "title": "1Â  Erste Schritte in R",
    "section": "1.4 Aufgaben",
    "text": "1.4 Aufgaben\n\nBitte speichern Sie Ihr Skript regelmÃ¤ÃŸig ab!\n\n\n1.4.1 R als Taschenrechner\nR ist ein groÃŸer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die Ã¼blichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie spÃ¤ter Daten in R einlesen mÃ¶chten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.4.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles MÃ¶gliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur VerfÃ¼gung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen kÃ¶nnen in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: Die linke Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erhÃ¤lt eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungÃ¼ltige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen kÃ¶nnen (fast) frei gewÃ¤hlt werden. Sie mÃ¼ssen mit einem Buchstaben beginnen und dÃ¼rfen keine Sonderzeichen enthalten. Bei lÃ¤ngeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.4.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie kÃ¶nnen im Ãœbrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden LÃ¤nge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHÃ¤ufig wollen wir fÃ¼r unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.4.4 Objekte ansprechen\nUm das â€œInnenlebenâ€ der Objekte in R anzusprechen, gibt es verschieden MÃ¶glichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren mÃ¶chte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir kÃ¶nnen auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen mÃ¼ssen in AnfÃ¼hrungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte AnfÃ¼hrungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.4.5 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat mÃ¶chte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst mÃ¶chte er sich einen Ãœberblick Ã¼ber seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\n\nArs Mensaausgaben\n \n  \n    Wochentag \n    Ausgaben (â‚¬) \n  \n \n\n  \n    Montag \n    2,57 \n  \n  \n    Dienstag \n    2,90 \n  \n  \n    Mittwoch \n    2,73 \n  \n  \n    Donnerstag \n    3,23 \n  \n  \n    Freitag \n    3,90 \n  \n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groÃŸ ist die Differenz zwischen dem hÃ¶chsten und dem niedrigsten Betrag?\nWie viel hÃ¤tte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hÃ¤tte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwÃ¤hlen!\n\nLeider hat Ar sich beim Ãœbertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 â‚¬ statt 2,90 â‚¬ ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verÃ¤ndern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.6 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\n\nArs Mensaausgaben, cont.\n \n  \n    Wochentag \n    Amount spent (â‚¬) \n  \n \n\n  \n    Montag, 9. MÃ¤rz \n    2,57 \n  \n  \n    Dienstag, 10. MÃ¤rz \n    2,90 \n  \n  \n    Mittwoch, 11. MÃ¤rz \n    2,73 \n  \n  \n    Donnerstag, 12. MÃ¤rz \n    3,23 \n  \n  \n    Freitag, 13. MÃ¤rz \n    3,90 \n  \n  \n    Montag, 16. MÃ¤rz \n    NA \n  \n\n\n\n\n\nWie Ã¤ndert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthÃ¤lt. Rufen Sie dazu die Hilfe auf, i.e.Â ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend.\n\n\n\n1.4.7 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nÃ¤mlich um echte DatensÃ¤tze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab('Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)') +\n  ylab('Lebenserwartung bei der Geburt (Jahre)') +\n  labs(title = 'Daten von Gapminder fÃ¼r das Jahr 2007')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e.Â ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die SymbolgrÃ¶ÃŸe dargestellt?\nWie wÃ¼rden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "href": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "title": "1Â  Erste Schritte in R",
    "section": "1.6 Ihre Arbeit einreichen",
    "text": "1.6 Ihre Arbeit einreichen\n\nSpeichern Sie Ihre .Rmd Datei ab.\nLaden Sie die Datei auf ILIAS in Ihrer Ãœbungsgruppe in der dazugehÃ¶rigen Ãœbung hoch.\nNach der Abgabe erhalten Sie die MusterlÃ¶sung.\nVergleichen Sie Ihre LÃ¶sung selbststÃ¤ndig mit der MusterlÃ¶sung.\nStellen Sie entweder in Campuswire (im #class-chat) oder in der nÃ¤chsten Sitzung Fragen, falls Sie bei den Aufgaben etwas nicht verstanden haben und die MusterlÃ¶sung es nicht aufklÃ¤ren konnte.\n\n\n\nBeachten Sie die Frist fÃ¼r das Hochladen der Hausaufgaben!"
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff-1",
    "href": "01-erste-schritte.html#lesestoff-1",
    "title": "1Â  Erste Schritte in R",
    "section": "1.6 Lesestoff",
    "text": "1.6 Lesestoff\nr4ds, Kapitel 4 (Wickham, Ã‡etinkaya-Rundel, and Grolemund 2023)\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. â€œR: A Language for Data Analysis and Graphics.â€ Journal of Computational and Graphical Statistics 5 (3): 299â€“314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley, Mine Ã‡etinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "02-rmarkdown.html",
    "href": "02-rmarkdown.html",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "",
    "text": "Wichtigkeit der Reproduzierbarkeit erklÃ¤ren\nBegriff literate programming definieren\nAufbau einer RMarkdown-Datei erklÃ¤ren\nEinen einfachen ersten reproduzierbaren Bericht selbst schreiben"
  },
  {
    "objectID": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "href": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist",
    "text": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation fÃ¼r dieses Thema empfehle ich das Video von Prof.Â Roger Peng der John Hopkins Bloogmerg School of Public Health."
  },
  {
    "objectID": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "href": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.2 Literate Programming Idee von Donald Knuth",
    "text": "2.2 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugehÃ¶rige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zurÃ¼ck. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erklÃ¤ren, was man den Computer machen lassen mÃ¶chte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verstÃ¤ndlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt fÃ¼r viele (unentdeckte und unnÃ¶tige) Fehler und Frust."
  },
  {
    "objectID": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "href": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.3 Reproduzierbare Berichte mit R Markdown",
    "text": "2.3 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und ermÃ¶glicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, PrÃ¤sentationsfolien usw.\nEs wird Sie vielleicht Ã¼berraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein â€œliterarischâ€ programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell fÃ¼r lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code ermÃ¶glichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endgÃ¼ltiges Dokument umgewandelt werden. Diesen Prozess nennt man knit."
  },
  {
    "objectID": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "href": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.4 Ein neues R Notebook erstellen",
    "text": "2.4 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine grÃ¼ne Plus oben links und wÃ¤hlen Sie R Notebook aus. Sie kÃ¶nnen es erst einmal bei untitled belassen (AbbildungÂ 2.1).\n\n\n\nAbbildungÂ 2.1: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enthÃ¤lt das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche TastenkÃ¼rzel und Tipps. Danach kÃ¶nnen Sie den Text unterhalb des Headers lÃ¶schen."
  },
  {
    "objectID": "02-rmarkdown.html#header",
    "href": "02-rmarkdown.html#header",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten mÃ¼ssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch EinrÃ¼ckungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterfÃ¼hrende Literatur). Wir bleiben bei einem einfachen Header ohne EinrÃ¼ckungen (Abbildung FigureÂ 2.2).\nUm einen neuen R-Chunk hinzuzufÃ¼gen, klicken Sie auf das kleine grÃ¼ne C+ oben rechts oder verwenden Sie das TastenkÃ¼rzel Str+Alt+i.\n\n\n\nFigure 2.2: Einen neuen R Chunk hinzufÃ¼gen\n\n\nText kann einfach unterhalb des Headers und auÃŸerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente fÃ¼r den Text finden Sie hier. R Markdown unterstÃ¼tzt mathematische Notation in Latex-Stil. Eine EinfÃ¼hrung in Latex wÃ¼rde an dieser Stelle aber zu weit fÃ¼hren.\nDas R Notebook hat den Vorteil, dass man Ã¼ber den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie mÃ¼ssen also nicht knitten. Falls Sie es doch mÃ¶chten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal â€œgeknittetesâ€ Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, mÃ¼ssen Sie im Header output: html_notebbok einstellen (Abbildung (fig:rmarkdown-file?))."
  },
  {
    "objectID": "02-rmarkdown.html#wichtigste-regeln-fÃ¼r-reproduzierbarkeit",
    "href": "02-rmarkdown.html#wichtigste-regeln-fÃ¼r-reproduzierbarkeit",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.6 Wichtigste Regeln fÃ¼r Reproduzierbarkeit",
    "text": "2.6 Wichtigste Regeln fÃ¼r Reproduzierbarkeit\nEin weiteres Video von Prof.Â Peng widmet sich den wichtigsten Regeln fÃ¼r Reproduzierbarkeit."
  },
  {
    "objectID": "02-rmarkdown.html#lesestoff",
    "href": "02-rmarkdown.html#lesestoff",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.7 Lesestoff",
    "text": "2.7 Lesestoff\nIntro zu Kapitel 2 (Basics), Kapitel 3.2.1 und 3.2.2 in Xie, Allaire, and Grolemund (2021)"
  },
  {
    "objectID": "02-rmarkdown.html#weiterfÃ¼hrende-literatur",
    "href": "02-rmarkdown.html#weiterfÃ¼hrende-literatur",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.8 WeiterfÃ¼hrende Literatur",
    "text": "2.8 WeiterfÃ¼hrende Literatur\nr4ds, Kapitel 27 (Wickham, Ã‡etinkaya-Rundel, and Grolemund 2023)"
  },
  {
    "objectID": "02-rmarkdown.html#aufgaben",
    "href": "02-rmarkdown.html#aufgaben",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.8 Aufgaben",
    "text": "2.8 Aufgaben\n\n2.8.1 Layoutelemente in R Markdown\nFÃ¼gen Sie in Ihrem Notebook Layoutelemente hinzu: - Ãœberschrift - UnterÃ¼berschrift - kursiver Text - ein Exponent: R2 - ein Mathematikelement: \\(x^2\\) - eine Liste\nNutzen Sie die unter KapitelÂ 2.5 verlinkte Liste der Layoutelemente.\n\n\n2.8.2 Editierene Sie Ihr erstes Notebook\n\nEditieren Sie das R Notebook der ersten Session.\nGliedern Sie Ihr Notebook mit passenden Layoutelementen, wenn noch nicht geschehen.\nFÃ¼gen Sie mehr ErklÃ¤rungstext zu den einzelnen Abschnitten.\n\n\n\n2.8.3 Hausaufgabe\nSchlieÃŸen Sie den Kurs â€œIntroduction to Râ€ auf datacamp ab.\n\n\n\n\nKnuth, D. E. 1984. â€œLiterate Programming.â€ The Computer Journal 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "01-erste-schritte.html#gemeinsame-aufgaben",
    "href": "01-erste-schritte.html#gemeinsame-aufgaben",
    "title": "1Â  Erste Schritte in R",
    "section": "1.4 Gemeinsame Aufgaben",
    "text": "1.4 Gemeinsame Aufgaben\n\nBitte speichern Sie Ihr Skript regelmÃ¤ÃŸig ab!\n\n\n1.4.1 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat mÃ¶chte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst mÃ¶chte er sich einen Ãœberblick Ã¼ber seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\nArs Mensaausgaben\n\n\nWochentag\nAusgaben (â‚¬)\n\n\n\n\nMontag\n2,57\n\n\nDienstag\n2,90\n\n\nMittwoch\n2,73\n\n\nDonnerstag\n3,23\n\n\nFreitag\n3,90\n\n\n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie groÃŸ ist die Differenz zwischen dem hÃ¶chsten und dem niedrigsten Betrag?\nWie viel hÃ¤tte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt hÃ¤tte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuwÃ¤hlen!\n\nLeider hat sich Ar beim Ãœbertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 â‚¬ statt 2,90 â‚¬ ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie verÃ¤ndern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.2 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen, die Ausgaben zu notieren.\n\n\nArs Mensaausgaben, cont.\n\n\nWochentag\nAmount spent (â‚¬)\n\n\n\n\nMontag, 9. MÃ¤rz\n2,57\n\n\nDienstag, 10. MÃ¤rz\n2,90\n\n\nMittwoch, 11. MÃ¤rz\n2,73\n\n\nDonnerstag, 12. MÃ¤rz\n3,23\n\n\nFreitag, 13. MÃ¤rz\n3,90\n\n\nMontag, 16. MÃ¤rz\nNA\n\n\n\n\n\n\n\nWie Ã¤ndert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enthÃ¤lt. Rufen Sie dazu die Hilfe auf, i.e.Â ?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend."
  },
  {
    "objectID": "01-erste-schritte.html#hausaufgaben",
    "href": "01-erste-schritte.html#hausaufgaben",
    "title": "1Â  Erste Schritte in R",
    "section": "1.5 Hausaufgaben",
    "text": "1.5 Hausaufgaben\n\n1.5.1 R als Taschenrechner\nR ist ein groÃŸer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die Ã¼blichen Rechenregeln wie z. B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert.\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie spÃ¤ter Daten in R einlesen mÃ¶chten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.5.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles MÃ¶gliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur VerfÃ¼gung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen kÃ¶nnen in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings die Pfeilrichtung entscheidend! x <- 42 bedeutet: Die rechte Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, ergibt die Zuweisung keinen Sinn und man erhÃ¤lt eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ungÃ¼ltige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen kÃ¶nnen (fast) frei gewÃ¤hlt werden. Sie mÃ¼ssen mit einem Buchstaben beginnen und dÃ¼rfen keine Sonderzeichen enthalten. Bei lÃ¤ngeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z. B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.5.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z. B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die Summe von my_a.\n\nSie kÃ¶nnen im Ãœbrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden LÃ¤nge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nHÃ¤ufig wollen wir fÃ¼r unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.5.4 Objekte ansprechen\nUm das â€œInnenlebenâ€ der Objekte in R anzusprechen, gibt es verschiedene MÃ¶glichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z. B. die dritte Komponente extrahieren mÃ¶chte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir kÃ¶nnen auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen mÃ¼ssen in AnfÃ¼hrungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte AnfÃ¼hrungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.5.5 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, nÃ¤mlich um echte DatensÃ¤tze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)', \n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       title = 'Daten von Gapminder fÃ¼r das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i. e. ?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die SymbolgrÃ¶ÃŸe dargestellt?\nWie wÃ¼rden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. â€œR: A Language for Data Analysis and Graphics.â€ Journal of Computational and Graphical Statistics 5 (3): 299â€“314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "02-rmarkdown.html#sec-header",
    "href": "02-rmarkdown.html#sec-header",
    "title": "2Â  R Markdown fÃ¼r reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten mÃ¼ssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch EinrÃ¼ckungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterfÃ¼hrende Literatur). Wir bleiben bei einem einfachen Header ohne EinrÃ¼ckungen (AbbildungÂ 2.2).\nUm einen neuen R-Chunk hinzuzufÃ¼gen, klicken Sie auf das kleine grÃ¼ne C+ oben rechts oder verwenden Sie das TastenkÃ¼rzel Str+Alt+i.\n\n\n\nAbbildungÂ 2.2: Einen neuen R Chunk hinzufÃ¼gen\n\n\nText kann einfach unterhalb des Headers und auÃŸerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente fÃ¼r den Text finden Sie hier. R Markdown unterstÃ¼tzt mathematische Notation in Latex-Stil. Eine EinfÃ¼hrung in Latex wÃ¼rde an dieser Stelle aber zu weit fÃ¼hren.\nDas R Notebook hat den Vorteil, dass man Ã¼ber den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie mÃ¼ssen also nicht knitten. Falls Sie es doch mÃ¶chten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal â€œgeknittetesâ€ Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, mÃ¼ssen Sie im Header output: html_notebbok einstellen (AbbildungÂ 2.2)."
  },
  {
    "objectID": "20-aufgabensammlung.html",
    "href": "20-aufgabensammlung.html",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele VÃ¶gel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFÃ¼hren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "03-ggplot.html",
    "href": "03-ggplot.html",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "",
    "text": "Aufbau des Aufrufs der Funktion ggplot() kennen\nfÃ¼nf wichtigste Grafiktypen kennen und einsetzten"
  },
  {
    "objectID": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "href": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.1 Aufbau eines Darstellungsbefehls",
    "text": "3.1 Aufbau eines Darstellungsbefehls\nDas Paket ggplot2 ist ein sehr mÃ¤chtiges Visualisierungswerkzeug. Der Name steht fÃ¼r â€œthe grammar of graphicsâ€. Das bedeutet, dass man mithilfe von verschiedenen Funktionen in ggplot2 seine Grafik Schritt fÃ¼r Schritt aufbaut, wie einen (grammatikalisch korrekten) Satz. In aller KÃ¼rze bedeutet das:\n\nEine statistische Grafik ist eine Zuordnung (mapping) von Variablen in einem Datensatz (data) zu (Ã¤sthetischen) Attributen (aes) von geometrischen Objekten (geom).\n\nWir mÃ¼ssen also fÃ¼r die Darstellung von Daten R Folgendes mitteilen:\n\ndata: der Datensatz, der die Variablen enthÃ¤lt, die wir darstellen mÃ¶chten.\naes: (Ã¤sthetische) Attribute fÃ¼r die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z. B. die \\(x\\)- und \\(y\\)-Koordinaten, Farbe, Form und GrÃ¶ÃŸe der geometrischen Objekte.\ngeom: geometrische Objekte, die dargestellt werden sollen, z. B. Punkte, Linien, Boxen, Balken/SÃ¤ulen etc.\n\nWir laden zunÃ¤chst die nÃ¶tigen Bibliotheken.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nAnschlieÃŸend filtern wir den Datensatz gapminder, um nur die Daten aus dem Jahr 2007 zu behalten. Der Code filter(year == 2007) bedeutet, dass wir nur die Zeilen aus dem Datensatz behalten wollen, in denen in der Variable year 2007 steht.\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nWir Ã¼berzeugen uns davon, dass es geklappt hat ğŸ˜„. BlÃ¤ttern Sie durch den Datensatz und Ã¼berprÃ¼fen Sie die Werte in der Variablen year.\n\ngapminder2007"
  },
  {
    "objectID": "03-ggplot.html#punktdiagramm",
    "href": "03-ggplot.html#punktdiagramm",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.2 Punktdiagramm",
    "text": "3.2 Punktdiagramm\nEin typischer Befehl zur Visualisierung wÃ¼rde also so aussehen:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n{width== â€œ90%â€}\n\n\nIn Worten kÃ¶nnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap\nauf die y-Achse die Variable lifeExp\nfÃ¤rbe ein mithilfe der Variablen continent\nbestimme die GrÃ¶ÃŸe der Symbole mithilfe der Variablen pop\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl fÃ¼r die Farbe als auch fÃ¼r die GrÃ¶ÃŸe der Symbole, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z.B. sind die Beschriftungen der beiden Achsen so nichtssagend und mÃ¼ssen verbessert werden. Wir hÃ¤ngen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Kopf (US$)', y = 'Lebenserwartung (Jahre)',\n       color = 'Kontinent', size = 'BevÃ¶lkerung')\n\n{width== â€œ90%â€}"
  },
  {
    "objectID": "03-ggplot.html#weitere-geoms",
    "href": "03-ggplot.html#weitere-geoms",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.3 Weitere geoms",
    "text": "3.3 Weitere geoms\nDas geom_point() produziert ein Streudiagramm, auch XY-Diagramm (scatter plot). Weiter wichtige Grafiktypen sind:\n\ngeom_line(): Linien\ngeom_bar(): Balken"
  },
  {
    "objectID": "03-ggplot.html#scatter",
    "href": "03-ggplot.html#scatter",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms wÃ¼rde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten kÃ¶nnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfÃ¤rbe ein mithilfe der Variablen continent (Kontinent)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl fÃ¼r die Farbe continent als auch fÃ¼r die GrÃ¶ÃŸe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und mÃ¼ssen verbessert werden. Wir hÃ¤ngen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder fÃ¼r das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#histogramm",
    "href": "03-ggplot.html#histogramm",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.5 Histogramm",
    "text": "3.5 Histogramm\nWie ist das GDP im Jahre 2007 in Afrika und Europa verteilt? Dazu nutzen wir das Histogramm und filtern die Daten vorher entsprechend. Als Ã„sthetik eignet sich hier fill besser als color.\n\nafrica_europe <- gapminder2007 %>% \n  filter(continent %in% c('Africa', 'Europe'))\n\nggplot(africa_europe, mapping = aes(x = gdpPercap, fill = continent)) +\n  geom_histogram(bins = 20)"
  },
  {
    "objectID": "03-ggplot.html#boxplot",
    "href": "03-ggplot.html#boxplot",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.6 Boxplot",
    "text": "3.6 Boxplot\nWie ist das GDP im Jahre 2007 auf verschiedenen Kontinenten verteilt? Ein Histogramm mit allen Kontinenten wÃ¼rde schnell sehr unÃ¼bersichtlich werden. Das geht mit einem Boxplot besser.\n\nggplot(gapminder2007, mapping = aes(x = continent, y = gdpPercap)) +\n  geom_boxplot()"
  },
  {
    "objectID": "03-ggplot.html#sÃ¤ulendiagramm",
    "href": "03-ggplot.html#sÃ¤ulendiagramm",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.5 SÃ¤ulendiagramm",
    "text": "3.5 SÃ¤ulendiagramm\nWie viele EintrÃ¤ge gibt es pro Kontinent? Das SÃ¤ulendiagramm zÃ¤hlt fÃ¼r uns die EintrÃ¤ge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine HÃ¤ufigkeitstabelle enthalten wÃ¼rde.\n\nggplot(data = gapminder, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "03-ggplot.html#lesestoff",
    "href": "03-ggplot.html#lesestoff",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.6 Lesestoff",
    "text": "3.6 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "03-ggplot.html#aufgaben",
    "href": "03-ggplot.html#aufgaben",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.7 Aufgaben",
    "text": "3.7 Aufgaben\n\n3.7.1 Darstellung von groÃŸen Zahlen\nWir verÃ¤ndern die Grafik aus KapitelÂ 3.2 so, dass die Symbole nach der GrÃ¶ÃŸe der Einwohnerzahl skaliert werden. Dazu benutzen wir ein neues Argument in der Funktion aes(size = pop):\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder fÃ¼r das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\n\n\nDie Einwohnerzahlen sind sehr groÃŸ. Daher stellt R sie in der sogen. wissenschaftlichen Notation dar. Dabei steht z. B. e+08 fÃ¼r \\(10^8\\). Das heiÃŸt 2.5e+08 sind 250000000 Einwohner.\nBeschriften Sie die Legende fÃ¼r die GrÃ¶ÃŸe der Symbole richtig, indem Sie size = 'Einwohnerzahl' in der Funktion labs() hinzufÃ¼gen.\n\n\n3.7.2 Grafiken richtig beschriften\nBis auf die Grafik in KapitelÂ 3.4 fehlen bei den Grafiken oben ordentliche Achsenbeschriftungen und Titel fÃ¼r die Legenden. ErgÃ¤nzen Sie den Code entsprechend."
  },
  {
    "objectID": "03-ggplot.html#ihre-arbeit-einreichen",
    "href": "03-ggplot.html#ihre-arbeit-einreichen",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.8 Ihre Arbeit einreichen",
    "text": "3.8 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "03-ggplot.html#streudiagramm",
    "href": "03-ggplot.html#streudiagramm",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms wÃ¼rde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point()\n\n\n\n\nIn Worten kÃ¶nnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz (data) gapminder und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (Lebenserwartung)\nfÃ¤rbe ein mithilfe der Variablen continent (Kontinent)\nbestimme die GrÃ¶ÃŸe der Symbole mithilfe der Variablen pop (Einwohnerzahl)\n\nStelle das Ganze als geometrisches Objekte Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch, sowohl fÃ¼r die Farbe continent als auch fÃ¼r die GrÃ¶ÃŸe der Symbole pop, erstellt wird.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichts sagend und mÃ¼ssen verbessert werden. Wir hÃ¤ngen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       size = 'Einwohnerzahl',\n       title = 'Daten von Gapminder fÃ¼r das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#line",
    "href": "03-ggplot.html#line",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen fÃ¼r Frankreich und Deutschland heraus. Weil wir jetzt zwei LÃ¤nder haben mÃ¶chten, muss beim Filtern ein Vektor mit LÃ¤ndernamen angegeben werden und statt == der Operator %in%. Wir werden spÃ¤ter noch ausfÃ¼hrlich auf diese Operatoren zurÃ¼ckkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "03-ggplot.html#sec-scatter",
    "href": "03-ggplot.html#sec-scatter",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.2 Streudiagramm",
    "text": "3.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms wÃ¼rde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()\n\n\n\n\nIn Worten kÃ¶nnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz gapminder2007 (data = gapminder2007) und\nOrdne folgende Attribute zu:\n\nauf die \\(x\\)-Achse die Variable gdpPercap (x = gdpPercap) (Bruttoinlandsprodukt)\nauf die \\(y\\)-Achse die Variable lifeExp (y = lifeExp) (Lebenserwartung)\nfÃ¤rbe ein mithilfe der Variablen continent (color = continent).\n\nStelle das Ganze als geometrisches Objekt Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch erstellt wird. Merke: color innerhalb der Funktion aes() erstellt die Legende automatisch.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichtssagend und mÃ¼ssen verbessert werden. Wir hÃ¤ngen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder fÃ¼r das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#sec-line",
    "href": "03-ggplot.html#sec-line",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.4 Liniendiagramm",
    "text": "3.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen fÃ¼r Frankreich und Deutschland heraus. Weil wir jetzt zwei LÃ¤nder haben mÃ¶chten, muss beim Filtern ein Vektor mit LÃ¤ndernamen angegeben werden und statt == der Operator %in%. Wir werden spÃ¤ter noch ausfÃ¼hrlich auf diese Operatoren zurÃ¼ckkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()"
  },
  {
    "objectID": "20-aufgabensammlung.html#einfÃ¼hrung-in-die-darstellung-von-daten",
    "href": "20-aufgabensammlung.html#einfÃ¼hrung-in-die-darstellung-von-daten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.2 EinfÃ¼hrung in die Darstellung von Daten",
    "text": "A.2 EinfÃ¼hrung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen FlossenlÃ¤nge flipper_length_mm auf der \\(x\\)-Achse und der Variablen KÃ¶rpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFÃ¤rben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung ğŸ¤“."
  },
  {
    "objectID": "03-ggplot.html#balkendiagramm",
    "href": "03-ggplot.html#balkendiagramm",
    "title": "3Â  EinfÃ¼hrung in die Darstellung von Daten",
    "section": "3.5 Balkendiagramm",
    "text": "3.5 Balkendiagramm\nWie viele LÃ¤nder gibt es pro Kontinent im Jahr 2007? Das Balkendiagramm zÃ¤hlt fÃ¼r uns die EintrÃ¤ge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine HÃ¤ufigkeitstabelle enthalten wÃ¼rde.\n\nggplot(data = gapminder2007, \n       mapping = aes(x = continent)) +\n  geom_bar()"
  },
  {
    "objectID": "04-einlesen.html",
    "href": "04-einlesen.html",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "",
    "text": "Daten aus Textdateien in R einlesen\nDie $-Notation\nAnsprechen eines Eintrags im tibble\nDaten als Textdateien aus R speichern"
  },
  {
    "objectID": "04-einlesen.html#lesestoff",
    "href": "04-einlesen.html#lesestoff",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.6 Lesestoff",
    "text": "4.6 Lesestoff\nKapitel 4.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "04-einlesen.html#aufgaben",
    "href": "04-einlesen.html#aufgaben",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.7 Aufgaben",
    "text": "4.7 Aufgaben"
  },
  {
    "objectID": "04-einlesen.html#ihre-arbeit-einreichen",
    "href": "04-einlesen.html#ihre-arbeit-einreichen",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.10 Ihre Arbeit einreichen",
    "text": "4.10 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "05-explorative-kategorial.html",
    "href": "05-explorative-kategorial.html",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "",
    "text": "Den Pipe-Operator %>%nutzen\nKategoriale Variablen in Faktor umwandeln\nKategoriale Variablen darstellen\nNeue Variablen mit mutate() erstellen\nHÃ¤ufigkeits- und Kontingenztabellen erstellen"
  },
  {
    "objectID": "05-explorative-kategorial.html#lesestoff",
    "href": "05-explorative-kategorial.html#lesestoff",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "5.2 Lesestoff",
    "text": "5.2 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "05-explorative-kategorial.html#aufgaben",
    "href": "05-explorative-kategorial.html#aufgaben",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "5.3 Aufgaben",
    "text": "5.3 Aufgaben\n\n5.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus KapitelÂ 5.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n5.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ã„ndern Sie die finale Grafik in KapitelÂ 5.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie Ã¤ndert sich die Position der LÃ¤ndernamen?\n\n\n\n5.3.3 Tutorium\nBearbeiten Sie das Tutorium â€œExplorative Datenanalyse: 1 - Erkundung kategorischer Datenâ€. Sie kÃ¶nnen entweder die deutsche Ãœbersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "href": "05-explorative-kategorial.html#ihre-arbeit-einreichen",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "5.4 Ihre Arbeit einreichen",
    "text": "5.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "href": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.1 Daten aus Textdateien in R einlesen",
    "text": "4.1 Daten aus Textdateien in R einlesen\nUm Daten aus Textdateien (z.B. aus .csv, .txt, .dat) in R zu importieren (i.e.Â einzulesen) werden wir die Bibliothek readr aus tidyverse benutzen. Wir laden erst einmal tidyverse.\n\nlibrary(tidyverse)\n\nWir gehen davon aus, dass die Daten im Ordner Daten gespeichert sind. Falls Ihre Daten an einem anderen Ort abgelegt sind, mÃ¼ssen Sie den Pfad beim Einlesen entsprechend anpassen.\nUm die Daten zu laden, gibt es in der Bibliothek readr verschiedene Funktionen, die alle mit read_ beginnen. Die allgemeinste davon ist read_delim. Darin kann man explizit einstellen, mit welchem Zeichen (z. B. Komma, Strichpunkt etc.) die einzelnen Spalten in der zu importierenden Datei getrennt sind. In der Datei, die wir einlesen, ist das Trennungszeichen ;. Das mÃ¼ssen Sie aber bei jeder Datei, die Sie einlesen, nachsehen.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2023-10-08.csv', delim = ';')\n\nRows: 76 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEin kurzer Blick auf den Datensatz, den Sie aus der ersten Sitzung der Vorlesung erkennen sollten ğŸ˜„. Es sind die Daten zur MobilitÃ¤t in Europa aus eurostat, heruntergeladen am 08.10.2023 und vorgefiltert. Die Daten beinhalten die Anzhal der â€œPersonenkraftwagen je 1 000 Einwohnerâ€, online Datencode: ROAD_EQS_CARHAB.\n\ncar_numbers\n\n\n\n  \n\n\n\nDas Ergebnis des Einlesens mit read_ Funktionen ist immer ein tibble."
  },
  {
    "objectID": "04-einlesen.html#einzlene-variablen-ansprechen",
    "href": "04-einlesen.html#einzlene-variablen-ansprechen",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzlene Variablen ansprechen",
    "text": "4.2 Einzlene Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen Nutzen, um die Variable anzusprechen. Z. B. kÃ¶nnten wir die Variable geo so ansprechen:\n\ncars$geo\n\n [1] \"Albania\"         \"Albania\"         \"Austria\"         \"Austria\"        \n [5] \"Belgium\"         \"Belgium\"         \"Bulgaria\"        \"Bulgaria\"       \n [9] \"Croatia\"         \"Croatia\"         \"Cyprus\"          \"Cyprus\"         \n[13] \"Czechia\"         \"Czechia\"         \"Denmark\"         \"Denmark\"        \n[17] \"Estonia\"         \"Estonia\"         \"Finland\"         \"Finland\"        \n[21] \"France\"          \"France\"          \"Germany\"         \"Germany\"        \n[25] \"Greece\"          \"Greece\"          \"Hungary\"         \"Hungary\"        \n[29] \"Iceland\"         \"Iceland\"         \"Ireland\"         \"Ireland\"        \n[33] \"Italy\"           \"Italy\"           \"Kosovo\"          \"Kosovo\"         \n[37] \"Latvia\"          \"Latvia\"          \"Liechtenstein\"   \"Liechtenstein\"  \n[41] \"Lithuania\"       \"Lithuania\"       \"Luxembourg\"      \"Luxembourg\"     \n[45] \"Malta\"           \"Malta\"           \"Montenegro\"      \"Montenegro\"     \n[49] \"Netherlands\"     \"Netherlands\"     \"North Macedonia\" \"North Macedonia\"\n[53] \"Norway\"          \"Norway\"          \"Poland\"          \"Poland\"         \n[57] \"Portugal\"        \"Portugal\"        \"Romania\"         \"Romania\"        \n[61] \"Serbia\"          \"Serbia\"          \"Slovakia\"        \"Slovakia\"       \n[65] \"Slovenia\"        \"Slovenia\"        \"Spain\"           \"Spain\"          \n[69] \"Sweden\"          \"Sweden\"          \"Switzerland\"     \"Switzerland\"    \n[73] \"TÃ¼rkiye\"         \"TÃ¼rkiye\"         \"United Kingdom\"  \"United Kingdom\" \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 EintrÃ¤ge (LÃ¤nder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-mehrere-spalten-in-einem-tibble",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen mehrere Spalten in einem tibble",
    "text": "4.3 Ansprechen mehrere Spalten in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nÃ¤mlich zwei Indizes: einen Index fÃ¼r die Zeile und einen Index fÃ¼r die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Ã–sterreich. Wir kÃ¶nnen auch ganze Spalten (Variablen) ansprechen. DafÃ¼r wird der erste Index (fÃ¼r Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle EintrÃ¤ge gemeint sind. So kÃ¶nnen wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es Ã¤hnlich. Wir lassen den Index fÃ¼r die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurÃ¼ck. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "04-einlesen.html#ein-tibble-erstellen",
    "href": "04-einlesen.html#ein-tibble-erstellen",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.4 Ein tibble erstellen",
    "text": "4.4 Ein tibble erstellen\nUm ein tibble zu erstellen, nutzen wir die Funktion tibble() und zÃ¤hlen auf, welche Variablen wir dort haben mÃ¶chten.\n\ncar_numbers_short <- tibble(Land = car_numbers$geo, Zeit = car_numbers$time)\n\nIn dem Datensatz car_numbers_short haben wir jetzt die beiden Variablen geo und time aus dem Datensatz car_numbers als tibble abgespeichert."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-r-speichern",
    "href": "04-einlesen.html#daten-aus-r-speichern",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.5 Daten aus R speichern",
    "text": "4.5 Daten aus R speichern\nWir speichern dieses tibble als Textdatei. DafÃ¼r nutzen wir die Funktion write_delim(), die ebenfalls in der Bibliothek readr in tidyverse vorhanden ist. Achten Sie darauf, dass write_delim() nur tibble speichern kann. Wenn Sie einen Vektor (eine einzelne Variable) abspeichern mÃ¶chten, dann wandeln Sie diesen zuerst in ein tibble um.\n\nwrite_delim(x = car_numbers_short, file = 'Daten/geo.csv', delim = ';')"
  },
  {
    "objectID": "05-explorative-kategorial.html#mobilitÃ¤t-in-europa",
    "href": "05-explorative-kategorial.html#mobilitÃ¤t-in-europa",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "5.1 MobilitÃ¤t in Europa",
    "text": "5.1 MobilitÃ¤t in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. ZunÃ¤chst laden wir wie immer die nÃ¶tigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2023-10-08.csv', delim = ';')\n\n\n5.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen kÃ¶nnen, welche verschiedenen MerkmalsausprÃ¤gungen die Variable enthÃ¤lt. Zur Erinnerung: MerkmalsausprÃ¤gungen sind die theoretisch mÃ¶glichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsÃ¤chlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse fÃ¼r eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen MerkmalsausprÃ¤gungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heiÃŸt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Ãœbergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben kÃ¶nnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unÃ¼bersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schÃ¶n strukturiert, wird er hÃ¤ufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verÃ¤ndern oder lÃ¶schen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhÃ¤lt man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fÃ¼gt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun kÃ¶nnen wir R auch fragen, welche verschiedenen MerkmalsausprÃ¤gungen (levels) diese Variable enthÃ¤lt:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"                \"Austria\"                \"Belgium\"               \n [4] \"Bosnia and Herzegovina\" \"Bulgaria\"               \"Croatia\"               \n [7] \"Cyprus\"                 \"Czechia\"                \"Denmark\"               \n[10] \"Estonia\"                \"Finland\"                \"France\"                \n[13] \"Germany\"                \"Greece\"                 \"Hungary\"               \n[16] \"Iceland\"                \"Ireland\"                \"Italy\"                 \n[19] \"Kosovo\"                 \"Latvia\"                 \"Liechtenstein\"         \n[22] \"Lithuania\"              \"Luxembourg\"             \"Malta\"                 \n[25] \"Montenegro\"             \"Netherlands\"            \"North Macedonia\"       \n[28] \"Norway\"                 \"Poland\"                 \"Portugal\"              \n[31] \"Romania\"                \"Slovakia\"               \"Slovenia\"              \n[34] \"Spain\"                  \"Sweden\"                 \"Switzerland\"           \n[37] \"TÃ¼rkiye\"                \"United Kingdom\"        \n\n\nDie einzelnen MerkmalsausprÃ¤gungen sind die verschiedenen LÃ¤nder. Der Datensatz enthÃ¤lt 38 unterschiedliche LÃ¤nder.\n\n\n5.1.2 Balkendiagramm mit geom_col()\nWir mÃ¶chten die Daten als Balkendiagramm darstellen. Das Ziel ist eine Ã¤hnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafÃ¼r mÃ¼ssen wir zuerst eine neue Variable erstellen, die wir zum EinfÃ¤rben der Jahre nutzen kÃ¶nnen. Dazu benÃ¶tigen wir eine zusÃ¤tzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heiÃŸt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum EinfÃ¤rben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern Ã¼berschreibt (verÃ¤ndert) die vorhandene Variable time_year. Das ist mÃ¶glich und gÃ¤ngige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im KapitelÂ 3 haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der EintrÃ¤ge in einer Variablen auszÃ¤hlen und diese als Balkendiagramm darstellen. Das mÃ¶chten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht fÃ¼r columns, also SÃ¤ulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nÃ¶tig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmÃ¤ÃŸig ein Stapelbalkendiagramm darstellt (stacked bar plot ). MÃ¶chte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie LÃ¤ndernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall Ã¼berdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehÃ¤ngt wird. Sie heiÃŸt theme(). Der Parameter, der fÃ¼r die Gestaltung der \\(x\\)-Achse zustÃ¤ndig ist, heiÃŸt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen LÃ¤nder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))"
  },
  {
    "objectID": "04-einlesen.html#eine-grafik-speichern",
    "href": "04-einlesen.html#eine-grafik-speichern",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.6 Eine Grafik speichern",
    "text": "4.6 Eine Grafik speichern"
  },
  {
    "objectID": "04-einlesen.html#einzelne-variablen-ansprechen",
    "href": "04-einlesen.html#einzelne-variablen-ansprechen",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.2 Einzelne Variablen ansprechen",
    "text": "4.2 Einzelne Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen nutzen, um die Variable anzusprechen. Z. B. kÃ¶nnten wir die Variable geo so ansprechen:\n\ncar_numbers$geo\n\n [1] \"Albania\"                \"Albania\"                \"Austria\"               \n [4] \"Austria\"                \"Belgium\"                \"Belgium\"               \n [7] \"Bosnia and Herzegovina\" \"Bosnia and Herzegovina\" \"Bulgaria\"              \n[10] \"Bulgaria\"               \"Croatia\"                \"Croatia\"               \n[13] \"Cyprus\"                 \"Cyprus\"                 \"Czechia\"               \n[16] \"Czechia\"                \"Denmark\"                \"Denmark\"               \n[19] \"Estonia\"                \"Estonia\"                \"Finland\"               \n[22] \"Finland\"                \"France\"                 \"France\"                \n[25] \"Germany\"                \"Germany\"                \"Greece\"                \n[28] \"Greece\"                 \"Hungary\"                \"Hungary\"               \n[31] \"Iceland\"                \"Iceland\"                \"Ireland\"               \n[34] \"Ireland\"                \"Italy\"                  \"Italy\"                 \n[37] \"Kosovo\"                 \"Kosovo\"                 \"Latvia\"                \n[40] \"Latvia\"                 \"Liechtenstein\"          \"Liechtenstein\"         \n[43] \"Lithuania\"              \"Lithuania\"              \"Luxembourg\"            \n[46] \"Luxembourg\"             \"Malta\"                  \"Malta\"                 \n[49] \"Montenegro\"             \"Montenegro\"             \"Netherlands\"           \n[52] \"Netherlands\"            \"North Macedonia\"        \"North Macedonia\"       \n[55] \"Norway\"                 \"Norway\"                 \"Poland\"                \n[58] \"Poland\"                 \"Portugal\"               \"Portugal\"              \n[61] \"Romania\"                \"Romania\"                \"Slovakia\"              \n[64] \"Slovakia\"               \"Slovenia\"               \"Slovenia\"              \n[67] \"Spain\"                  \"Spain\"                  \"Sweden\"                \n[70] \"Sweden\"                 \"Switzerland\"            \"Switzerland\"           \n[73] \"TÃ¼rkiye\"                \"TÃ¼rkiye\"                \"United Kingdom\"        \n[76] \"United Kingdom\"        \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 EintrÃ¤ge (LÃ¤nder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "href": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.8 Die Umfrage aus der ersten Sitzung",
    "text": "4.8 Die Umfrage aus der ersten Sitzung\nLesen Sie die Datei â€˜Umfrage_2023_kurz.csvâ€™ ein (sie ist auf ILIAS zu finden). Sie enthÃ¤lt die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage â€˜Haben Sie schon mal einen Statistikkurs besucht?â€™\n\nWie viele EintrÃ¤ge enthÃ¤lt der Datensatz?\nWie viele Variablen enthÃ¤lt der Datensatz?\nSind die Variablen numerisch oder kategorial? Wurden die Variablen auch so von R eingelesen?\nErklÃ¤ren Sie jede Variable. Welche Information enthÃ¤lt sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungefÃ¤hr)?"
  },
  {
    "objectID": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "href": "05-explorative-kategorial.html#lending-club-peer-to-peer-kredite",
    "title": "5Â  Exploration von kategorialen Daten",
    "section": "5.2 Lending Club â€“ Peer-to-Peer-Kredite",
    "text": "5.2 Lending Club â€“ Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen Ã¼ber eine Plattform ermÃ¶glicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nloans_full_schema\n\n\n\n  \n\n\n\n\n5.2.1 HÃ¤ufigkeitstabelle\nWir erstellen eine HÃ¤ufigkeitstabelle der Variable homeownership. Dazu mÃ¼ssen wir die einzelnen Merkmalswerte auszÃ¤hlen lassen. Das Ã¼bernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership fÃ¼r die Vorlesung verÃ¤ndert wurde. Es ist nÃ¤mlich stÃ¶rend, wenn die MerkmalsausprÃ¤gungen mit GroÃŸbuchstaben geschrieben werden. AuÃŸerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir Ã¤ndern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu Ã¼berschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Ã„nderungen in einem Aufruf zu mutate() durchfÃ¼hren darf. Zuerst macht die Funktion tolower() aus den GroÃŸbuchstaben Kleinbuchstaben, danach Ã¤nder die Funktion fct_relevel() die Reihenfolge der MerkmalsausprÃ¤gungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n5.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nÃ¤mlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall mÃ¶chte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen FÃ¤lle, nÃ¤mlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy ğŸ¤“.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die EintrÃ¤ge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die eintrÃ¤ge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige Ã¤sthetische Griffe ist das jetzt das Gleiche wie in der Vorlesung ğŸ˜„."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble",
    "text": "4.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir nÃ¤mlich zwei Indizes: einen Index fÃ¼r die Zeile und einen Index fÃ¼r die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um Ã–sterreich. Wir kÃ¶nnen auch ganze Spalten (Variablen) ansprechen. DafÃ¼r wird der erste Index (fÃ¼r Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle EintrÃ¤ge gemeint sind. So kÃ¶nnen wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es Ã¤hnlich. Wir lassen den Index fÃ¼r die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zurÃ¼ck. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "20-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen OberflÃ¤chen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante DatensÃ¤tze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Ãœbung lernen Sie das Paket haven kennen, dass solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschÃ¤ftigen uns mit dem Datensatz â€œPolitbarometer 2021â€. Die Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen fÃ¼r das ZDF durchgefÃ¼hrt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind fÃ¼r Lehre und Forschung frei. Sie mÃ¼ssen Sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter â€œDownloadsâ€ (rechts oben) den Datensatz â€œZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MBâ€ herunter. DafÃ¼r werden Sie sich einmalig (und kostenlos) anmelden mÃ¼ssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem â€œDatenâ€-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei â€œZA7856_v1-0-0.dtaâ€ finden. Das ist der eigentliche Datensatz.\n\nDatensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich fÃ¼r die Ãœbung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthÃ¤lt der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der â€œTabelle 1: Variablenkorrespondenzliste Politbarometer 2021â€ gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren Ã¤ndern. Gehen Sie durch den Code Zeile fÃ¼r Zeile durch und erklÃ¤ren Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenÃ¼ber dem ursprÃ¼nglichen Datensatz gesis verÃ¤ndert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "20-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse fÃ¼r Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Ãœbung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie mÃ¼ssen vorher natÃ¼rlich diese Bibliothek mit library() laden.\n\n\n\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir mÃ¼ssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der MerkmalsausprÃ¤gungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmÃ¤ÃŸig so, wie diese im Datensatz erscheinen. Das ist fÃ¼r die BundeslÃ¤nder ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den BundeslÃ¤ndern ausgeprÃ¤gt ist. DafÃ¼r sehen wir uns die Antworten auf die Frage â€œWie stark interessieren Sie sich fÃ¼r Politik, â€¦â€. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der MerkmalsausprÃ¤gungen ist unlogisch. Das mÃ¼ssen wir Ã¤ndern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht fÃ¼r keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der MerkmalsausprÃ¤gungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den BundeslÃ¤ndern. Ist das Interesse der BÃ¼rger Ã¤hnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen HÃ¤ufigkeiten heran. Was macht der nachfolgende Code. Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nÃ¤chste Schritt ist es, die relativen HÃ¤ufigkeiten (Anteile) fÃ¼r jedes Bundesland auszurechnen, um die obige Frage zu beantworten. ErklÃ¤ren Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurÃ¼ck zu unserer Frage: Ist das Interesse der BÃ¼rger in allen BundeslÃ¤ndern Ã¤hnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafÃ¼r kÃ¶nnen Sie folgende Code-Fragmente ergÃ¤nzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +\n  labs(___)\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginnerâ€™s Guide to R. Springer."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html",
    "href": "30-lab-02-intro-to-data.html",
    "title": "8Â  Lab 02: PÃ¼nktlichkeit von FlÃ¼gen",
    "section": "",
    "text": "Das ist die deutsche Ãœbersetzung des â€œOpenIntro Labs for R and tidyverseâ€ 2. Intro to data. Es ist Teil des Buches von Ã‡etinkaya-Rundel et al., Introduction to Modern Statistics, lizenziert unter CC-BY-SA 3.0. Ãœbersetzt mit www.DeepL.com/Translator, bearbeitet und ergÃ¤nzt von C. Bogner und L. Dedeke.\nManche definieren Statistik als das Gebiet, das sich darauf konzentriert, Informationen in Wissen zu verwandeln. Der erste Schritt in diesem Prozess ist die Zusammenfassung und Beschreibung der Rohinformationen - der Daten. In dieser Ãœbung untersuchen wir FlÃ¼ge, insbesondere eine Zufallsstichprobe von InlandsflÃ¼gen, die im Jahr 2013 von den drei groÃŸen FlughÃ¤fen in New York City abgeflogen sind. Wir werden einfache grafische und numerische Zusammenfassungen der Daten zu diesen FlÃ¼gen erstellen und die VerspÃ¤tungszeiten untersuchen. Da es sich um einen groÃŸen Datensatz handelt, werden Sie nebenbei auch die unverzichtbaren Fertigkeiten der Datenverarbeitung und -unterteilung erlernen."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#mobilitÃ¤t-in-europa",
    "href": "30-lab-02-intro-to-data.html#mobilitÃ¤t-in-europa",
    "title": "6Â  Lab 02: EinfÃ¼hrung in Daten",
    "section": "6.1 MobilitÃ¤t in Europa",
    "text": "6.1 MobilitÃ¤t in Europa\nWir nutzen erneut den Datensatz aus der ersten Sitzung der Vorlesung. ZunÃ¤chst laden wir wie immer die nÃ¶tigen Bibliotheken.\n\nlibrary(tidyverse)\n\nDas Einlesen eines Datensatzes aus einer Textdatei haben Sie ja bereits im letzten Kapitel gelernt.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n6.1.1 Kategoriale Variablen als Faktoren\nWir sehen uns das tibble etwas genauer an.\n\ncar_numbers\n\n\n\n  \n\n\n\nKategorische Variablen werden als Text (character) eingelesen. Das bedeutet, dass wir R nicht (so leicht) fragen kÃ¶nnen, welche verschiedenen MerkmalsausprÃ¤gungen die Variable enthÃ¤lt. Zur Erinnerung: MerkmalsausprÃ¤gungen sind die theoretisch mÃ¶glichen Werte, die eine Variable annehmen kann. Merkmalswert ist dann der tatsÃ¤chlich beobachtete Wert (die Beobachtung), den die Variable angenommen hat.\nEine bessere Klasse fÃ¼r eine kategoriale Variable ist ein Faktor (factor). Bei einem Faktor werden die unterschiedlichen MerkmalsausprÃ¤gungen (levels) explizit gespeichert. Wir wandeln daher die Text-Variable geo in einen Faktor um.\n\ncar_numbers <- car_numbers %>% \n  mutate(geo_factor = as_factor(geo))\n\nDas Zeichen %>% heiÃŸt Pipe-Operator. Man spricht ihn als und dann aus. Mehr dazu lernen Sie im Tutorium. Hier reicht es, wenn Sie sich die Funktion des Pipe-Operators als ein Weitergeben oder ein Ãœbergeben des Objekts auf der linken Seite des Pipe-Operators (also car_numbers) an die erste Stelle der Funktion in der neuen Zeile (bzw. rechts vom Pipe-Operator, also an die Funktion mutate()) vorstellen. Das bedeutet, dass man den Code oben auch wie folgt schreiben kÃ¶nnte:\n\ncar_numbers_test <- mutate(.data = car_numbers, geo_factor = as_factor(geo))\n\nEs kommt dasgleiche raus:\n\ncar_numbers\n\n\n\n  \n\n\ncar_numbers_test\n\n\n\n  \n\n\n\nDas ist aber viel unÃ¼bersichtlicher als mit dem Pipe-Operator. Da dieser den Code so schÃ¶n strukturiert, wird er hÃ¤ufig verwendet und ist ein fester Bestandteil von tidyverse.\nDie Funktion mutate() kann neue Variablen in einem Datensatz erstellen, verÃ¤ndern oder lÃ¶schen. In unserem Fall erstellen wir eine neue Variable, die wir geo_factor nennen. Die Funktion as_factor() wandelt (konvertiert) die Text-Variable geo in einen Faktor.\nDen Code car_numbers %>% mutate(geo_factor = as_factor(geo)) kann man also aussprechen als:\n\nNimm den Datensatz car_numbers und dann\nerstelle darin eine neue Variable geo_factor, in der die Variable geo als Faktor abgespeichert wird.\n\nDen Pipe-Operator erhÃ¤lt man mit der Tastenkombination Str+Shift+M.\nDie Funktion mutate() fÃ¼gt neue Variablen am Ende des Datensatzes ein:\n\ncar_numbers\n\n\n\n  \n\n\n\nNun kÃ¶nnen wir R auch fragen, welche verschiedenen MerkmalsausprÃ¤gungen (levels) diese Variable enthÃ¤lt:\n\nlevels(car_numbers$geo_factor)\n\n [1] \"Albania\"         \"Austria\"         \"Belgium\"         \"Bulgaria\"       \n [5] \"Croatia\"         \"Cyprus\"          \"Czechia\"         \"Denmark\"        \n [9] \"Estonia\"         \"Finland\"         \"France\"          \"Germany\"        \n[13] \"Greece\"          \"Hungary\"         \"Iceland\"         \"Ireland\"        \n[17] \"Italy\"           \"Kosovo\"          \"Latvia\"          \"Liechtenstein\"  \n[21] \"Lithuania\"       \"Luxembourg\"      \"Malta\"           \"Montenegro\"     \n[25] \"Netherlands\"     \"North Macedonia\" \"Norway\"          \"Poland\"         \n[29] \"Portugal\"        \"Romania\"         \"Serbia\"          \"Slovakia\"       \n[33] \"Slovenia\"        \"Spain\"           \"Sweden\"          \"Switzerland\"    \n[37] \"TÃ¼rkiye\"         \"United Kingdom\" \n\n\nDie einzelnen MerkmalsausprÃ¤gungen sind die verschiedenen LÃ¤nder. Der Datensatz enthÃ¤lt 38 unterschiedliche LÃ¤nder.\n\n\n6.1.2 Balkendiagramm mit geom_col()\nWir mÃ¶chten die Daten als Balkendiagramm darstellen. Das Ziel ist eine Ã¤hnliche Darstellung, wie in der Vorlesung.\n\n\n\n\n\nDafÃ¼r mÃ¼ssen wir zuerst eine neue Variable erstellen, die wir zum EinfÃ¤rben der Jahre nutzen kÃ¶nnen. Dazu benÃ¶tigen wir eine zusÃ¤tzliche Bibliothek, die uns den Umgang mit Datum und Uhrzeit erleichtert. Sie heiÃŸt lubridate.\n\nlibrary(lubridate)\n\nNun nutzen wir die Funktion year() aus lubridate, um aus der Variablen time nur das Jahr zu extrahieren. Wir erstellen dazu mit mutate() wieder eine neue Variable, die wir time_year nennen.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = year(time))\n\nAuch diese Variable wir an das Ende des Datensatzes car_numbers gestellt.\n\ncar_numbers\n\n\n\n  \n\n\n\nEine Variable zum EinfÃ¤rben mit zwei verschiedenen Farben (je Jahr eine andere Farbe) muss kategorial sein. Die Variable time_year ist aber numerisch. Daher nutzen wir mutate(), um time_year in einen Faktor zu verwandeln.\n\ncar_numbers <- car_numbers %>% \n  mutate(time_year = as_factor(time_year))\n\nIn diesem Fall erstellt mutate() keine neue Variable, sondern Ã¼berschreibt (verÃ¤ndert) die vorhandene Variable time_year. Das ist mÃ¶glich und gÃ¤ngige Praxis in R. Jetzt ist time_year ein Faktor, was man auch in der Darstellung des tibble sehen kann.\n\ncar_numbers\n\n\n\n  \n\n\n\nNun geht es an die Darstellung. Im Kapitel ?sec-ggplot haben Sie das geom_bar() kennengelernt. Es kann die Anzahl der EintrÃ¤ge in einer Variablen auszÃ¤hlen und diese als Balkendiagramm darstellen. Das mÃ¶chten wir aber in unserem Fall nicht. Wir wollen die Anzahl der Autos darstellen, die in der Variablen value enthalten ist. In anderen Worten, wir wollen die Merkmalswerte (Beobachtungen) selbst und und nicht deren Anzahl (counts) darstellen. Das ist die Aufgabe des geom_col() (col steht fÃ¼r columns, also SÃ¤ulen/Balken).\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col()\n\n\n\n\nEs ist noch etwas Nacharbeit nÃ¶tig. Sieht man in die Hilfe von geom_col(), dann kann man nachlesen, dass es standardmÃ¤ÃŸig ein Stapelbalkendiagramm darstellt (stacked bar plot ). MÃ¶chte man die Balken nebeneinander haben (dodged bar plot), muss man das explizit sagen.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) \n\n\n\n\nDie LÃ¤ndernamen erscheinen (wie es Standard ist) horizontal. In unserem Fall Ã¼berdecken sie sich aber und wir sollten sie vertikal schreiben. Dazu gibt es eine neue Funktion aus ggplot2, die wie alle anderen mit einem + angehÃ¤ngt wird. Sie heiÃŸt theme(). Der Parameter, der fÃ¼r die Gestaltung der \\(x\\)-Achse zustÃ¤ndig ist, heiÃŸt axis.text.x Die Funktion element_text mit der Einstellung angle = 90 dreht die einzelnen LÃ¤nder um 90 Grad. Die Aufgabe der beiden anderen Parameter finden Sie im Rahmen der Aufgaben heraus.\n\nggplot(data = car_numbers, mapping = aes(x = geo, y = values, fill = time_year)) +\n  geom_col(position = position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\nWarning: Removed 3 rows containing missing values (geom_col)."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "href": "30-lab-02-intro-to-data.html#lending-club-peer-to-peer-kredite",
    "title": "6Â  Lab 02: EinfÃ¼hrung in Daten",
    "section": "6.2 Lending Club â€“ Peer-to-Peer-Kredite",
    "text": "6.2 Lending Club â€“ Peer-to-Peer-Kredite\nLending Club: Ein US-Unternehmen, das Individuen Ã¼ber eine Plattform ermÃ¶glicht, an andere Individuen Geld zu verleihen (Peer-to-Peer-Kredite). Wir haben den Datensatz bereits in der Vorlesung kennengelernt. Er ist in der Bibliothek openintro als loands_full_schema zu finden. Wir laden die Bibliothek und holen uns den Datensatz.\n\n# Das R-Paket (auch Bibliothek genannt) laden\nlibrary(openintro)\n\n# Datensatz laden\ndata(loans_full_schema)\n\n# Datensatz ansehen\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouseâ€¦\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1â€¦\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, Iâ€¦\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWNâ€¦\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34â€¦\n$ verified_income                  <fct> Verified, Not Verified, Source Verifiâ€¦\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4â€¦\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NAâ€¦\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,â€¦\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,â€¦\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0â€¦\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NAâ€¦\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2â€¦\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8â€¦\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,â€¦\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,â€¦\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42â€¦\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898â€¦\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0â€¦\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, Nâ€¦\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,â€¦\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2â€¦\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7â€¦\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,â€¦\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,â€¦\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, â€¦\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,â€¦\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272â€¦\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, â€¦\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,â€¦\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3â€¦\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3â€¦\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1â€¦\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0â€¦\n$ loan_purpose                     <fct> moving, debt_consolidation, other, deâ€¦\n$ application_type                 <fct> individual, individual, individual, iâ€¦\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000â€¦\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3â€¦\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7â€¦\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87â€¦\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, Câ€¦\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, Aâ€¦\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201â€¦\n$ loan_status                      <fct> Current, Current, Current, Current, Câ€¦\n$ initial_listing_status           <fct> whole, whole, fractional, whole, wholâ€¦\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, Câ€¦\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,â€¦\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,â€¦\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569â€¦\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.â€¦\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n\n\n\n6.2.1 HÃ¤ufigkeitstabelle\nWir erstellen eine HÃ¤ufigkeitstabelle der Variable homeownership. Dazu mÃ¼ssen wir die einzelnen Merkmalswerte auszÃ¤hlen lassen. Das Ã¼bernimmt die Funktion count().\n\nloans_full_schema %>% \n  count(homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht anders aus als in der Vorlesung. Das liegt daran, dass die Variable homeownership fÃ¼r die Vorlesung verÃ¤ndert wurde. Es ist nÃ¤mlich stÃ¶rend, wenn die MerkmalsausprÃ¤gungen mit GroÃŸbuchstaben geschrieben werden. AuÃŸerdem macht es logisch Sinn, zuerst die gemieteten, dann die mit einer Hypothek belegten und zum Schluss die Eigentumsobjekte zu sehen. Das spiegelt in einer gewissen Weise das Risiko wider, dass ein Kredit nicht bedient werden kann. Achtung: Es ist trotzdem keine ordinal-skalierte Variable!\nWir Ã¤ndern die Darstellung der Variablen homeownership. Um den Originaldatensatz nicht zu Ã¼berschreiben, erstellen wir einen neuen, den wir loans nennen.\n\nloans <- loans_full_schema %>%\n  mutate(homeownership = tolower(homeownership),\n         homeownership = fct_relevel(homeownership, \"rent\", \"mortgage\", \"own\"))\n\nSie sehen, dass man die beiden Ã„nderungen in einem Aufruf zu mutate() durchfÃ¼hren darf. Zuerst macht die Funktion tolower() aus den GroÃŸbuchstaben Kleinbuchstaben, danach Ã¤nder die Funktion fct_relevel() die Reihenfolge der MerkmalsausprÃ¤gungen (levles). Jetzt entspricht das Ergebnis dem der Vorlesung.\n\nloans %>% \n  count(homeownership)\n\n\n\n  \n\n\n\n\n\n6.2.2 Kontingenztabelle\nEine Kontingenztabelle fasst zwei kategoriale Variablen zusammen. Jede Zeile zeigt die Anzahl der Kombinationen zwischen diesen Variablen.\n\nloans %>%\n  count(application_type, homeownership)\n\n\n\n  \n\n\n\nDie Tabelle sieht auch anders aus als in der Vorlesung. Sie ist nÃ¤mlich tidy: jede Spalte ist eine Variable und jede Zeile ist eine Beobachtung. In diesem Fall mÃ¶chte man es aber eigentlich untidy dargestellt haben. Das ist einer der seltenen FÃ¤lle, nÃ¤mlich die Darstellung von Tabellen, wo das auch Sinn macht. Achtung, jetzt wird es nerdy ğŸ¤“.\nWir formatieren die Tabelle von lang tidy auf breit und untidy. Dabei wandern die EintrÃ¤ge der Spalte homeowndership in die Breite und werden zu neuen Spalten. Die eintrÃ¤ge in den Tabellenzellen kommen aus der Spalte n.\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n)\n\n\n\n  \n\n\n\nJetzt fehlen nur noch die Zeilen- und Spaltensummen. Da hilft die Bibliothek janitor\n\nlibrary(janitor)\n\nloans %>%\n  count(application_type, homeownership) %>%\n  pivot_wider(names_from = homeownership, values_from = n) %>% \n  adorn_totals(where = c(\"row\", \"col\"))\n\n\n\n  \n\n\n\nBis auf wenige Ã¤sthetische Griffe ist das jetzt das Gleiche wie in der Vorlesung ğŸ˜„."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#aufgaben",
    "href": "30-lab-02-intro-to-data.html#aufgaben",
    "title": "6Â  Lab 02: EinfÃ¼hrung in Daten",
    "section": "6.3 Aufgaben",
    "text": "6.3 Aufgaben\n\n6.3.1 Grafik beschriften\nBeschriften Sie die finale Grafik aus SectionÂ 6.1.2 so, dass sie wie dort anfangs dargestellt aussieht.\n\n\n6.3.2 Aufgaben der Funktion theme()\n\nLesen Sie nach, was die Aufgabe der Funktion theme() ist. Fassen Sie den Abschnitt Description kurz mit Ihren eigenen Worten zusammen.\nIch habe in der Vorlesung theme_classic() benutzt. Ã„ndern Sie die finale Grafik in SectionÂ 6.1.2 so, dass auch dort dieses theme benutzt wird.\nFinden Sie heraus, was hjust und vjust tun. Probieren Sie die Werte 0, 0.5 und 1 aus. Wie Ã¤ndert sich die Position der LÃ¤ndernamen?\n\n\n\n6.3.3 Tutorium\nBearbeiten Sie das Tutorium â€œEinfÃ¼hrung in Daten: 1 - Die Sprache der Datenâ€. Sie kÃ¶nnen entweder die deutsche Ãœbersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "href": "30-lab-02-intro-to-data.html#ihre-arbeit-einreichen",
    "title": "6Â  Lab 02: EinfÃ¼hrung in Daten",
    "section": "6.4 Ihre Arbeit einreichen",
    "text": "6.4 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen."
  },
  {
    "objectID": "100-aufgabensammlung.html",
    "href": "100-aufgabensammlung.html",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "",
    "text": "In einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009a). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\n\n\n \n  \n    Fluegel \n    Fuss \n    Kopf \n    Gewicht \n  \n \n\n  \n    59.0 \n    22.3 \n    31.2 \n    9.5 \n  \n  \n    55.0 \n    19.7 \n    30.4 \n    13.8 \n  \n  \n    53.5 \n    20.8 \n    30.6 \n    14.8 \n  \n  \n    55.0 \n    20.3 \n    30.3 \n    15.2 \n  \n  \n    52.5 \n    20.8 \n    30.3 \n    15.5 \n  \n  \n    57.5 \n    21.5 \n    30.8 \n    15.6 \n  \n  \n    53.0 \n    20.6 \n    32.5 \n    15.6 \n  \n  \n    55.0 \n    21.5 \n    NA \n    15.7 \n  \n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele VÃ¶gel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFÃ¼hren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#einfÃ¼hrung-in-die-darstellung-von-daten",
    "href": "100-aufgabensammlung.html#einfÃ¼hrung-in-die-darstellung-von-daten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.2 EinfÃ¼hrung in die Darstellung von Daten",
    "text": "A.2 EinfÃ¼hrung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen FlossenlÃ¤nge flipper_length_mm auf der \\(x\\)-Achse und der Variablen KÃ¶rpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nFÃ¤rben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung ğŸ¤“."
  },
  {
    "objectID": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen OberflÃ¤chen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante DatensÃ¤tze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser Ãœbung lernen Sie das Paket haven kennen, das solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir beschÃ¤ftigen uns mit dem Datensatz â€œPolitbarometer 2021â€. Das Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen fÃ¼r das ZDF durchgefÃ¼hrt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind fÃ¼r Lehre und Forschung frei. Sie mÃ¼ssen sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter â€œDownloads/Datasetsâ€ (rechts oben) den Datensatz â€œZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MBâ€ herunter. DafÃ¼r werden Sie sich einmalig (und kostenlos) anmelden mÃ¼ssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem â€œDatenâ€-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei â€œZA7856_v1-0-0.dtaâ€ finden. Das ist der eigentliche Datensatz.\n\nDen Datensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich fÃ¼r die Ãœbung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enthÃ¤lt der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der â€œTabelle 1: Variablenkorrespondenzliste Politbarometer 2021â€ gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren Ã¤ndern. Gehen Sie durch den Code Zeile fÃ¼r Zeile durch, und erklÃ¤ren Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegenÃ¼ber dem ursprÃ¼nglichen Datensatz gesis verÃ¤ndert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse fÃ¼r Politik\nWir analysieren den Datensatz, den Sie in der vorherigen Ãœbung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie mÃ¼ssen vorher natÃ¼rlich diese Bibliothek mit library() laden.\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir mÃ¼ssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der MerkmalsausprÃ¤gungen (der unterschiedlichen Werte einer kategorialen Variablen) standardmÃ¤ÃŸig so, wie diese im Datensatz erscheinen. Das ist fÃ¼r die BundeslÃ¤nder ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den BundeslÃ¤ndern ausgeprÃ¤gt ist. DafÃ¼r sehen wir uns die Antworten auf die Frage â€œWie stark interessieren Sie sich fÃ¼r Politik, â€¦â€. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der MerkmalsausprÃ¤gungen ist unlogisch. Das mÃ¼ssen wir Ã¤ndern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht fÃ¼r keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der MerkmalsausprÃ¤gungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den BundeslÃ¤ndern. Ist das Interesse der BÃ¼rger Ã¤hnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen HÃ¤ufigkeiten heran. Was macht der nachfolgende Code? Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer nÃ¤chste Schritt ist es, die relativen HÃ¤ufigkeiten (Anteile) fÃ¼r jedes Bundesland auszurechnen, um die obige Frage zu beantworten. ErklÃ¤ren Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZurÃ¼ck zu unserer Frage: Ist das Interesse der BÃ¼rger in allen BundeslÃ¤ndern Ã¤hnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDafÃ¼r kÃ¶nnen Sie folgende Code-Fragmente ergÃ¤nzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  labs(___) +\n  theme_minimal()\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#erste-schritte",
    "href": "30-lab-02-intro-to-data.html#erste-schritte",
    "title": "11Â  Lab 02: PÃ¼nktlichkeit von FlÃ¼gen",
    "section": "11.1 Erste Schritte",
    "text": "11.1 Erste Schritte\n\n11.1.1 Pakete laden\nIn dieser Ãœbung werden wir die Daten mithilfe der Paketsammlung tidyverse untersuchen und visualisieren. Die Daten befinden sich im Begleitpaket fÃ¼r OpenIntro-Ãœbungen, openintro.\nLassen Sie uns die Pakete laden.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n\n11.1.2 Erstellen eines reproduzierbaren Berichts\nDenken Sie daran, dass wir R Markdown verwenden werden, um reproduzierbare Berichte zu erstellen. Gehen Sie in RStudio zu New File -> R Markdownâ€¦ WÃ¤hlen Sie dann From Template und wÃ¤hlen Sie dann Lab Report for OpenIntro Statistics Labs aus der Liste der Vorlagen. Oder verfahren Sie so, wie wir es in den Ãœbungen gelernt haben New File -> R Notebookâ€¦ Beide Varianten sind in Ordnung. Wenn Sie die Variante mit R Markdown wÃ¤hlen, gibt es keinen Button â€œPreviewâ€, sondern Sie mÃ¼ssen das Dokument â€œknittenâ€ Ã¼ber den Button mit dem WollknÃ¤uel.\nSehen Sie sich das folgende Video an, in dem beschrieben wird, wie Sie mit der Erstellung dieser Berichte fÃ¼r dieses und alle zukÃ¼nftigen Labs beginnen kÃ¶nnen:\nGrundlegendes zu R Markdown mit einer OpenIntro-Ãœbung \n\n\n11.1.3 Die Daten\nDas Bureau of Transportation Statistics (BTS) ist eine StatistikbehÃ¶rde, die zur Research and Innovative Technology Administration (RITA) gehÃ¶rt. Wie der Name schon sagt, sammelt das BTS Verkehrsdaten und stellt sie zur VerfÃ¼gung, wie z. B. die Flugdaten, mit denen wir in diesem Labor arbeiten werden.\nAls Erstes werden wir uns den Datensatz nycflights ansehen. Geben Sie Folgendes in Ihre Konsole ein, um die Daten zu laden:\n\ndata(nycflights)\n\nDer Datensatz nycflights, der in Ihrem Arbeitsbereich angezeigt wird, ist eine Datenmatrix oder Datentabelle, wobei jede Zeile eine Beobachtung und jede Spalte eine Variable darstellt. In R wird dieses Datenformat als Dataframe bezeichnet, ein Begriff, der in den Ãœbungen immer wieder verwendet wird. Bei diesem Datensatz ist jede Beobachtung ein einzelner Flug.\nUm die Namen der Variablen anzuzeigen, geben Sie den Befehl\n\nnames(nycflights)\n\nDies gibt die Namen der Variablen in diesem Datenrahmen zurÃ¼ck. Das Codebuch (Beschreibung der Variablen) kann Ã¼ber die Hilfedatei abgerufen werden:\n\n?nycflights\n\nEine der Variablen bezieht sich auf die Fluggesellschaft des Fluges, die nach folgendem System kodiert wird.\n\ncarrier (Fluggesellschaft): Zweibuchstabiges KÃ¼rzel der Fluggesellschaft.\n\n9E: Endeavor Air Inc.\nAA: American Airlines Inc.\nAS: Alaska Airlines Inc.\nB6: JetBlue Airways\nDL: Delta Air Lines Inc.\nEV: ExpressJet Fluggesellschaften Inc.\nF9: Frontier Airlines Inc.\nFL: AirTran Airways Corporation\nHA: Hawaiian Airlines Inc.\nMQ: Envoy Air\nOO: SkyWest Airlines Inc.\nUA: United Air Lines Inc.\nUS: US Airways Inc.\nVX: Virgin America\nWN: Southwest Airlines Co.\nYV: Mesa Airlines Inc.\n\n\nDenken Sie daran, dass Sie die Funktion glipmse() nutzen kÃ¶nnen, um einen Ãœberblick Ã¼ber die Daten zu erhalten und somit deren Inhalt besser zu verstehen.\n\nglimpse(nycflights)\n\nDer Datensatz nycflights ist eine riesige Fundgrube an Informationen. Lassen Sie uns Ã¼ber einige Fragen nachdenken, die wir mit diesen Daten beantworten wollen:\n\nWie verspÃ¤tet waren die FlÃ¼ge nach Los Angeles?\nWie unterscheiden sich die AbflugverspÃ¤tungen je nach Monat?\nWelcher der drei groÃŸen FlughÃ¤fen in New York hat den besten Prozentsatz an pÃ¼nktlichen AbflÃ¼gen?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#analyse",
    "href": "30-lab-02-intro-to-data.html#analyse",
    "title": "11Â  Lab 02: PÃ¼nktlichkeit von FlÃ¼gen",
    "section": "11.2 Analyse",
    "text": "11.2 Analyse\n\n11.2.1 Bericht\nUm Ihre Analyse in einem reproduzierbaren Bericht festzuhalten, kÃ¶nnen Sie die allgemeine Vorlage fÃ¼r Berichte aus dem Paket openintro anpassen. Sehen Sie sich das Video oben an, um zu erfahren, wie das geht.\n\n\n11.2.2 AbflugverspÃ¤tungen\nBeginnen wir damit, die Verteilung der AbflugverspÃ¤tungen aller FlÃ¼ge mit einem Histogramm zu untersuchen.\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram()\n\nMit dieser Funktion wird die Variable dep_delay aus dem Dataframe nycflights auf der \\(x\\)-Achse dargestellt. Sie definiert auch ein geom (kurz fÃ¼r geometrisches Objekt), das die Art der Darstellung beschreibt, die Sie erzeugen werden.\nHistogramme eignen sich im Allgemeinen sehr gut, um die Form der Verteilung einer einzelnen numerischen Variablen zu sehen, aber diese Form kann sich Ã¤ndern, je nachdem, wie die Daten auf die verschiedenen Bins aufgeteilt sind. Sie kÃ¶nnen die zu verwendende Bin-Breite einfach festlegen:\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)\n\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 150)\n\n\n\nSchauen Sie sich diese drei Histogramme genau an. Wie lassen sie sich vergleichen? Sind in einem Histogramm Merkmale zu erkennen, die in einem anderen verdeckt sind?\n\n\nWenn Sie nur die VerspÃ¤tungen von FlÃ¼gen nach Los Angeles anzeigen mÃ¶chten, mÃ¼ssen Sie zunÃ¤chst die Daten nach FlÃ¼gen mit diesem Ziel filter()n (dest == \"LAX\") und dann ein Histogramm der AbflugverspÃ¤tungen nur dieser FlÃ¼ge erstellen.\n\nlax_flights <- nycflights %>%\n  filter(dest == \"LAX\")\nggplot(data = lax_flights, aes(x = dep_delay)) +\n  geom_histogram()\n\nLassen Sie uns diese beiden Befehle entschlÃ¼sseln (OK, es sieht vielleicht nach vier Zeilen aus, aber die ersten beiden physischen Codezeilen sind tatsÃ¤chlich Teil desselben Befehls. Es ist Ã¼blich, nach %>% einen Zeilenumbruch einzufÃ¼gen, um die Lesbarkeit zu verbessern).\n\nBefehl 1: Nehmen Sie den Dataframe nycflights, filter()n Sie nach FlÃ¼gen zum LAX und speichern Sie das Ergebnis als neuen Datenrahmen namens lax_flights.\n\n== bedeutet â€œwenn es gleich ist mitâ€.\nLAX steht in AnfÃ¼hrungszeichen, da es sich um eine Zeichenkette handelt.\n\nBefehl 2: Im Grunde derselbe ggplot-Aufruf wie bei der Erstellung eines Histogramms, nur dass hier das kleinere Dataframe fÃ¼r FlÃ¼ge mit Ziel LAX anstelle aller FlÃ¼ge verwendet wird.\n\n\nLogische Operatoren: Das Filtern nach bestimmten Beobachtungen (z. B. FlÃ¼ge von einem bestimmten Flughafen) ist in Dataframes oft von Interesse, wenn wir Beobachtungen mit bestimmten MerkmalsausprÃ¤gungen getrennt vom Rest der Daten untersuchen mÃ¶chten. Zu diesem Zweck kÃ¶nnen Sie die Filterfunktion und eine Reihe von logischen Operatoren verwenden. Die am hÃ¤ufigsten verwendeten logischen Operatoren fÃ¼r die Datenanalyse sind die folgenden:\n\n== bedeutet â€œgleichâ€\n!= bedeutet â€œnicht gleichâ€\n> oder < bedeutet â€œgrÃ¶ÃŸer alsâ€ oder â€œkleiner alsâ€.\n>= oder <= bedeutet â€œgrÃ¶ÃŸer als oder gleichâ€ oder â€œkleiner als oder gleichâ€.\n\n\nSie kÃ¶nnen auch numerische Zusammenfassungen fÃ¼r diese FlÃ¼ge erhalten:\n\nlax_flights %>%\n  summarise(mean_dd   = mean(dep_delay), \n            median_dd = median(dep_delay), \n            n         = n())\n\nBeachten Sie, dass Sie in der Funktion summarise() eine Liste mit drei verschiedenen numerischen Zusammenfassungen erstellt haben, an denen Sie interessiert waren. Die Namen dieser Elemente sind benutzerdefiniert, wie mean_dd, median_dd, n, und Sie kÃ¶nnen diese Namen nach Belieben anpassen (verwenden Sie nur keine Leerzeichen in Ihren Namen). FÃ¼r die Berechnung dieser zusammenfassenden Statistiken mÃ¼ssen Sie auch die Funktionsaufrufe kennen. Beachten Sie, dass n() den Stichprobenumfang angibt.\n\nZusammenfassende Statistiken aka statistische Lage- und StreumaÃŸe: Einige nÃ¼tzliche Funktionsaufrufe fÃ¼r zusammenfassende Statistiken fÃ¼r eine einzelne numerische Variable sind wie folgt:\n\nMittelwert: mean()\nMedian: median()\nStandardabweichung: sd()\nVarianz: var()\nInterquartilabstand: IQR()\nKleinster Wert: min()\nGrÃ¶ÃŸter Wert: max()\n\nBeachten Sie, dass jede dieser Funktionen einen einzelnen Vektor als Argument annimmt und einen einzelnen Wert zurÃ¼ckgibt.\n\nSie kÃ¶nnen auch nach mehreren Kriterien filtern. Angenommen, Sie sind an FlÃ¼gen nach San Francisco (SFO) im Februar interessiert:\n\nsfo_feb_flights <- nycflights %>%\n  filter(dest == \"SFO\", month == 2)\n\nBeachten Sie, dass Sie die Bedingungen durch Kommas trennen kÃ¶nnen, wenn Sie FlÃ¼ge sowohl nach SFO als auch im Februar suchen. Wenn Sie entweder an FlÃ¼gen nach SFO oder an FlÃ¼gen im Februar interessiert sind, kÃ¶nnen Sie das | anstelle des Kommas verwenden.\n\n\nErstellen Sie ein neues Dataframe, das FlÃ¼ge nach SFO im Februar enthÃ¤lt, und speichern Sie diesen Datenrahmen als sfo_feb_flights. Wie viele FlÃ¼ge erfÃ¼llen diese Kriterien?\nBeschreiben Sie die Verteilung der AnkunftsverspÃ¤tungen arr_delay dieser FlÃ¼ge anhand eines Histogramms und geeigneter zusammenfassender Statistiken. Tipp: Die von Ihnen verwendete zusammenfassende Statistik sollte von der Form der Verteilung abhÃ¤ngen.\n\n\nEine weitere nÃ¼tzliche Methode ist die schnelle Berechnung von zusammenfassenden Statistiken fÃ¼r verschiedene Gruppen in Ihrem Dataframe. Wir kÃ¶nnen den obigen Befehl etwa mit der Funktion group_by() modifizieren, um die gleiche zusammenfassende Statistik fÃ¼r jeden Herkunftsflughafen zu erhalten:\n\nsfo_feb_flights %>%\n  group_by(origin) %>%\n  summarise(median_dd = median(dep_delay), iqr_dd = IQR(dep_delay), n_flights = n())\n\nHier haben wir die Daten zunÃ¤chst nach Herkunft gruppiert und dann die zusammenfassenden Statistiken berechnet.\n\n\nBerechnen Sie den Median und den Interquartilsabstand fÃ¼r arr_delays der FlÃ¼ge im Datenrahmen sfo_feb_flights, gruppiert nach Fluggesellschaft. Welche Fluggesellschaft hat AnkunftsverspÃ¤tungen mit der grÃ¶ÃŸten VariabilitÃ¤t?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#abflugverspÃ¤tungen-nach-monaten",
    "href": "30-lab-02-intro-to-data.html#abflugverspÃ¤tungen-nach-monaten",
    "title": "11Â  Lab 02: PÃ¼nktlichkeit von FlÃ¼gen",
    "section": "11.3 AbflugverspÃ¤tungen nach Monaten",
    "text": "11.3 AbflugverspÃ¤tungen nach Monaten\nIn welchem Monat wÃ¼rden Sie die hÃ¶chste durchschnittliche VerspÃ¤tung bei AbflÃ¼gen von einem New Yorker Flughafen erwarten?\nLassen Sie uns Ã¼berlegen, wie Sie diese Frage beantworten kÃ¶nnen:\n\nBerechnen Sie zunÃ¤chst die monatlichen Durchschnittswerte fÃ¼r AbflugverspÃ¤tungen. Mit der neuen Sprache, die Sie gerade lernen, kÃ¶nnten Sie\n\ngroup_by() nach Monaten, dann\ndie durchschnittlichen AbflugverspÃ¤tungen zusammenfassen mit summarise().\n\nDann kÃ¶nnten Sie diese durchschnittlichen VerspÃ¤tungen in absteigender Reihenfolge mit arrange()anordnen\n\n\nnycflights %>%\n  group_by(month) %>%\n  summarise(mean_dd = mean(dep_delay)) %>%\n  arrange(desc(mean_dd))\n\n\n\nAngenommen, Sie mÃ¶gen keine VerspÃ¤tungen bei der Abreise und mÃ¶chten Ihre Reise in einem Monat planen, der Ihre mÃ¶gliche VerspÃ¤tung bei der Abreise aus New York minimiert. Eine MÃ¶glichkeit ist, den Monat mit dem geringsten Mittelwerten der AbflugverspÃ¤tung zu wÃ¤hlen. Eine andere MÃ¶glichkeit ist, den Monat mit dem geringsten Median der AbflugverspÃ¤tung zu wÃ¤hlen. Was sind die Vor- und Nachteile dieser beiden MÃ¶glichkeiten?\n\n\n\n11.3.1 PÃ¼nktliche Abflugrate fÃ¼r NYC-FlughÃ¤fen\nAngenommen, Sie fliegen von New York City aus und mÃ¶chten wissen, welcher der drei groÃŸen FlughÃ¤fen in New York City die beste PÃ¼nktlichkeitsrate bei abgehenden FlÃ¼gen aufweist. Nehmen wir weiter an, dass fÃ¼r Sie ein Flug, der weniger als 5 Minuten VerspÃ¤tung hat, grundsÃ¤tzlich â€œpÃ¼nktlichâ€ (â€œon timeâ€) ist. Sie betrachten jeden Flug, der mehr als 5 Minuten VerspÃ¤tung hat, als â€œverspÃ¤tetâ€ (â€œdelayedâ€).\nUm festzustellen, welcher Flughafen die beste PÃ¼nktlichkeitsquote hat, kÃ¶nnen Sie\n\nzunÃ¤chst jeden Flug als â€œon timeâ€ oder â€œdelayedâ€ einstufen,\ndann die FlÃ¼ge nach Herkunftsflughafen gruppieren,\ndann die Rate der pÃ¼nktlichen AbflÃ¼ge fÃ¼r jeden Herkunftsflughafen berechnen,\nund schlieÃŸlich die FlughÃ¤fen in absteigender Reihenfolge nach dem Prozentsatz der pÃ¼nktlichen AbflÃ¼ge ordnen.\n\nBeginnen wir mit der Klassifizierung der einzelnen FlÃ¼ge als â€œon timeâ€ oder â€œdelayedâ€, indem wir mit der Funktion mutate() eine neue Variable erstellen.\n\nnycflights <- nycflights %>%\n  mutate(dep_type = ifelse(dep_delay < 5, \"on time\", \"delayed\"))\n\nDas erste Argument in der Funktion mutate() ist der Name der neuen Variable, die wir erstellen wollen, in diesem Fall dep_type. Wenn dep_delay < 5 ist, klassifizieren wir den Flug als â€œon timeâ€, wenn nicht, als â€œdelayedâ€, d.Â h. wenn der Flug 5 oder mehr Minuten verspÃ¤tet ist.\nBeachten Sie, dass wir auch das Dataframe nycflights mit der neuen Version dieses Dataframes Ã¼berschreiben, der die neue Variable dep_type enthÃ¤lt.\nAlle Ã¼brigen Schritte kÃ¶nnen wir in einem einzigen Code-Chunk erledigen:\n\nnycflights %>%\n  group_by(origin) %>%\n  summarise(ot_dep_rate = sum(dep_type == \"on time\") / n()) %>%\n  arrange(desc(ot_dep_rate))\n\n\n\nWenn Sie einen Flughafen nur aufgrund des prozentualen Anteils der AbflÃ¼ge in der Zeit auswÃ¤hlen wÃ¼rden, welchen Flughafen in NYC wÃ¼rden Sie dann wÃ¤hlen?\n\n\nSie kÃ¶nnen auch die Verteilung der pÃ¼nktlichen Abflugrate auf die drei FlughÃ¤fen mithilfe eines Balkendiagramms visualisieren.\n\nggplot(data = nycflights, aes(x = origin, fill = dep_type)) +\n  geom_bar()"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#weitere-Ã¼bungen",
    "href": "30-lab-02-intro-to-data.html#weitere-Ã¼bungen",
    "title": "11Â  Lab 02: PÃ¼nktlichkeit von FlÃ¼gen",
    "section": "11.4 Weitere Ãœbungen",
    "text": "11.4 Weitere Ãœbungen\n\n\nÃ„ndern Sie das Dataframe so, dass es eine neue Variable enthÃ¤lt, die die Durchschnittsgeschwindigkeit, avg_speed, die das Flugzeug bei jedem Flug zurÃ¼ckgelegt hat (in mph), angibt. Tipp: Die Durchschnittsgeschwindigkeit kann als Entfernung geteilt durch die Anzahl der Flugstunden berechnet werden, und beachten Sie, dass die Flugzeit air_time in Minuten angegeben wird.\nErstellen Sie ein Streudiagramm von der Durchschnittsgeschwindigkeit avg_speed und Entfernung distance. Beschreiben Sie die Beziehung zwischen Durchschnittsgeschwindigkeit und Entfernung. Tipp: Verwenden Sie geom_point().\nBauen Sie die folgende Darstellung nach. Tipp: Das dargestellte Dataframe enthÃ¤lt nur FlÃ¼ge von American Airlines, Delta Airlines und United Airlines, und die Punkte sind nach Fluggesellschaft carrier eingefÃ¤rbt (colored). Ermitteln Sie nach dem Plotten (grob) den Grenzwert fÃ¼r AbflugverspÃ¤tungen, bei dem Sie noch erwarten kÃ¶nnen, Ihr Ziel rechtzeitig zu erreichen."
  },
  {
    "objectID": "06-explorative-numerisch.html",
    "href": "06-explorative-numerisch.html",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "",
    "text": "Kernpakete aus tidyverse benennen\nein Workflow (Daten einlesen, zusammenfassen, darstellen) mit tidyverse durchfÃ¼hren\nFunktionen des Pakets dplyr fÃ¼r Datentransformation anwenden\ntidyverse ist eine Sammlung von R-Paketen, die explizit fÃ¼r Datenanalyse entwickelt wurden (https://www.tidyverse.org/). tidyverse versucht durch gemeinsame Philosophie in Design, Grammatik und Datenstruktur die Datenanalyse zu erleichtern (https://design.tidyverse.org/). Auch wenn tidyverse auf den ersten Blick etwas fremd erscheint, es ist ein Teil von R, kein eigenes Universum. Es ist also vÃ¶llig in Ordnung, R-Basisfunktionen mit Funktionen aus tidyverse zu mischen.\nDas wichtigste EinfÃ¼hrungsbuch zu tidyverse ist sicherlich R4DS: â€œR for Data Scienceâ€ (Wickham and Grolemund 2021), das Sie kostenlos online lesen kÃ¶nnen (https://r4ds.had.co.nz/)."
  },
  {
    "objectID": "06-explorative-numerisch.html#grundpakete",
    "href": "06-explorative-numerisch.html#grundpakete",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.1 Grundpakete",
    "text": "6.1 Grundpakete\ntidyverse enthÃ¤lt folgende Grundpakete, die alle installiert werden, wenn Sie install.packages('tidyverse') ausfÃ¼hren.\n\n\n\nPaketname\nKurzbeschreibung\n\n\n\n\nggplot2\nVisualisierung\n\n\ndplyr\nDatentransformation\n\n\ntidyr\nDatenbereinigung\n\n\nreadr\nDaten einlesen\n\n\npurrr\nFunktionale Programmierung (Funktionen auf Objekte anwenden)\n\n\ntibble\nErweiterung von data.frame\n\n\nstringr\nFunktionen fÃ¼r Strings, d.Â h. Textvariablen\n\n\nforcats\nFunktionen fÃ¼r factor\n\n\n\nJedes dieser Pakete hat ein Cheat Sheet, eine Ã¼bersichtliche Zusammenstellung der Funktionen des Pakets. Sie bekommen die Cheet Sheats Ã¼ber die tidyverse-Seite (https://www.tidyverse.org/packages/), indem Sie auf das jeweilige Paket klicken und zum Abschnitt â€˜Cheatsheetâ€™ scrollen."
  },
  {
    "objectID": "06-explorative-numerisch.html#der-explorative-workflow",
    "href": "06-explorative-numerisch.html#der-explorative-workflow",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.2 Der explorative Workflow",
    "text": "6.2 Der explorative Workflow\n\n6.2.1 Daten einlesen, revisited\nAls Erstes laden wir die Bibliothek tidyverse.\n\nlibrary(tidyverse)\n\nSie kennen bereits die Funktion read_delim() zum Einlesen von Textdateien. Die Funktion ist die allgemeinste Funktion der read_* Familie aus readr in tidyverse; read_csv() und read_csv2() sind jeweils fÃ¼r Komma- und Strichpunkt-getrennte DatensÃ¤tze gedacht. In der Basisinstallation von R (also auÃŸerhalb von tidyverse) gibt die sehr umfangreiche Funktion read.table(), die ebenfalls zum Einlesen von Textdateien verwendet wird. Man kÃ¶nnte berechtigterweise fragen, warum neue Funktion (read_*) fÃ¼r etwas erfinden, was es schon gibt. Die Autoren von tidyverse versprechen Konsistenz und Geschwindigkeit. Ersteres war schon immer ein Problem von R, da es nicht von Computerspezialisten, sondern von Anwendern erfunden wurde. Daher ist eine Vereinheitlichung durch tidyverse mehr als willkommen. Und Geschwindigkeit ist spÃ¤testens bei grÃ¶ÃŸeren DatensÃ¤tzen ein wichtiger Punkt.\nWir sehen uns Daten des Deutschen Wetterdienstes an, die ich am 24. Mai 2020 heruntergeladen habe (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). Der Datensatz enthÃ¤lt Stundenwerte fÃ¼r relative Luftfeuchte (%) und Lufttemperatur (Â°C) von drei Wetterstationen, nÃ¤mlich Hof, Frankfurt und KÃ¶ln-Bonn. Die Daten sind in der Datei â€œDrei_Stationen.csvâ€ gespeichert.\nBeim Einlesen zeigt Ihnen read_delim() bereits, welche Spalten und welche Datentypen es erkennt, mit trim_ws = T werden Leerzeichen aus Spalten entfernt, weil die Daten sonst falsch eingelesen werden.\n\ntemp_humid <- read_delim('Daten/Drei_Stationen.csv', delim = ';', trim_ws = T)\n\nEs sollte fÃ¼r Sie bereits Routine sein, das Ergebnis des Einlesens zu kontrollieren.\n\ntemp_humid\n\n\n\n  \n\n\n\nAlternative kÃ¶nnen Sie die Funktion glimpse() verwenden.\n\nglimpse(temp_humid)\n\nRows: 39,600\nColumns: 6\n$ STATIONS_ID <dbl> 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261, 2261â€¦\n$ MESS_DATUM  <dbl> 2018111900, 2018111901, 2018111902, 2018111903, 2018111904â€¦\n$ QN_9        <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3â€¦\n$ TT_TU       <dbl> -2.8, -2.5, -2.3, -2.0, -1.9, -2.1, -1.8, -1.5, -1.1, -0.6â€¦\n$ RF_TU       <dbl> 99, 100, 100, 100, 99, 99, 99, 99, 99, 97, 95, 93, 94, 88,â€¦\n$ eor         <chr> \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eor\", \"eâ€¦\n\n\nIn diesem Datensatz sind folgende Variablen (Spalten) enthalten (s. Datensatzbeschreibung des DWDs)\n\n\n\nVariablen\nBeschreibung\n\n\n\n\nSTATIONS_ID\nStationsidentifikationsnummer\n\n\nMESS_DATUM\nZeitstempel im Format yyyymmddhh\n\n\nQN_9\nQualitÃ¤tsniveau der nachfolgenden Spalten\n\n\nTT_TU\nLufttemperatur in 2 m HÃ¶he Â°C\n\n\nRF_TU\nrelative Feuchte %\n\n\neor\nEnde data record"
  },
  {
    "objectID": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "href": "06-explorative-numerisch.html#geschickter-umgang-mit-zeit-und-datum",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.3 Geschickter Umgang mit Zeit und Datum",
    "text": "6.3 Geschickter Umgang mit Zeit und Datum\nEin weiteres Paket, das zwar nicht zum Kern von tidyverse gehÃ¶rt, jedoch trotzdem extrem nÃ¼tzlich ist, heiÃŸt lubridate. Das haben wir bereits im letzten Kapitel verwendet, um aus einem Datum das Jahr zu extrahieren. lubridate hilft aber auch, Text sehr einfach in richtige Datums-Objekte zu transformieren. Wir transformieren die Spalte temp_humid$MESS_DATUM in ein richtiges Datum mit Uhrzeit. Die Funktion ymd_h() kann character in ein richtiges Datumsformat transformieren, wenn das Datum als year, month, day, hour codiert ist. Es gibt noch weitere Varianten der Codierung, die Sie bei Bedarf in der Hilfe nachschlagen sollten.\n\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid\n\n\n\n  \n\n\n\n\n6.3.1 Daten zusammenfassen\nDie drei Wetterstationen haben folgende IDs:\n\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\n\nWir zÃ¤hlen nach, wie viele Messpunkte es pro Station gibt. Die Funktion count() kennen Sie bereits. Sie zÃ¤hlt, wie hÃ¤ufig unterschiedlichen MerkmalsausprÃ¤gungen vorkommen:\n\ntemp_humid %>% \n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDie Zeichenkombination %>% heiÃŸt Pipe-Operator (pipe) und wird als â€˜und dannâ€™ gelesen (then). Diesen Operator haben wir bereits im letzten Kapitel verwendet. Der Ausdruck temp_humid %>% count(STATIONS_ID) heiÃŸt also: nimm das Objekt temp_humid, und zÃ¤hle dann die Anzahl der verschiedenen MerkmalsausprÃ¤gungen zusammen. Der Pipe-Operator ist die Kernphilosophie von tidyverse und wird Ihnen Ã¼berall begegnen. Der Operator stammt aus dem Paket magrittr (https://magrittr.tidyverse.org/). Seine Hauptaufgabe ist es, den Code Ã¼bersichtlicher und besser lesbar zu machen (vielleicht nicht gleich zu Beginn der Lernkurve, aber schon bald ğŸ˜)."
  },
  {
    "objectID": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "href": "06-explorative-numerisch.html#die-grammatik-der-datenmanipulation-dplyr",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.4 Die Grammatik der Datenmanipulation â€“ dplyr",
    "text": "6.4 Die Grammatik der Datenmanipulation â€“ dplyr\nDie Funktion count() gehÃ¶rt zum Paket dplyr, das fÃ¼r Datentransformationen zustÃ¤ndig ist. Es ist abermals eine Grammatik. Dieses Paket enthÃ¤lt 5 Grundfunktionen (alle nach Verben benannt, damit man gleich weiÃŸ, was frau tut ğŸ˜„):\n\n\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nfilter()\nWÃ¤hle Daten anhand ihrer Werte\n\n\narrange()\nSortiere Zeilen\n\n\nselect()\nWÃ¤hle Variablen anhand ihrer Namen\n\n\nmutate()\nErstelle neue Variablen als Funktionen vorhandener Variablen\n\n\nsummarize()\nFasse Daten zusammen\n\n\n\nWenn wir nur von einer bestimmten Station die Anzahl der Messwerte wissen mÃ¶chten, dann filtern wir vorher.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nBeim Filtern lÃ¤uft eine logische Abfrage. D. h. es wird bei jedem Eintrag in STATION_ID nachgesehen, ob da der Wert 2667 steht. Wenn da 2667 steht, dann gibt == ein TRUE zurÃ¼ck, wenn da etwas anderes steht, dann gibt == ein FALSE zurÃ¼ck. Und die Funktion filter() behÃ¤lt nur die Zeilen, bei denen == ein TRUE zurÃ¼ckgegeben hat.\nWeiter wichtige logische und relationale Operatoren finden Sie hier in der Hilfe zu filter(). Hier ein paar einfache Beispiele:\n\n\n\n\n\n\n\nOperator\nBedeutung\n\n\n\n\n==/ > / >=\nist die linke Seite gleich / grÃ¶ÃŸer / grÃ¶ÃŸer-gleich als die rechte Seite\n\n\n!=\nist die linke Seite ungleich der rechten Seite\n\n\n\nZudem kann man bei filter() die Anfragen auch kombinieren. Wir wollen z. B. die Stationen KÃ¶ln und Hof haben. | ist der logische Operator oder. Wenn man also sowohl KÃ¶ln als auch Hof haben will, sagt man: finde alles, was entweder gleich KÃ¶ln oder gleich Hof ist.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nDas Gleiche erreicht man mit folgendem Code, indem man Frankfurt ausschlieÃŸt:\n\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\nAlternative kann man auch den Operator %in% verwenden. Dieser ist sehr nÃ¼tzlich, wenn man anhand einer einzelnen Variablen filtert, aber unterschiedliche EintrÃ¤ge auswÃ¤hlen mÃ¶chte (z. B. zwei Messstationen). Es wird bei jeder Zeile in der Variablen STATIONS_ID nun Ã¼berprÃ¼ft, ob hier entweder 2667 oder 2261 stehen.\n\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  count(STATIONS_ID)\n\n\n\n  \n\n\n\n\n6.4.1 Daten plotten\nWir sehen uns die Daten erst mal an, bevor wir weiter machen. Wir plotten die Temperatur. Weil es sich um Zeitreihen handelt, kommt auf die \\(x\\)-Achse die Zeit.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU, color = as_factor(STATIONS_ID))) + \n  geom_line() +\n  labs(x = 'Zeit', y = 'Temperatur (Â°C)', color = 'Stationen')\n\n\n\n\nBeachten Sie, dass wir die Variable zum EinfÃ¤rben, nÃ¤mlichSTATIONS_ID, direkt in ggplot() in eine kategoriale Variable umgewandelt haben. Sonst werden die Farben als Farbverlauf statt drei unterschiedliche Farben, dargestellt.\nDa man erwarten kann, dass sich der Temperaturverlauf innerhalb Deutschlands nicht so stark unterscheidet, Ã¼berdecken sich die Zeitreihen. Das ist fÃ¼r die Darstellung ungÃ¼nstig. Daher wÃ¤re es besser, wenn wir die Zeitreihen in getrennte Grafiken je Station plotten wÃ¼rden. DafÃ¼r gibt es eine neue Funktion aus dem Paket ggplot2, nÃ¤mlich facet_wrap(). Sie kann eine Grafik mithilfe einer kategorialen Variablen in Teilgrafiken aufteilen.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Zeit', y = 'Temperatur (Â°C)')\n\n\n\n\nDa wir die Teilgrafiken untereinander darstellen mÃ¶chten, setzen wir bei facet_wrap() den Parameter nrow = 3. Bei Teilgrafiken kann man auf die FÃ¤rbung der Zeitreihen verzichten.\n\n\n6.4.2 Jahresdurchschnittstemperatur\nWie hoch war die Jahresdurchschnittstemperatur auf den drei Stationen? Um diese Frage zu beantworten, erstellen wir zunÃ¤chst eine neue Variable mit dem Jahr der Messungen. Das kennen Sie bereits aus dem letzten Kapitel. Die Funktion year() gehÃ¶rt zur Bibliothek lubridate. Die Funktion mutate() erstellt die neue Spalte und hÃ¤ngt sie an das Ende des Dataframes.\n\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM))\n\nDa wir die Durchschnittstemperatur fÃ¼r jede Station und jedes Jahr separat berechnen wollen, mÃ¼ssen wir unseren Datensatz nach den Stationen gruppieren. Durch die Gruppierung entstehen intern Gruppen, fÃ¼r die Berechnungen getrennt laufen werden. An den Daten selbst Ã¤ndert sich nichts.\nAls zweiten Schritt nutzen wir dann die Funktion summerise(), die verschiedene statistische Zusammenfassungen der Daten berechnen kann. In diesem Fall mÃ¶chten wir mithilfe der Funktion mean() den Mittelwert berechnen. Wir nennen den neu berechneten Datensatz yearly_means.\n\nyearly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year) %>% \n  summarize(mean_T = mean(TT_TU))\n\nWir erhalten einen Datensatz, der pro Jahr und Station einen Mittelwert der Temperatur enthÃ¤lt. Die Variable, die die mittlere Temperatur enthÃ¤lt, haben wir mean_T genannt. Sie steht in der Zeile summarize(mean_T = mean(TT_TU)) links vom Aufruf der Funktion mean(). Der Code mean(TT_TU) berechnet den Mittelwert der Variablen TT_TU, also der Temperatur.\n\nyearly_means\n\n\n\n  \n\n\n\nDie Berechnung der Jahresmittelwerte ist sehr kritisch zu sehen. Nicht alle berechneten Werte ergeben Sinn. Diskutieren Sie in der Hausaufgabe warum.\n\n\n6.4.3 Monatliche Durchschnittstemperatur und ihre VariabilitÃ¤t\nWie hoch war die monatliche Durchschnittstemperatur auf den verschiedenen Stationen und wie stark schwankte sie? Diese Frage kÃ¶nnen wir beantworten, indem wir Mittelwerte und Standardabweichungen fÃ¼r jeden Monat eines jeden Jahres und jede Station berechnen. FÃ¼r die Berechnung erstellen wir eine weite Spalte mit dem Monat. Die Funktion month() gehÃ¶rt ebenfalls zur Bibliothek lubridate und extrahiert den Monat aus MESS_DATUM.\n\ntemp_humid <- temp_humid %>% \n  mutate(month = month(MESS_DATUM))\n\ntemp_humid\n\n\n\n  \n\n\n\nJetzt kÃ¶nnen wir die Mittelwerte und die Standardabweichungen mit der Funktion summarise() berechnen. Diese Funktion kann gleichzeitig verschiedene statistische Zusammenfassungen berechnen. Den Mittelwert berechnen wir erneut mit der Funktion mean() und die Standardabweichung mit der Funktion sd().\nFÃ¼r die Berechnung gruppieren wir die Daten nach STATIONS_ID, year und month mit der Funktion group_by(). Die Mittelwerte sollen ja je Station, Jahr und Monat berechnet werden. Beim Gruppieren gibt man die Variablennamen ohne AnfÃ¼hrungszeichen durch Kommas getrennt an. Man kann nach einer oder mehreren Variablen gruppieren, die Logik bleibt immer die gleiche, nÃ¤mlich group_by(VARIABLE_1) fÃ¼rs Gruppieren mit einer Variablen oder group_by(VARIABLE_1, VARIABLE_2, VARIABLE_3) fÃ¼r z. B. gruppieren nach drei Variablen.\n\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), sd_T = sd(TT_TU))\n\nmonthly_means\n\n\n\n  \n\n\n\nDie Variable, die die Standardabweichung enthÃ¤lt, haben wir sd_T genannt.\nDas Dataframe monthly_means ist ein gruppiertes tibble. Das ist fÃ¼r die meisten Anwendungen nicht von Belang. Insbesondere Ã¤ndert es nicht die Daten selbst, sondern nur die interne Organisation des tibble. Manchmal stÃ¶rt die Gruppierung jedoch beim Rechnen mit dem Datensatz und wir lÃ¶sen sie wieder auf.\n\nmonthly_means <- ungroup(monthly_means)\n\nUm die monatlichen Daten als Zeitreihen zu plotten, benÃ¶tigen wir noch eine Variable mit dem dazugehÃ¶rigen Datum. Die Funktion parse_date_time() kann aus character richtige Datums- und Zeitobjekte erstellen. Sie ist allgemeiner als die oben verwendete ymd_h() Funktion, da man hier das Format explizit angeben kann. In unserem Fall ist das Format â€˜ymâ€™ fÃ¼r Jahr und Monat.\n\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET'))\n\nmonthly_means\n\n\n\n  \n\n\n\nDer Code paste0(year, month) â€œklebtâ€ die Daten in der Variablen year und month zusammen. Das ist nÃ¶tig, da die Funktion parse_date_time() einen zusammenhÃ¤ngenden Text als Input erwartet und keine zwei getrennten Spalten. Da das Datum auÃŸer dem Jahr und dem Monat noch einen Tag benÃ¶tigt, hat parse_date_time() automatisch den Ersten eines jeden Monats genommen. Beim Erstellen von korrekten Zeitangaben kommt es auch auf die Zeitzone an. Wir sind in Deutschland, da gilt die mitteleuropÃ¤ische Zeit (engl. central European time, CET). Die Zeitzone ist fÃ¼r unsere Daten zwar nicht wirklich relevant, da wir hier Monatsdaten darstellen. Ich wÃ¼rde sie aber trotzdem richtig setzen, da die Standardeinstellung der Funktion parse_date_time(tz = \"UTC\") lautet und fÃ¼r Deutschland falsch ist.\n\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Zeit', y = 'Temperatur (Â°C)', color = 'Messstation')\n\n\n\n\nAlternativ kÃ¶nnen wir die Mittelwerte mit den Standardabweichungen darstellen.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (Â°C)')\n\n\n\n\nOder, weil es gerade SpaÃŸ macht, als halb-transparentes Band ğŸ˜.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (Â°C)')\n\n\n\n\nEin letzter Trick. Die Ãœberschriften fÃ¼r die Teilgrafiken sind ungeschickt, da man die IDs als Mensch einfach nicht zuordnen kann. Weiter oben haben wir einen benannten Vektor definiert, der die Klarnamen enthÃ¤lt.\n\nstation_ids\n\n       2261        1420        2667 \n      \"Hof\" \"Frankfurt\"     \"Koeln\" \n\n\nDiesen Vektor nutzen wir als Titel.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Zeit', y = 'Temperatur (Â°C)')"
  },
  {
    "objectID": "06-explorative-numerisch.html#weiterfÃ¼hrende-literatur-und-videos",
    "href": "06-explorative-numerisch.html#weiterfÃ¼hrende-literatur-und-videos",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.5 WeiterfÃ¼hrende Literatur und Videos",
    "text": "6.5 WeiterfÃ¼hrende Literatur und Videos\n\nR4DS Wickham, Ã‡etinkaya-Rundel, and Grolemund (2023): Kapitel 3 â€œData transformationâ€\nEine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt ğŸ˜„."
  },
  {
    "objectID": "06-explorative-numerisch.html#aufgaben",
    "href": "06-explorative-numerisch.html#aufgaben",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.6 Aufgaben",
    "text": "6.6 Aufgaben\n\n6.6.1 Was bedeutet der Code?\nWas bedeuten die Parameter ymin und ymax im folgenden Code?\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T))\n\n\n\n6.6.2 Welche Mittelwerte sind sinnvoll?\nDiskutieren Sie kritisch, fÃ¼r welche Zeitabschnitte in unseren Daten die Berechnung der Jahresmitteltemperatur sinnvoll ist und interpretiert werden kann. BegrÃ¼nden Sie.\n\n\n6.6.3 Politbarometer\nBearbeiten Sie die Aufgaben KapitelÂ A.3.1 und KapitelÂ A.4.1 aus der Aufgabensammlung."
  },
  {
    "objectID": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "href": "06-explorative-numerisch.html#ihre-arbeit-einreichen",
    "title": "6Â  Exploration von numerischen Daten",
    "section": "6.7 Ihre Arbeit einreichen",
    "text": "6.7 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen.\n\n\n\n\n\nWickham, Hadley, Mine Ã‡etinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.5 Exploration von numerischen Daten",
    "text": "A.5 Exploration von numerischen Daten\n\nA.5.1 Umweltdaten entlang der dÃ¤nischen KÃ¼ste\nDie Datei â€œTemperatur.csvâ€ aus Zuur, Ieno, and Meesters (2009) enthÃ¤lt Messungen von Temperatur, SalinitÃ¤t und Chlorophyll a an 31 Orten entlang der dÃ¤nischen KÃ¼ste. Der Datensatz kann hier heruntergeladen werden. Sie bekommen ihn aber bereits Ã¼ber ILIAS gestellt. Die Daten stammen vom dÃ¤nischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgefÃ¼hrt, mit einer HÃ¤ufigkeit von 0â€“4 Mal pro Monat je nach Jahreszeit.\n\nLesen Sie den Datensatz â€œTemperatur.csvâ€ (auf ILIAS) ein.\nKonvertieren Sie die Spalte Date in ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (facet_wrap()) als Zeitreihen.\nBerechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur fÃ¼r alle Stationen, sowie die Standardabweichungen. Tipp: innerhalb von summarize() mÃ¼ssen Sie n = n() schreiben, um die Anzahl der Messwerte zu erhalten.\nStellen Sie die Monatsmittel der Temperatur als Linien dar. Tipp: Um die Montasnamen darzustellen, nutzen Sie den folgenden Code scale_x_discrete(limits = as_factor(1:12), labels = month.abb). HÃ¤ngen Sie ihn mit einem + an. Was macht dieser Code?\nBeschriften Sie die Grafik sinnvoll.\nFÃ¼gen Sie die Standardabweichungen als Band hinzu.\n\n\n\nA.5.2 Quantile\nWir beschÃ¤ftigen uns mit dem Datensatz possum im Paket openintro.\n\nLaden Sie die Bibliothek und anschlieÃŸend den Datensatz.\nBerechnen Sie\n\n\nDas 1. Quartil\nDas 3. Quartil\nDen Median\n\nDer KÃ¶rper- und KopflÃ¤ngen.\n\nStellen Sie die KÃ¶rper- und KopflÃ¤ngen als Boxplots nebeneinander dar. Nutzen Sie dazu die Bibliothek patchwork.\nStellen Sie die beiden Variablen als Streudiagramm dar (KÃ¶rperlÃ¤ngen auf die \\(x\\)-Achse).\nBerechnen Sie den linearen Korrelationskoeffizienten mit der Funktion cor()."
  },
  {
    "objectID": "07-lineare-regression.html",
    "href": "07-lineare-regression.html",
    "title": "7Â  Lineare Regression",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklÃ¤ren.\nLineare Regression mit einer und mehreren erklÃ¤renden Variablen selbst in R durchfÃ¼hren.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression.html#begriff-regression",
    "href": "07-lineare-regression.html#begriff-regression",
    "title": "7Â  Lineare Regression",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prÃ¤gte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem fÃ¼r den Zusammenhang zwischen der durchschnittlichen KÃ¶rpergrÃ¶ÃŸe der Eltern und der KÃ¶rpergrÃ¶ÃŸe ihrer erwachsenen Kinder. Leider war er nicht nur einer der VÃ¤ter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher grÃ¶ÃŸer waren und umgekehrt, Kinder von Ã¼berdurchschnittlich groÃŸen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (RÃ¼ckkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression.html#idee-der-regression",
    "href": "07-lineare-regression.html#idee-der-regression",
    "title": "7Â  Lineare Regression",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschlieÃŸlich mit solchen linearen Modellen beschÃ¤ftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklÃ¤renden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklÃ¤rende Variable, nÃ¤mlich die DurchschnittsgrÃ¶ÃŸe der Eltern. Die Zielvariable war die zu erwartende GrÃ¶ÃŸe der Kinder. Es ging also nicht darum, die exakte GrÃ¶ÃŸe eines bestimmten Kindes zu berechnen, sondern den Einfluss der DurchschnittsgrÃ¶ÃŸe der Eltern auf die zu erwartende (oder eben mittlere) GrÃ¶ÃŸe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die KÃ¶rpergrÃ¶ÃŸe sein. Sie kann binÃ¤r, kategorial oder eine ZÃ¤hlvariable sein. Auch die erklÃ¤renden Variablen kÃ¶nnen stetig, binÃ¤r oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschÃ¤ftigen."
  },
  {
    "objectID": "07-lineare-regression.html#lineare-regression-mit-einer-erklÃ¤renden-variablen",
    "href": "07-lineare-regression.html#lineare-regression-mit-einer-erklÃ¤renden-variablen",
    "title": "7Â  Lineare Regression",
    "section": "7.3 Lineare Regression mit einer erklÃ¤renden Variablen",
    "text": "7.3 Lineare Regression mit einer erklÃ¤renden Variablen\nDie Formel fÃ¼r die lineare Regression mit einer erklÃ¤renden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklÃ¤rende Variable oder PrÃ¤diktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklÃ¤renden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKÃ¶nnen wir aus der KÃ¶rpermasse der Pinguine deren mittlere FlÃ¼gellÃ¤nge vorhersagen?\nAls Erstes mÃ¼ssen wir untersuchen, ob es Ã¼berhaupt einen plausiblen linearen Zusammenhang zwischen KÃ¶rpermassen und FlÃ¼gellÃ¤ngen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklÃ¤rende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir kÃ¶nnen fÃ¼r die Visualisierung gleich die Gerade hinzu plotten. Das Ã¼bernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst spÃ¤ter kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu kÃ¶nnen, nutzen wir die Funktion lm(). Das steht fÃ¼r engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ PrÃ¤diktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen fÃ¼r die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthÃ¤lt sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigun der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt fÃ¼r ein schÃ¶nes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kÃ¼mmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls NÃ¤chstes mÃ¼ssen wir Ã¼berprÃ¼fen, ob die Residuen in unserem Modell irgendwelche auffÃ¤lligen Muster zeigen. Das wÃ¤re ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklÃ¤rende Variable nicht berÃ¼cksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werde auf der \\(x\\)-Achse die vom Modell angepassten Werte, d.Â h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthÃ¤lt. Die Streuung der Residuen sieht gleich aus fÃ¼r den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafÃ¼r, dass das Modell soweit plausibel fÃ¼r unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein GÃ¼temaÃŸ fÃ¼r das angepasste Modell. Er zeigt, wie viel VariabilitÃ¤t der Zielvariablen, hier also der FlÃ¼gellÃ¤ngen, wird vom Modell erklÃ¤rt. Mit anderen Worten, wenn wir das Modell verwenden und die Information Ã¼ber die KÃ¶rpermasse der Tiere nutzen, um wie viel sinkt dann die VariabilitÃ¤t unserer Vorhersagen der FlÃ¼gellÃ¤ngen.\nDen Determinationskoeffizienten \\(R^2\\) kÃ¶nnen wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der VariabilitÃ¤t der FlÃ¼gellÃ¤ngen erklÃ¤rt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche FlÃ¼gellÃ¤nge sich Ã¤ndert, wenn die KÃ¶rpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche FlÃ¼gellÃ¤nge, wenn die KÃ¶rpermasse 0 ist. Das ist keine relevante GrÃ¶ÃŸe, da KÃ¶rpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression.html#aufgaben",
    "href": "07-lineare-regression.html#aufgaben",
    "title": "7Â  Lineare Regression",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Vertiefung des linearen Modells\nArbeiten Sie das Tutorial Regression modeling: 4 - Interpreting regression models durch.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorial durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie fÃ¼r einen Pinguin mit der KÃ¶rpermasse 5000 g die zu erwartende FlÃ¼gellÃ¤nge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:"
  },
  {
    "objectID": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression.html#ihre-arbeit-einreichen",
    "title": "7Â  Lineare Regression",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html",
    "href": "07-lineare-regression-ein-pred.html",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "",
    "text": "Allgemeinen Aufbau eines Regressionsmodells erklÃ¤ren.\nLineare Regression mit einer erklÃ¤renden Variablen selbst in R durchfÃ¼hren.\nParameter des linearen Regressionsmodells interpretieren."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#begriff-regression",
    "href": "07-lineare-regression-ein-pred.html#begriff-regression",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "7.1 Begriff Regression",
    "text": "7.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen prÃ¤gte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem fÃ¼r den Zusammenhang zwischen der durchschnittlichen KÃ¶rpergrÃ¶ÃŸe der Eltern und der KÃ¶rpergrÃ¶ÃŸe ihrer erwachsenen Kinder. Leider war er nicht nur einer der VÃ¤ter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher grÃ¶ÃŸer waren und umgekehrt, Kinder von Ã¼berdurchschnittlich groÃŸen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (RÃ¼ckkehr) zur Mitte."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "href": "07-lineare-regression-ein-pred.html#idee-der-regression",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "7.2 Idee der Regression",
    "text": "7.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschlieÃŸlich mit solchen linearen Modellen beschÃ¤ftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erklÃ¤renden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erklÃ¤rende Variable, nÃ¤mlich die DurchschnittsgrÃ¶ÃŸe der Eltern. Die Zielvariable war die zu erwartende GrÃ¶ÃŸe der Kinder. Es ging also nicht darum, die exakte GrÃ¶ÃŸe eines bestimmten Kindes zu berechnen, sondern den Einfluss der DurchschnittsgrÃ¶ÃŸe der Eltern auf die zu erwartende (oder eben mittlere) GrÃ¶ÃŸe der Kinder. Es ging also nicht um bestimmte Eltern-Kind-Paare.\nDie Zielvariable muss nicht immer stetig wie die KÃ¶rpergrÃ¶ÃŸe sein. Sie kann binÃ¤r, kategorial oder eine ZÃ¤hlvariable sein. Auch die erklÃ¤renden Variablen kÃ¶nnen stetig, binÃ¤r oder kategorial sein. Das macht die Regressionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen beschÃ¤ftigen."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklÃ¤renden-variablen",
    "href": "07-lineare-regression-ein-pred.html#lineare-regression-mit-einer-numerischen-erklÃ¤renden-variablen",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "7.3 Lineare Regression mit einer numerischen erklÃ¤renden Variablen",
    "text": "7.3 Lineare Regression mit einer numerischen erklÃ¤renden Variablen\nDie Formel fÃ¼r die lineare Regression mit einer erklÃ¤renden Variablen haben Sie bereits in der Vorlesung kennengelernt:\n\n\\(y=b_0+b_1 \\cdot x+e\\)\n\n\\(y\\): Zielvariable (engl. outcome)\n\\(x\\): erklÃ¤rende Variable oder PrÃ¤diktor (engl. predictor)\n\\(b_0\\): \\(y\\)-Achsenabschnitt\n\\(b_1\\): Steigung der Geraden\n\\(e\\): Fehlerterm\n\n\nWir nutzen den Datensatz penguins aus dem Paket palmerpenguins, um das lineare Modell mit einer erklÃ¤renden Variablen anzupassen. Unsere Forschungsfrage lautet:\nKÃ¶nnen wir aus der KÃ¶rpermasse der Pinguine deren mittlere FlÃ¼gellÃ¤nge vorhersagen?\nAls Erstes mÃ¼ssen wir untersuchen, ob es Ã¼berhaupt einen plausiblen linearen Zusammenhang zwischen KÃ¶rpermassen und FlÃ¼gellÃ¤ngen gibt. Dazu stellen wir die beiden Variablen in einem Streudiagramm dar. Dabei wird die erklÃ¤rende Variable auf der \\(x\\)-Achse und die Zielvariable auf der \\(y\\)-Achse dargestellt.\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nBei diesem Bild kann man von einem linearen Zusammenhang ausgehen. Wir kÃ¶nnen fÃ¼r die Visualisierung gleich die Gerade hinzu plotten. Das Ã¼bernimmt das geom_smooth. Allerdings wird hier die Gerade lediglich dargestellt, die Modellparameter werden nicht gespeichert. Der Parameter method = 'lm' zeigt, dass wir eine Gerade plotten wollen und se = FALSE verhindert das Darstellen der Konfidenzintervalle (das werden wir erst spÃ¤ter kennenlernen).\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = 'lm', se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n7.3.1 Anpassen des Modells\nUm das lineare Modell anzupassen und danach die Parameter interpretieren zu kÃ¶nnen, nutzen wir die Funktion lm(). Das steht fÃ¼r engl. linear model.\n\nmod <- lm(formula = flipper_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\nDer Parameter des Aufrufs ist wie folgt:\n\nformula = flipper_length_mm ~ body_mass_g: Das ist die Geradengleichung, die wir anpassen wollen. Die Struktur ist \\(y ~ x\\), also Zielvariable ~ PrÃ¤diktor. Man kann formula = weggelassen und gleich flipper_length_mm ~ body_mass_g schreiben.\ndata = penguins: Datensatz, in dem die Variablen zu finden sind\nna.action = na.exclude: Die fehlenden Werte sollen fÃ¼r die Modellierung ignoriert werden.\n\n\n\n7.3.2 Modellparameter\nDie Modellergebnisse haben wir dem Objekt mod zugeordnet. Das enthÃ¤lt sowohl die Modellparameter als auch die Residuen und die angepassten Werte. Die Modellparameter sind der \\(y\\)-Achsenabschnitt (engl. intercept) und die Steigung der Geraden. Die Funktion tidy()aus dem Paket broom() sorgt fÃ¼r ein schÃ¶nes Layout der Tabelle:\n\nmod %>% \n  tidy()\n\n\n\n  \n\n\n\nDer \\(y\\)-Achsenabschnitt ist also 136,7 mm und die Steigung 0,02 mm/g. Um die anderen Spalten kÃ¼mmern wir uns im weiteren Verlauf des Kurses.\n\n\n7.3.3 Residualplot\nAls NÃ¤chstes mÃ¼ssen wir Ã¼berprÃ¼fen, ob die Residuen in unserem Modell irgendwelche auffÃ¤lligen Muster zeigen. Das wÃ¤re ein Hinweis darauf, dass wir entweder ein falsches Modell (z. B. linear statt nicht-linear) angepasst oder evtl. eine erklÃ¤rende Variable nicht berÃ¼cksichtigt haben.\nDie Residuen werden in einem sogen. Residualplot dargestellt. Dabei werden auf der \\(x\\)-Achse die vom Modell angepassten Werte, d.Â h. die Werte auf der Geraden, dargestellt, und auf der \\(y\\)-Achse die Residuen. Um den Aufruf zu ggplot() zu vereinfachen, speichern wir die Residuen und die angepassten Werte direkt im Datensatz penguins mithilfe von `mutate().\n\npenguins <- penguins %>% \n  mutate(residuals = residuals(mod),\n         fitted = fitted(mod))\n\nDer Residualplot sieht wie folgt aus:\n\nggplot(data = penguins, mapping = aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMan bekommt eine Warnung, dass der Datensatz 2 Fehlwerte enthÃ¤lt. Die Streuung der Residuen sieht gleich aus fÃ¼r den gesamten Bereich der angepassten Werte und es sind keine Muster zu erkennen. Es spricht also dafÃ¼r, dass das Modell soweit plausibel fÃ¼r unsere Daten ist.\n\n\n7.3.4 Wie gut ist das Modell?\nDer Determinationskoeffizient \\(R^2\\) ist ein GÃ¼temaÃŸ fÃ¼r das angepasste Modell. Er zeigt, wie viel VariabilitÃ¤t der Zielvariablen, hier also der FlÃ¼gellÃ¤ngen, wird vom Modell erklÃ¤rt. Mit anderen Worten, wenn wir das Modell verwenden und die Information Ã¼ber die KÃ¶rpermasse der Tiere nutzen, um wie viel sinkt dann die VariabilitÃ¤t unserer Vorhersagen der FlÃ¼gellÃ¤ngen.\nDen Determinationskoeffizienten \\(R^2\\) kÃ¶nnen wir mit der Funktion glance() anzeigen lassen. Er steht gleich in der ersten Spalte r.squred.\n\nmod %>%\n  glance()\n\n\n\n  \n\n\n\nDer Determinationskoeffizient ist gerundet 0.76. Das bedeutet, dass unser Modell ca. 76% der VariabilitÃ¤t der FlÃ¼gellÃ¤ngen erklÃ¤rt. Es ist ein sehr gutes Modell.\n\n\n7.3.5 Interpretation der Modellparameter\nDie Steigung des linearen Modells beschreibt, um wie viel die durchschnittliche FlÃ¼gellÃ¤nge sich Ã¤ndert, wenn die KÃ¶rpermasse des Tieres um eine Einheit (also ein g) steigt. Der \\(y\\)-Achsenabschnitt beschreibt die durchschnittliche FlÃ¼gellÃ¤nge, wenn die KÃ¶rpermasse 0 ist. Das ist keine relevante GrÃ¶ÃŸe, da KÃ¶rpermassen von 0 nicht beobachtet werden. Allerdings darf man den \\(y\\)-Achsenabschnitt nicht einfach weglassen, da sonst die Gerade nicht optimal an die Daten angepasst wird."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#aufgaben",
    "href": "07-lineare-regression-ein-pred.html#aufgaben",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "7.4 Aufgaben",
    "text": "7.4 Aufgaben\n\n7.4.1 Tutorium\nBearbeiten Sie das Tutorium â€œRegressionsmodellierung: 4 - Interpretation von Regressionsmodellenâ€. Sie kÃ¶nnen entweder die deutsche Ãœbersetzung oder das englische Original bearbeiten. Das Tutorium muss nicht hochgeladen werden.\n\n\n7.4.2 Vorhersagen\nNachdem Sie das Tutorium durchgearbeitet haben, nutzen Sie Ihr neues Wissen, und\n\nBerechnen Sie fÃ¼r einen Pinguin mit der KÃ¶rpermasse 5000 g die zu erwartende FlÃ¼gellÃ¤nge. Tipp: new_data <- data.frame(body_mass_g = 5000).\nStellen Sie diesen vorhergesagten Wert dar. Tipp: Nutzen Sie die Funktion augment(). Es sollte die folgende Abbildung dabei entstehen:\n\n\n\n\n\n\nDiese Aufgaben ist hochzuladen."
  },
  {
    "objectID": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "href": "07-lineare-regression-ein-pred.html#ihre-arbeit-einreichen",
    "title": "7Â  Lineare Regression mit einer erklÃ¤renden Variablen",
    "section": "7.5 Ihre Arbeit einreichen",
    "text": "7.5 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die MusterlÃ¶sung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4."
  },
  {
    "objectID": "index.html#lernergebnisse-intended-learning-outcomes",
    "href": "index.html#lernergebnisse-intended-learning-outcomes",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "Lernergebnisse (intended learning outcomes)",
    "text": "Lernergebnisse (intended learning outcomes)\n\nDatenanalyse\n\nDaten fÃ¼r statistische Analysen aufbereiten\nExplorative (beschreibende) Datenanalyse durchfÃ¼hren\nDaten visualisieren\nErgebnisse der Analysen reproduzierbar darstellen\n\nStatistische Methoden\n\nEinfache statistische KenngrÃ¶ÃŸen (Mittelwert, Standardabweichung etc.) berechnen\nEine Korrelation zwischen zwei DatensÃ¤tzen berechnen\nHypothesentests durchfÃ¼hren und die Ergebnisse richtig berichten und interpretieren\nKonfidenzintervalle berechnen und interpretieren\nEin lineares Modell berechnen, die Ergebnisse darstellen und interpretieren"
  },
  {
    "objectID": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nPÃ¼nktlichkeit in der Vorlesung und den Ãœbungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegenÃ¼ber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen ğŸ˜„"
  },
  {
    "objectID": "index.html#sinn-und-unsinn-dieses-skripts",
    "href": "index.html#sinn-und-unsinn-dieses-skripts",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "Sinn und Unsinn dieses Skripts",
    "text": "Sinn und Unsinn dieses Skripts\nDieses Skript ist ein lebendiges Begleitdokument des Kurses. Es wird laufend angepasst und aktualisiert.\nIch nutze verschiedenfarbige BlÃ¶cke, um wichtige Stellen hervorzuheben:\n\nInfoblock\n\n\n\nAchtung, wichtig!\n\n\n\nDefinition\n\n\n\nLernziele"
  },
  {
    "objectID": "index.html#inspiration-quellen-und-danksagung",
    "href": "index.html#inspiration-quellen-und-danksagung",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "Inspiration, Quellen und Danksagung",
    "text": "Inspiration, Quellen und Danksagung\nDieses Skript baut stark auf folgenden freien Quellen auf:\n\nr4ds: Wickham, Ã‡etinkaya-Rundel, and Grolemund (2023)\nggplot2: Wickham (2020)\nModernDive: Ismay and Kim (2021)\nIntroduction to Modern Statistics: (IMS2021?)\n\nDen Autoren dieser BÃ¼cher gilt ein groÃŸer Dank fÃ¼r Ihren Beitrag zur -Community !"
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "Ãœbung zur Vorlesung Statistik und Datenanalyse",
    "section": "Reproduzierbarkeit",
    "text": "Reproduzierbarkeit\nDieses Skript wurde in RStudio mit Quarto geschrieben und in R version 4.4.1 (2024-06-14) gebaut. Folgende Pakete werden fÃ¼r die Beispiele und Ãœbungen benÃ¶tigt:\n\n\n\n\npackage\nversion\nsource\n\n\n\n\ndabestr\n2023.9.12\nCRAN (R 4.3.2)\n\n\nemojifont\n0.5.5\nCRAN (R 4.2.0)\n\n\nfontawesome\n0.5.2\nCRAN (R 4.3.2)\n\n\ngapminder\n1.0.0\nCRAN (R 4.3.2)\n\n\ninfer\n1.0.7\nCRAN (R 4.4.1)\n\n\nlubridate\n1.9.3\nCRAN (R 4.3.2)\n\n\nmoderndive\n0.5.5\nCRAN (R 4.3.2)\n\n\ntidyverse\n2.0.0\nCRAN (R 4.3.2)\n\n\n\n\nDie komplette Information zur Session lautet:\n\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Berlin\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2      vctrs_0.6.5       cli_3.6.2         knitr_1.48       \n [5] rlang_1.1.3       xfun_0.46         stringi_1.8.3     purrr_1.0.2      \n [9] generics_0.1.3    assertthat_0.2.1  jsonlite_1.8.8    glue_1.7.0       \n[13] rprojroot_2.0.4   htmltools_0.5.7   fansi_1.0.6       rmarkdown_2.25.2 \n[17] emo_0.0.0.9000    tibble_3.2.1      evaluate_0.23     fontawesome_0.5.2\n[21] fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4   stringr_1.5.1    \n[25] compiler_4.4.1    sessioninfo_1.2.2 pkgconfig_2.0.3   htmlwidgets_1.6.2\n[29] timechange_0.2.0  rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[33] utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3    tools_4.4.1      \n[37] lubridate_1.9.3   desc_1.4.2       \n\n\n\nDieses Skript ist lizenziert unter Creative Commons Namensnennung - Nicht-kommerziell - Weitergabe unter gleichen Bedingungen 4.0 International.\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for Data Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine Ã‡etinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "09-tests-infer.html#workflow-in-infer",
    "href": "09-tests-infer.html#workflow-in-infer",
    "title": "8Â  Hypothesentests mit Randomisierung",
    "section": "8.2 Workflow in infer",
    "text": "8.2 Workflow in infer\nDas Paket infer bietet ein einheitliches Framework fÃ¼r Hypothesentests (AbbildungÂ 8.1). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen und ein Verb fÃ¼r die Visualisierung der Ergebnisse:\n\nspecify() Variablen festlegen\nhypothesize() Nullhypothese definieren\ngenerate() Daten unter der Nullhypothese generieren\ncalculate() Stichprobenverteilung (d.h. Verteilung der Teststatistik) berechnen\nvisualize() Stichprobenverteilung darstellen\n\nMit get_p_value kann man den \\(p\\)-Wert berechnen und mit shade_p_value diesen darstellen lassen.\n\n\n\nAbbildungÂ 8.1: Allgemeines Vorgehen bei Hypothesentests (Quelle: https://infer.netlify.app/)."
  },
  {
    "objectID": "09-tests-infer.html#aufgaben",
    "href": "09-tests-infer.html#aufgaben",
    "title": "8Â  Hypothesentests mit Randomisierung",
    "section": "8.4 Aufgaben",
    "text": "8.4 Aufgaben\n\n8.4.1 Vertiefung des Themas Zufall und VariabilitÃ¤t\nArbeiten Sie das Tutorium â€œGrundlagen der Inferenz: 1 - StichprobenvariabilitÃ¤tâ€ oder das englische Original Foundations of inference: 1 - Sampling Variability durch."
  },
  {
    "objectID": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "href": "09-tests-infer.html#studiendauer-in-werdeschlau",
    "title": "8Â  Hypothesentests mit Randomisierung",
    "section": "8.1 Studiendauer in Werdeschlau",
    "text": "8.1 Studiendauer in Werdeschlau\nWir beschÃ¤ftigen uns mit einem fiktiven Beispiel.\nAn der (kleinen) UniversitÃ¤t Werdeschlau mÃ¶chte man wissen, ob die vor einiger Zeit eingefÃ¼hrte Studienordnung die Studiendauer verÃ¤ndert hat. Dazu werden 300 Studierende zufÃ¤llig Ã¼ber die Dauer ihres Studiums befragt. ZusÃ¤tzlich werden noch andere Daten erhoben, aber mit diesen beschÃ¤ftigen wir uns in einer anderen Ãœbung.\n\n8.1.1 Simulation der Grundgesamtheit\nBei statistischer Inferenz geht es unter anderem darum, die Begriffe Zufall und VariabilitÃ¤t zu quantifizieren. Um diese Konzepte zu verstehen, helfen Computerexperimente. DafÃ¼r erstellen wir uns unsere eigene Grundgesamtheit aller Studierenden an der UniversitÃ¤t Werdeschlau. Das hat den Vorteil, dass wir viele verschiedene Befragungen durchfÃ¼hren kÃ¶nnen, die VariabilitÃ¤t der Antworten analysieren und dabei immer mit den wahren Parametern der Grundgesamtheit vergleichen kÃ¶nnen.\nWir erstellen zunÃ¤chst die Grundgesamtheit. Die Zeile set.seed(123) sorgt fÃ¼r reproduzierbare Ergebnisse.\n\nset.seed(123)\n\npop_size <- 12000\nstudent_id <- 1:pop_size\n  \nanreise <- c(runif(n = pop_size * 0.8, min = 5, max = 40),\n             runif(n = pop_size * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = pop_size, replace = TRUE)\n\nstudienordnung <- sample(c('alt', 'neu'), size = pop_size, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nstudiendauer <- rnorm(n = pop_size, mean = 3.5, sd = 0.6)\n\nWir setzen geschlecht, wohnort, studiendauer, studienordnung und anreise zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, studiendauer, studienordnung, anreise)\n\n\n\n8.1.2 Befragung simulieren\nIn der RealitÃ¤t werden natÃ¼rlich nicht alle 12000 Studierende befragt (wer hat schon so viele KapazitÃ¤ten?), sondern eine zufÃ¤llige Stichprobe erhoben, also eine Teilmenge der Grundgesamtheit.\nUm unsere Stichprobe zu erstellen, ziehen wir 300 Studierende ohne ZurÃ¼cklegen aus unserer Grundgesamtheit. Das entspricht einer einmaligen Befragung von 300 zufÃ¤llig ausgewÃ¤hlten Studierenden.\n\nset.seed(345)\n\nbefragung_size <- 300\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nWir berechnen den Mittelwert der Studiendauer, jeweils fÃ¼r die alte und neue Studienordnung.\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nWie groÃŸ ist die Differenz der Mittelwerte?\n\nstat_obs$dauer[1] - stat_obs$dauer[2]\n\n[1] -0.1183631\n\n\nWie verÃ¤ndert sich die Differenz, wenn wir zufÃ¤lligerweise andere Studierende befragt hÃ¤tten? Wir wÃ¤hlen neue Studierende aus und wiederholen die Berechnung des Mittelwerts der Studiendauer.\n\nset.seed(987)\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nstat_obs <- befragung %>% \n  group_by(studienordnung) %>% \n  summarise(dauer = mean(studiendauer))\n\nstat_obs\n\n\n\n  \n\n\n\nFÃ¼r diese Gruppe der Befragten betrÃ¤gt die Differenz der Mittelwerte 0.0323477."
  },
  {
    "objectID": "09-tests-infer.html#hypothesentest-durchfÃ¼hren",
    "href": "09-tests-infer.html#hypothesentest-durchfÃ¼hren",
    "title": "8Â  Hypothesentests mit Randomisierung",
    "section": "8.3 Hypothesentest durchfÃ¼hren",
    "text": "8.3 Hypothesentest durchfÃ¼hren\n\n8.3.1 Schritt 1: Nullhypothese und Alternativhypothese festlegen\nUnsere Forschungsfrage lautet: Hat sich die Studiendauer durch die EinfÃ¼hrung der neuen Studienordnung verÃ¤ndert? Daraus ergeben sich folgende Hypothesen:\n\nNullhypothese H\\(_0\\): Die Studiendauer hat sich durch die EinfÃ¼hrung der neuen Studienordnung nicht verÃ¤ndert. Sie ist gleich geblieben.\nAlternativhypothese H\\(_A\\): Die Studiendauer hat sich durch die EinfÃ¼hrung der neuen Studienordnung verÃ¤ndert.\n\nDie Alternativhypothese ist unsere eigentliche Forschungsfrage. Da wir nicht wissen, in welche Richtung die Ã„nderungen erfolgt sein kÃ¶nnte (VerlÃ¤ngerung oder VerkÃ¼rzung der Studiendauer), formulieren wir eine sogenannte beidseitige Alternativhypothese. Beidseitig heiÃŸt, dass Ã„nderungen in beide Richtungen interessant sind.\nWir berechnen zunÃ¤chst die tatsÃ¤chlich in den Daten (der Befragung) beobachtete Differenz zwischen den Studiendauern nach der alten und der neuen Studienordnung, also unsere Teststatistik. Die Differenz wird als alt \\(-\\) neu berechnet. Die Funktion observe() im Paket infer berechnet diese Teststatistik.\n\nd_hat <- befragung %>% \n  observe(formula = studiendauer ~ studienordnung,\n          stat = \"diff in means\", \n          order = c('alt', 'neu'))\n\nd_hat\n\n\n\n  \n\n\n\n\n\n8.3.2 Schritt 2: Simulationsexperimente durchfÃ¼hren\nUm Daten unter der Nullhypothese, d.Â h. wenn die Nullhypothese gilt, zu produzieren, permutieren wir 10000 Mal die Variable studienordnung. Denn, wenn die Studiendauer nicht von der Studienordnung abhÃ¤ngt, dann sind diese beiden Variablen unabhÃ¤ngig. Das legt die Zeile hypothesize(null = \"independence\") fest. Damit wir alle dieselben Ergebnisse bekommen, setzen wir erneut set.seed().\n\nset.seed(56)\n\nnull_dist <- befragung %>%\n  specify(studiendauer ~ studienordnung) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 10000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c('alt', 'neu'))\n\n\n\n8.3.3 Schritt 3: Ergebnisse darstellen\nWir stellen die Verteilung der Teststatistiken unter der Nullhypothese als ein Histogramm dar und zeichnen zusÃ¤tzlich ein, wo sich die beobachtete Teststatistik (d.Â h. der beobachtete Unterschied der Mittelwerte) befindet als vertikale rote Linie. Die schattierten Bereiche zeigen Teststatistiken aus den Permutationen, die so extrem oder noch extremer sind, als die beobachtete Teststatistik von 0.0323477. Da unsere Alternativhypothese lautet, dass sich die Studiendauer verÃ¤ndert hat, betrachten wir extreme Werte sowohl bei der VerlÃ¤ngerung als auch bei der VerkÃ¼rzung der Studiendauer als Evidenz gegen die Nullhypothese und zugunsten der Alternativhypothese. Daher fÃ¤rben wird die Bereiche links und spiegelbildlich rechts der beobachteten Teststatistik ein.\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n\n\n\n8.3.4 Schritt 4: \\(p\\)-Wert berechnen und Schlussfolgerungen ziehen\nDer folgende Code berechnet den \\(p\\)-Wert. Der \\(p\\)-Wert gibt uns die Wahrscheinlichkeit an, eine Teststatistik (also die Differenz der Mittelwerte) so extrem oder noch extremer als 0.0323477 zu beobachten, wenn die Nullhypothese tatsÃ¤chlich korrekt ist. In anderen Worten, wenn wir in infer Daten generieren unter der Nullhypothese (d.Â h. Ã¼bereinstimmend mit der Nullhypothese), dann kommt eine Differenz von 0.0323477 oder noch grÃ¶ÃŸer und spiegelbildlich von -0.0323477 oder noch kleiner, mit einer Wahrscheinlichkeit von \\(p\\) vor. Um den \\(p\\)-Wert zu berechnen, rechnen wir den Anteil der eingefÃ¤rbten Bereiche aus.\n\nnull_dist %>%\n  get_p_value(obs_stat = d_hat, direction = \"two-sided\")\n\n\n\n  \n\n\n\nWir sehen also, dass Differenzen zwischen den Mittelwerten von 0.0323477 oder noch grÃ¶ÃŸer und spiegelbildlich von -0.0323477 oder noch kleiner in 61.92% der FÃ¤lle vorkommen, wenn die Nullhypothese gilt. Eine solche Differenz ist also nichts Besonderes. Unser Signifikanzniveau ist \\(\\alpha = 0.05\\). Da \\(p > \\alpha\\), behalten wir die Nullhypothese bei. Es gibt also keinen Unterschied in der Studiendauer zwischen der alten und der neuen Studienordnung."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#variabilitÃ¤t-von-schÃ¤tzungen",
    "href": "10-konfidenzintervall-infer.html#variabilitÃ¤t-von-schÃ¤tzungen",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.1 VariabilitÃ¤t von SchÃ¤tzungen",
    "text": "9.1 VariabilitÃ¤t von SchÃ¤tzungen\nIn der Vorlesung und im KapitelÂ 8 haben Sie erfahren, dass Statistiken aus zufÃ¤llig gezogenen Stichproben dem Zufall unterliegen. Sie sind Zufallsvariablen. Wenn wir Parameter der Grundgesamtheit schÃ¤tzen (z. B. Mittelwert oder Anteil) oder in Experimenten die EffektstÃ¤rke bestimmen mÃ¶chten, dann ist es eher unwahrscheinlich, dass wir den wahren Parameter ganz genau treffen. Daher ist es sinnvoll, bei einer SchÃ¤tzung einen Bereich von plausiblen Werten, das sogenannte Konfidenzintervall anzugeben."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#studiendauer-in-werdeschlau",
    "href": "10-konfidenzintervall-infer.html#studiendauer-in-werdeschlau",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.2 Studiendauer in Werdeschlau",
    "text": "9.2 Studiendauer in Werdeschlau\nWir beschÃ¤ftigen uns erneut mit unserem fiktiven Beispiel der Studierenden an der UniversitÃ¤t Werdeschlau. Diesmal interessieren wir uns dafÃ¼r fÃ¼r den Anteil der Studierenden, die auf dem Land wohnen.\n\n9.2.1 Simulation der Grundgesamtheit und einer Befragung\nWir simulieren erneut unsere Grundgesamtheit.\n\nset.seed(123)\n\npop_size <- 12000\nstudent_id <- 1:pop_size\n  \nanreise <- c(runif(n = pop_size * 0.8, min = 5, max = 40),\n             runif(n = pop_size * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = pop_size, replace = TRUE)\n\nstudienordnung <- sample(c('alt', 'neu'), size = pop_size, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nstudiendauer <- rnorm(n = pop_size, mean = 3.5, sd = 0.6)\n\nWir setzen geschlecht, wohnort, studiendauer, studienordnung und anreise zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, studiendauer, studienordnung, anreise)\n\nWie im KapitelÂ 8, simulieren wir eine Befragung von 300 Studierenden, indem wir eine zufÃ¤llige Stichprobe (ohne ZurÃ¼cklegen) aus den 1200 Studierenden (Grundgesamtheit) auswÃ¤hlen.\n\nset.seed(345)\n\nbefragung_size <- 300\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nUnsere Forschungsfrage lautet: Wie groÃŸ ist der Anteil der Studierenden, die auf dem Land wohnen. Wir mÃ¶chten aus der eben gewonnenen Stichprobe, den wahren Parameter (Anteil der Studierenden, die auf dem Land wohnen, in der Grundgesamtheit), den wir mit \\(p\\) bezeichnen schÃ¤tzen.\nDie beste SchÃ¤tzung fÃ¼r \\(p\\) ist der Anteil der Studierenden, die auf dem Land wohnen, den wir in der Befragung, d.Â h. unsere zufÃ¤llige Stichprobe beobachten. Diesen Anteil nennen wir \\(\\hat{p}\\) und die Variable p_hat.\nZunÃ¤chst zÃ¤hlen wir einfach die Studierenden der verschiedenen Wohnorte.\n\nbefragung %>% \n  count(wohnort)\n\n\n\n  \n\n\n\nWie verÃ¤ndern sich diese Zahlen, wenn wir zufÃ¤lligerweise andere Studierende befragt hÃ¤tten? Wir wÃ¤hlen neue Studierende aus und wiederholen die Berechnung des Mittelwerts der Studiendauer, Ã¤hnlich wie in KapitelÂ 8.\n\nset.seed(987)\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\nbefragung %>% \n  count(wohnort)\n\n\n\n  \n\n\n\nDer Anteil der Studierenden auf dem Land lÃ¤sst sich wie folgt berechnen:\n\np_hat <- befragung %>% \n  group_by(wohnort) %>% \n  summarise(prop = n()/befragung_size)\n\np_hat\n\n\n\n  \n\n\n\nEs wohnen also 44.3% auf dem Land und entsprechend 55.7% in der Stadt. Dass beide Anteile berechnet werden, soll uns hier nicht stÃ¶ren. NatÃ¼rlich sind die beiden Anteile zusammengerechnet immer gleich 1.\nErwartungsgemÃ¤ÃŸ bringt jede Wiederholung der Befragung etwas andere Ergebnisse."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#workflow-in-infer",
    "href": "10-konfidenzintervall-infer.html#workflow-in-infer",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.3 Workflow in infer",
    "text": "9.3 Workflow in infer\nDas Paket infer bietet ein einheitliches Framework sowohl fÃ¼r Hypothesentests als auch fÃ¼r die Berechnung von Konfidenzintervallen (AbbildungÂ 8.1). Es hat 4 Verben, die den oben beschriebenen Prozess der Hypothesentests vereinheitlichen, und ein Verb fÃ¼r die Visualisierung der Ergebnisse:\n\nspecify() Variablen festlegen\nhypothesize() Nullhypothese definieren\ngenerate() Daten unter der Nullhypothese generieren\ncalculate() Stichprobenverteilung (d.h. Verteilung der Teststatistik) berechnen\nvisualize() Stichprobenverteilung darstellen\n\nFÃ¼r die Berechnung der Konfidenzintervalle benÃ¶tigen wir keine Hypothese (also kein hypothesize()) und keine \\(p\\)-Werte. Alle anderen Funktionen sind nach wie vor notwendig. Das Berechnen des Konfidenzintervalls Ã¼bernimmt die Funktion get_confidence_interval()."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen",
    "href": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.4 Konfidenzintervalle berechnen",
    "text": "9.4 Konfidenzintervalle berechnen\n\n9.4.1 Schritt 1:\nUnsere Forschungsfrage lautet:\n\n\n9.4.2 Schritt 2: Bootstrappen\n\n\n9.4.3 Schritt 3: Ergebnisse darstellen\n\n\n9.4.4 Schritt 4: Schlussfolgerungen ziehen"
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#kleine-zusammenfassung",
    "href": "10-konfidenzintervall-infer.html#kleine-zusammenfassung",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.5 Kleine Zusammenfassung",
    "text": "9.5 Kleine Zusammenfassung\n\n\nGrundgesamtheit: alle Studierenden der UniversitÃ¤t Werdeschlau\nzufÃ¤llige Stichprobe: eine zufÃ¤llig ausgesuchte Gruppe von Studierenden\nParameter der Grundgesamtheit: z. B. der wahre Anteil von Studierenden, die in der Stadt oder auf dem Land leben\nSchÃ¤tzer fÃ¼r diesen Parameter der Grundgesamtheit: Anteil der Studierenden, die in der Stadt oder auf dem Land leben, berechnet aus der zufÃ¤lligen Stichprobe. Da die Stichprobe zufÃ¤llig ist, kann man davon ausgehen, dass sie reprÃ¤sentativ fÃ¼r die Grundgesamtheit ist und der SchÃ¤tzer unverzerrt (unbiased, d.Â h. ohne einen systematischen Fehler).\nInferenz: schlieÃŸen auf die Grundgesamtheit darf man, wenn die Stichprobe zufÃ¤llig erhoben wurde und reprÃ¤sentativ fÃ¼r die Fragestellung ist.\n\n\nDie Begriffe Statistik, SchÃ¤tzer, SchÃ¤tzfunktion und Stichprobenfunktion werden als Synonyme verwendet. Die Statistik ist ja auch eine Funktion, da sie mit einer Formel eine Zahl aus Daten (Stichprobe) berechnet. Sie fasst die Stichprobe also zusammen."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#aufgaben",
    "href": "10-konfidenzintervall-infer.html#aufgaben",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.6 Aufgaben",
    "text": "9.6 Aufgaben\n\n9.6.1 Vertiefung des Themas ParameterschÃ¤tzung und Konfidenzintervalle\nArbeiten Sie das Tutorium â€œGrundlagen der Inferenz: 4 - Parameter und Konfidenzintervalleâ€ oder das englische Original Foundations of inference: 4 - Parameters and confidence intervals durch."
  },
  {
    "objectID": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen-mit-infer",
    "href": "10-konfidenzintervall-infer.html#konfidenzintervalle-berechnen-mit-infer",
    "title": "9Â  Konfidenzintervalle mit Bootstrap",
    "section": "9.4 Konfidenzintervalle berechnen mit infer",
    "text": "9.4 Konfidenzintervalle berechnen mit infer\n\n9.4.1 Schritt 1: Berechnen der Statistik\nUnsere Forschungsfrage lautet: Wie groÃŸ ist der Anteil der Studierenden, die auf dem Land wohnen. Wir mÃ¶chten diesen Anteil durch unsere Befragung schÃ¤tzen und ein Konfidenzintervall fÃ¼r die SchÃ¤tzung angeben.\nDie SchÃ¤tzung haben wir bereits:\n\np_hat\n\n\n\n  \n\n\n\n\n\n9.4.2 Schritt 2: Bootstrappen\nIm nÃ¤chsten Schritt ziehen wir aus unserer Stichprobe befragung mit ZurÃ¼cklegen Bootstrap-Stichproben und berechnen fÃ¼r diese die Anteile der Wohnorte. Das sind unsere Bootstrap-Stichproben und die entsprechenden Statistiken. Wir kÃ¶nnen infer mitteilen, dass wir nur den Anteil der Landbewohner benÃ¶tigen.\n\nset.seed(345)\n\nbootstrap_distribution <- befragung %>%\n  specify(response = wohnort, success = 'land') %>% \n  generate(reps = 10000, type = 'bootstrap') %>% \n  calculate(stat = 'prop')\n\n\n\n9.4.3 Schritt 3: Ergebnisse darstellen\nNun kÃ¶nnen wir auch das Konfidenzintervall fÃ¼r unsere SchÃ¤tzung \\(\\hat{p}\\) berechnen:\n\npercentile_ci <- bootstrap_distribution %>% \n  get_confidence_interval(point_estimate = p_hat$prop[1],\n                          level = 0.95, type = \"percentile\")\n\npercentile_ci\n\n\n\n  \n\n\n\nDie Verteilung der Anteile der Studierenden, die auf dem Land wohnen, in den Bootstrap-Stichproben stellen wir als Histogramm dar und markieren gleich das Konfidenzintervall.\n\nvisualize(bootstrap_distribution) +\n  shade_confidence_interval(percentile_ci) +\n  geom_vline(xintercept = p_hat$prop[1], size = 3, col = 'red')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n9.4.4 Schritt 4: Schlussfolgerungen ziehen\nWir kÃ¶nnen nun unsere Forschungsfrage beantworten:\nWir schÃ¤tzen den Anteil der Studierenden, die auf dem Land wohnen, auf 0.44, mit dem Konfidenzintervall von 0.39, 0.5."
  },
  {
    "objectID": "100-aufgabensammlung.html#erste-schritte",
    "href": "100-aufgabensammlung.html#erste-schritte",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.1 Erste Schritte",
    "text": "A.1 Erste Schritte\n\nA.1.1 Morphometrische Messungen an VÃ¶geln\nIn einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider gibt die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\nFluegel\nFuss\nKopf\nGewicht\n\n\n\n\n59.0\n22.3\n31.2\n9.5\n\n\n55.0\n19.7\n30.4\n13.8\n\n\n53.5\n20.8\n30.6\n14.8\n\n\n55.0\n20.3\n30.3\n15.2\n\n\n52.5\n20.8\n30.3\n15.5\n\n\n57.5\n21.5\n30.8\n15.6\n\n\n53.0\n20.6\n32.5\n15.6\n\n\n55.0\n21.5\nNA\n15.7\n\n\n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele VÃ¶gel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nFÃ¼hren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.7 Umgang mit der Normalverteilung",
    "text": "A.7 Umgang mit der Normalverteilung\n\nA.7.1 Simulieren von Daten aus einer Normalverteilung\n\nSimulieren Sie 1000 Werte aus der Standardnormalverteilung. Nutzen Sie dazu die Funktion rnorm() und stellen Sie die Daten als Histogramm dar. Tipp: Wandeln Sie die Daten in ein tibble um.\nDie Funktion dnorm berechnet den Wert der Wahrscheinlichkeitsdichte \\(f(x)\\), also einen Punkt auf der Glockenkurve. Berechnen Sie diesen Wert fÃ¼r \\(x = 0.3\\) fÃ¼r die Standardnormalverteilung.\nDie Funktion dnorm kann man dazu nutzen, um die theoretische Normalverteilung Ã¼ber die simulierten Daten aus Aufgabe 1 zu plotten. Nutzen Sie dazu die Funktionen geom_density() und geom_function(). Diese Aufgabe machen wir gemeinsam.\nÃœberprÃ¼fen Sie, dass der Bereich \\(\\pm\\) 1.96 Standardabweichungen in einer Normalverteilung 95% der Werte enthÃ¤lt. Zeichnen Sie den Bereich richtig ein."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "href": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.8 Mittelwert der Studiendauer in Werdeschlau",
    "text": "A.8 Mittelwert der Studiendauer in Werdeschlau\nDie Studierendenvertretung in Werdeschlau mÃ¶chte wissen, wie hoch im Schnitt die Studiendauer an der Uni Werdeschlau betrÃ¤gt.\nFÃ¼hren Sie eine Befragung von 100 zufÃ¤llig ausgewÃ¤hlten Studierenden durch. SchÃ¤tzen Sie aus diesen Daten die Studiendauer und geben Sie ein 95%-Konfidenzintervall an. Berechnen Sie dieses Konfidenzintervall.\n\nmit Bootstrap\nmithilfe der Normalverteilung. Der Standardfehler des Mittelwerts sei 0.06 Jahre.\n\nVergleichen Sie die beiden Konfidenzintervalle."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.10 Umgang mit der \\(t\\)-Verteilung",
    "text": "A.10 Umgang mit der \\(t\\)-Verteilung\n\nFinden Sie den kritischen Wert \\(t^*_{2}\\) fÃ¼r das 95%-Konfidenzintervall. Nutzen Sie dazu die Funktion qt().\nPlotten Sie die dazugehÃ¶rige Verteilung mit normTail() und markieren Sie den Bereich, der 95% aller Werte enthÃ¤lt.\nVergleichen Sie die mit dem kritischen Wert fÃ¼r eine \\(t\\)-Verteilung mit 18 Freiheitsgraden."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race",
    "text": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race\nBeim Cherrys Blossom Race laufen die Teilnehmer ein 10-Meilen Rennen. Wie hoch ist die mittlere Laufzeit (mit 95%-Konfidenzintervall) im Jahr 2017? Der Datensatz run17 enthÃ¤lt die Daten.\n\nFiltern Sie zuerst nach event == '10 Mile', da der Datensatz mehrere Rennen enthÃ¤lt (Hilfe lesen!).\nZiehen Sie eine Zufallsstichprobe von 100 LÃ¤ufern und rechnen Sie die Laufzeit net_sec in Minuten um.\nÃœberprÃ¼fen Sie die Anforderungen an die Daten. Welches Modell dÃ¼rfen Sie nutzen?\nBerechnen Sie die PunktschÃ¤tzung und das Konfidenzintervall."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race â€“ mit infer",
    "text": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race â€“ mit infer\nLÃ¶sen Sie die obige Aufgabe mit dem Paket infer."
  },
  {
    "objectID": "100-aufgabensammlung.html#test-fÃ¼r-den-mittelwert",
    "href": "100-aufgabensammlung.html#test-fÃ¼r-den-mittelwert",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.11 $$-Test fÃ¼r den Mittelwert",
    "text": "A.11 $$-Test fÃ¼r den Mittelwert\nWird der typische US-LÃ¤ufer mit der Zeit schneller oder langsamer? Wir betrachten diese Frage im Kontext des Cherrys Blossom Race, einem 10-Meilen-Lauf in Washington, DC, der jedes FrÃ¼hjahr stattfindet. Die Durchschnittszeit aller LÃ¤ufer, die den KirschblÃ¼tenlauf im Jahr 2016 beendeten, betrug 93.29 Minuten (93 Minuten und etwa 17 Sekunden). Anhand der Daten von 100 Teilnehmern des KirschblÃ¼tenlaufs 2017 mÃ¶chten wir feststellen, ob die LÃ¤ufer bei diesem Lauf schneller oder langsamer werden, oder ob es keine VerÃ¤nderungen gibt.\nLÃ¶sen Sie die Aufgabe mit infer.\n\nA.11.1 Bodenverdichtung\nSchwere landwirtschaftliche Maschinen kÃ¶nnen beim Bearbeiten des Bodens zu Bodenverdichtung fÃ¼hren. In einem randomisierten Design wurden zufÃ¤llig Parzellen auf einem sonst homogenen Feld mit einer schweren Maschine bearbeitet (compacted). Auf allen Parzellen wurde danach die Lagerungsdichte bestimmt. Aus langjÃ¤hrigen Messungen ist ist der Mittelwert des unverdichteten Bodens bekannt und betrÃ¤gt 1.3 [g/cmÂ³]. Die Lagerungsdichte (auch Trockenrohdichte) ist ein MaÃŸ fÃ¼r Bodenstruktur und gibt das VerhÃ¤ltnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird hÃ¤ufig in [g/cmÂ³] gemessen und kann als ein Indikator fÃ¼r Bodenverdichtung genutzt werden. Eine ErhÃ¶hung der Lagerungsdichte ist ein Indikator fÃ¼r Verdichtung. Der Datensatz ist in der Datei â€œbd_compaction_simple.csvâ€ gespeichert.\n\nÃœberprÃ¼fen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erhÃ¶ht hat.\n\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009a. A Beginnerâ€™s Guide to R. Springer.\n\n\nâ€”â€”â€”. 2009b. A Beginnerâ€™s Guide to R. Springer."
  },
  {
    "objectID": "100-aufgabensammlung.html#t-test-fÃ¼r-den-mittelwert",
    "href": "100-aufgabensammlung.html#t-test-fÃ¼r-den-mittelwert",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.13 \\(t\\)-Test fÃ¼r den Mittelwert",
    "text": "A.13 \\(t\\)-Test fÃ¼r den Mittelwert\nWird der typische US-LÃ¤ufer mit der Zeit schneller oder langsamer? Wir betrachten diese Frage im Kontext des Cherrys Blossom Race, einem 10-Meilen-Lauf in Washington, DC, der jedes FrÃ¼hjahr stattfindet. Die Durchschnittszeit aller LÃ¤ufer, die den KirschblÃ¼tenlauf im Jahr 2016 beendeten, betrug 93.29 Minuten (93 Minuten und etwa 17 Sekunden). Anhand der Daten von 100 Teilnehmern des KirschblÃ¼tenlaufs 2017 mÃ¶chten wir feststellen, ob die LÃ¤ufer bei diesem Lauf schneller oder langsamer werden, oder ob es keine VerÃ¤nderungen gibt.\nLÃ¶sen Sie die Aufgabe mit infer.\n\nA.13.1 Bodenverdichtung\nSchwere landwirtschaftliche Maschinen kÃ¶nnen beim Bearbeiten des Bodens zu Bodenverdichtung fÃ¼hren. In einem randomisierten Design wurden zufÃ¤llig Parzellen auf einem sonst homogenen Feld mit einer schweren Maschine bearbeitet (compacted). Auf allen Parzellen wurde danach die Lagerungsdichte bestimmt. Aus langjÃ¤hrigen Messungen ist der Mittelwert des unverdichteten Bodens bekannt und betrÃ¤gt 1.3 [g/cmÂ³]. Die Lagerungsdichte (auch Trockenrohdichte) ist ein MaÃŸ fÃ¼r Bodenstruktur und gibt das VerhÃ¤ltnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird hÃ¤ufig in [g/cmÂ³] gemessen und kann als ein Indikator fÃ¼r Bodenverdichtung genutzt werden. Eine ErhÃ¶hung der Lagerungsdichte ist ein Indikator fÃ¼r Verdichtung. Der Datensatz ist in der Datei â€œbd_compaction_simple.csvâ€ gespeichert.\n\nÃœberprÃ¼fen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erhÃ¶ht hat.\n\n\n\n\n\nPew Research Center. 2013. https://www.openintro.org/go?id=textbook-pew-2013-diagnosis-difference.\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginnerâ€™s Guide to r. Springer. http://link.springer.com/book/10.1007%2F978-0-387-93837-0."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "href": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "title": "10Â  Lab 01: EinfÃ¼hrung in R und RStudio",
    "section": "10.1 Die Entwicklungsumgebung RStudio",
    "text": "10.1 Die Entwicklungsumgebung RStudio\nZiel dieser Ãœbung ist es, Sie mit R und RStudio vertraut zu machen, die Sie im Laufe des Kurses sowohl zum Erlernen der im Kurs besprochenen statistischen Konzepte als auch zur Analyse realer Daten und zum Ziehen fundierter Schlussfolgerungen verwenden werden. Der Unterschied zwischen R und RStudio ist folgender: R ist der Name der Programmiersprache selbst und RStudio ist eine praktische Schnittstelle fÃ¼r die Arbeit mit R. Genauer nennt man die Software RStudio eine integrierte Entwicklungsumgebung (IDE, von englisch integrated development environment).\nIm Laufe der Ãœbungen werden Sie ermutigt, Ã¼ber das hinauszugehen, was die Ãœbungen vorgeben; die Bereitschaft zum Experimentieren wird Sie zu einem/einer viel besseren Programmierer*in machen! Bevor wir jedoch so weit sind, mÃ¼ssen Sie einige Grundkenntnisse in der Sprache R erwerben. Zuerst werden wir die grundlegenden Bausteine von R und RStudio erkunden: die Entwicklungsumgebung RStudio, das Laden von Daten und grundlegende Befehle fÃ¼r die Arbeit mit Daten in R.\nFahren Sie fort und starten Sie RStudio. Sie sollten ein Fenster sehen, das wie in AbbildungÂ 10.1 aussieht.\n\n\n\nAbbildungÂ 10.1: Die Entwicklungsumgebung RStudio\n\n\nDas Panel unten links ist der Ort, an dem R arbeitet. Dieser Bereich wird Konsole genannt. Jedes Mal, wenn Sie RStudio starten, erscheint oben in der Konsole derselbe Text, der Ihnen die Version von R angibt, die Sie gerade ausfÃ¼hren. Unterhalb dieser Information befindet sich die Eingabeaufforderung, die durch das Symbol > gekennzeichnet ist. Wie der Name schon sagt, ist dieser Prompt eigentlich eine Aufforderung: eine Aufforderung zu einem Befehl. UrsprÃ¼nglich ging es bei der Interaktion mit R nur darum, Befehle einzugeben und die Ausgabe zu interpretieren. Diese Befehle und ihre Syntax haben sich im Laufe der Jahrzehnte (im wahrsten Sinne des Wortes) weiterentwickelt und bieten nun eine fÃ¼r viele Benutzer recht natÃ¼rliche MÃ¶glichkeit, auf Daten zuzugreifen und statistische Berechnungen zu organisieren, zu beschreiben und aufzurufen.\nDas Feld oben rechts enthÃ¤lt Ihre Arbeitsumgebung (Environment) sowie eine Aufzeichnung (History) der Befehle, die Sie zuvor eingegeben haben.\nDas Feld unten rechts enthÃ¤lt Registerkarten zum Durchsuchen der Files (Dateien) in Ihrem Projektordner, zum Zugriff auf Help (Hilfedateien) fÃ¼r R-Funktionen, zum Installieren und Verwalten von Packages (R-Paketen) und fÃ¼r Plots (Visualisierungen). StandardmÃ¤ÃŸig werden alle von Ihnen erstellten Datenvisualisierungen direkt unter dem Code angezeigt, mit dem Sie sie erstellt haben. Wenn Sie mÃ¶chten, dass Ihre Darstellungen auf der Registerkarte Plots erscheinen, mÃ¼ssen Sie Ihre globalen Optionen Ã¤ndern.\n\n10.1.1 R-Pakete\nR ist eine Open-Source-Programmiersprache, was bedeutet, dass Benutzer Pakete beisteuern kÃ¶nnen, die uns das Leben leichter machen, und wir kÃ¶nnen sie kostenlos nutzen. FÃ¼r diese Ãœbung und viele andere in der Zukunft werden wir die folgenden Pakete verwenden:\n\nDas tidyverse â€œDachâ€-Paket, das eine Reihe von vielen verschiedenen R-Paketen enthÃ¤lt: fÃ¼r Datenverarbeitung und Datenvisualisierung\nDas openintro R-Paket: fÃ¼r Daten und benutzerdefinierte Funktionen mit den OpenIntro-Ressourcen\n\nKlicken Sie in der unteren rechten Ecke auf die Registerkarte Packages. Geben Sie den Namen jedes dieser Pakete (tidyverse, openintro) in das Suchfeld ein, um zu sehen, ob sie installiert wurden. Wenn diese Pakete bei der Eingabe ihres Namens nicht angezeigt werden, installieren Sie sie, indem Sie die folgenden zwei Codezeilen kopieren und einfÃ¼gen oder in die Konsole eingeben. Achten Sie darauf, dass Sie nach jeder Codezeile die Eingabetaste drÃ¼cken. Achtung, bitte denken Sie an die AnfÃ¼hrungszeichen um den Namen des R-Pakets!\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"openintro\")\n\nNachdem Sie Enter/Return gedrÃ¼ckt haben, beginnt ein Textstrom, der den Prozess beschreibt, den R durchlÃ¤uft, um das Paket von der Quelle zu installieren, die Sie bei der Installation von R ausgewÃ¤hlt haben. Wenn Sie bei der Installation von R nicht aufgefordert wurden, einen Server fÃ¼r das Herunterladen von Paketen auszuwÃ¤hlen, kann RStudio Sie auffordern, einen Server auszuwÃ¤hlen, von dem das Paket heruntergeladen werden soll; jeder von ihnen wird funktionieren.\nSie mÃ¼ssen Pakete nur einmal installieren, aber Sie mÃ¼ssen sie jedes Mal laden, wenn Sie RStudio neu starten. Wir laden die Pakete mit der Funktion library. Kopieren Sie die folgenden zwei Zeilen und fÃ¼gen Sie sie in einen neuen Chunk ein. Um die Pakete tidyverse und openintro in Ihre Arbeitsumgebung zu laden, fÃ¼hren Sie den Code aus.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nSie kÃ¶nnen den obigen Code ausfÃ¼hren, indem Sie:\n\nden Cursor auf die Zeile setzen und Strg-Enter oder Cmd-Enter drÃ¼cken\nden Cursor auf die Zeile setzen und die SchaltflÃ¤che â€œRunâ€ in der oberen rechten Ecke der R Markdown-Datei drÃ¼cken, oder\nauf den grÃ¼nen Pfeil in der oberen rechten Ecke des Codeabschnitts klicken.\n\nWir haben uns fÃ¼r das tidyverse-Paket entschieden, weil es aus einer Reihe von Paketen besteht, die fÃ¼r verschiedene Aspekte der Arbeit mit Daten erforderlich sind, vom Laden von Daten Ã¼ber die Verarbeitung von Daten bis hin zur Visualisierung und Analyse von Daten. AuÃŸerdem haben diese Pakete eine gemeinsame Philosophie und sind so konzipiert, dass sie zusammenarbeiten. Sie kÃ¶nnen mehr Ã¼ber die Pakete im tidyverse unter tidyverse.org erfahren.\n\n\n10.1.2 Erstellen eines reproduzierbaren Berichts\nWir werden R Markdown verwenden, um reproduzierbare Berichte zu erstellen. Wie und warum Sie das machen sollen, haben Sie bereits in Kapitel ?sec-erste-schritte gelernt."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "href": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "title": "10Â  Lab 01: EinfÃ¼hrung in R und RStudio",
    "section": "10.2 Taufaufzeichnungen von Dr.Â Arbuthnot",
    "text": "10.2 Taufaufzeichnungen von Dr.Â Arbuthnot\nWir laden den Datensatz arbuthnot aus dem Paket openintro.\n\ndata(arbuthnot)\n\nDie einzige Codezeile in diesem Code-Chunk weist R an, einige Daten zu laden: die Arbuthnot-Taufzahlen fÃ¼r Jungen und MÃ¤dchen. Sie sollten sehen, dass die Registerkarte Environment in der oberen rechten Ecke des RStudio-Fensters nun einen Datensatz namens â€œArbuthnotâ€ mit 82 Beobachtungen fÃ¼r 3 Variablen auflistet. Wenn Sie mit R arbeiten, werden Sie Objekte fÃ¼r eine Vielzahl von Zwecken erstellen. Manchmal laden Sie die Objekte in Ihren Arbeitsbereich, indem Sie ein Paket laden, wie wir es hier getan haben, aber manchmal erstellen Sie selbst Objekte als Nebenprodukt eines Berechnungsprozesses, fÃ¼r eine Analyse, die Sie durchgefÃ¼hrt haben, oder fÃ¼r eine Visualisierung, die Sie erstellt haben. Wie Sie Daten aus einer Textdatei einlesen, erfahren Sie in Kapitel KapitelÂ 4.\nDer Arbuthnot-Datensatz geht auf die Arbeit von Dr.Â John Arbuthnot zurÃ¼ck, einem Arzt, Schriftsteller und Mathematiker aus dem 18. Jahrhundert. Er interessierte sich fÃ¼r das VerhÃ¤ltnis zwischen neugeborenen Jungen und neugeborenen MÃ¤dchen und sammelte daher die TaufeintrÃ¤ge fÃ¼r in London geborene Kinder fÃ¼r jedes Jahr zwischen 1629 und 1710. Auch hier kÃ¶nnen wir die Daten anzeigen, indem wir den unten stehenden Code ausfÃ¼hren oder den Namen des Datensatzes in die Konsole eingeben. Achten Sie auf die Schreibweise und GroÃŸschreibung! R unterscheidet GroÃŸ- und Kleinschreibung. Wenn Sie also versehentlich â€œArbuthnotâ€ eingeben, meldet R, dass das Objekt nicht gefunden werden kann.\n\narbuthnot\n\n\n\n  \n\n\n\nDer Befehl arbuthnot (also der Name des Datensatzes) zeigt die Daten fÃ¼r uns an. Sie kÃ¶nnen im R Markdown durch den Datensatz blÃ¤ttern, wenn sie unter dem Datensatz auf â€œNextâ€ klicken. Alternativ kÃ¶nnen Sie den Datensatz im Datenbetrachter (im Lesemodus) ansehen. Auf der Registerkarte Environment (im oberen rechten Bereich) werden die Objekte in Ihrer Umgebung aufgelistet. Wenn Sie auf den Namen arbuthnot klicken, Ã¶ffnet sich ein Data Viewer Reiter neben Ihrer R Markdown-Datei, der eine alternative Anzeige des Datensatzes bietet. Diese Anzeige sollte sich Ã¤hnlich anfÃ¼hlen wie die Anzeige von Daten in Excel, wo Sie durch den Datensatz blÃ¤ttern kÃ¶nnen, um ihn zu prÃ¼fen. Im Gegensatz zu Excel kÃ¶nnen Sie die Daten auf dieser Registerkarte jedoch nicht bearbeiten. Wenn Sie mit der Ansicht der Daten fertig sind, kÃ¶nnen Sie diese Registerkarte schlieÃŸen, indem Sie auf das â€œxâ€ in der oberen linken Ecke klicken.\nWenn Sie sich die Daten ansehen, sollten Sie vier Zahlenspalten und 82 Zeilen sehen. Jede Zeile steht fÃ¼r ein anderes Jahr, in dem Arbuthnot Daten gesammelt hat. Der erste Eintrag in jeder Zeile ist die Zeilennummer (ein Index, mit dem wir bei Bedarf auf die Daten einzelner Jahre zugreifen kÃ¶nnen), der zweite ist das Jahr, und der dritte und vierte sind die Anzahl der in diesem Jahr getauften Jungen bzw. MÃ¤dchen.\nBeachten Sie, dass die Zeilennummern in der ersten Spalte nicht zu den Daten von Arbuthnot gehÃ¶ren. R fÃ¼gt diese Zeilennummern als Teil des Ausdrucks hinzu, damit Sie visuelle Vergleiche anstellen kÃ¶nnen. Man kann sie sich als den Index vorstellen, den man auf der linken Seite eines Tabellenblatts sieht. In der Tat ist der Vergleich der Daten mit einer Tabellenkalkulation im Allgemeinen hilfreich. R hat die Daten von Arbuthnot in einem Objekt gespeichert, das einer Tabellenkalkulation oder einer Tabelle Ã¤hnelt und das R einen Dataframe nennt.\nSie kÃ¶nnen die Dimensionen dieses Dataframes sowie die Namen der Variablen und die ersten paar Beobachtungen sehen, indem Sie den Namen des Datensatzes aufrufen oder alternativ in die Funktion glimpse() einfÃ¼gen, wie unten gezeigt:\n\nglimpse(arbuthnot)\n\nRows: 82\nColumns: 3\n$ year  <int> 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639â€¦\n$ boys  <int> 5218, 4858, 4422, 4994, 5158, 5035, 5106, 4917, 4703, 5359, 5366â€¦\n$ girls <int> 4683, 4457, 4102, 4590, 4839, 4820, 4928, 4605, 4457, 4952, 4784â€¦\n\n\nWir kÃ¶nnen sehen, dass es 82 Beobachtungen und 3 Variablen in diesem Datensatz gibt. Die Namen der Variablen sind year, boys und girls. An dieser Stelle werden Sie vielleicht bemerken, dass viele der Befehle in R sehr wie Funktionen aus dem Mathematikunterricht aussehen; das heiÃŸt, der Aufruf von R-Befehlen bedeutet, dass man einer Funktion eine Anzahl von Eingaben (die sogenannten Argumente) gibt, die die Funktion verwendet, um eine Ausgabe zu erzeugen. Der Befehl glimpse() zum Beispiel nimmt ein einziges Argument, den Namen eines Dataframes, und erzeugt eine Anzeige des Datensatzes als Ausgabe."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#explorative-analyse",
    "href": "25-lab-01-intro-to-r.html#explorative-analyse",
    "title": "10Â  Lab 01: EinfÃ¼hrung in R und RStudio",
    "section": "10.3 Explorative Analyse",
    "text": "10.3 Explorative Analyse\nBeginnen wir damit, die Daten ein wenig genauer zu untersuchen. Wir kÃ¶nnen auf die Daten in einer einzelnen Spalte eines Dataframes zugreifen, indem wir die Spalte mit einem â€œ$â€ extrahieren. Der folgende Code extrahiert die Spalte boys aus dem Dataframe â€œArbuthnotâ€.\n\narbuthnot$boys\n\n [1] 5218 4858 4422 4994 5158 5035 5106 4917 4703 5359 5366 5518 5470 5460 4793\n[16] 4107 4047 3768 3796 3363 3079 2890 3231 3220 3196 3441 3655 3668 3396 3157\n[31] 3209 3724 4748 5216 5411 6041 5114 4678 5616 6073 6506 6278 6449 6443 6073\n[46] 6113 6058 6552 6423 6568 6247 6548 6822 6909 7577 7575 7484 7575 7737 7487\n[61] 7604 7909 7662 7602 7676 6985 7263 7632 8062 8426 7911 7578 8102 8031 7765\n[76] 6113 8366 7952 8379 8239 7840 7640\n\n\nDieser Befehl zeigt nur die Anzahl der Jungen an, die jedes Jahr getauft werden. R interpretiert das â€œ$â€ so, dass es sagt: â€œGehe zu dem Dataframe, der vor mir kommt, und finde die Variable, die nach mir kommt.â€\n\n\nWelchen Befehl wÃ¼rden Sie verwenden, um nur die Anzahl der getauften MÃ¤dchen zu extrahieren? Probieren Sie es in der Konsole aus!\n\n\nBeachten Sie, dass die Art und Weise, wie R diese Daten ausgibt, unterschiedlich ist. Als wir uns den kompletten Dataframes angesehen haben, sahen wir 82 Zeilen, eine in jeder Zeile der Anzeige. Diese Daten wurden aus dem Dataframe extrahiert, sodass sie nicht mehr in einer Tabelle mit anderen Variablen strukturiert sind. Stattdessen werden diese Daten direkt nacheinander angezeigt. Objekte, die auf diese Weise ausgedruckt werden, nennt man Vektoren; Ã¤hnlich wie die Vektoren, die Sie aus dem Mathematikunterricht kennen, stellen Vektoren eine Liste von Zahlen dar. R hat Zahlen in [Klammern] auf der linken Seite des Ausdrucks hinzugefÃ¼gt, um die Position jedes Eintrags innerhalb des Vektors anzugeben. Zum Beispiel folgt 5218 auf [1], was bedeutet, dass 5218 der erste Eintrag im Vektor ist. Wenn â€œ43â€ am Anfang einer Zeile angezeigt wird, bedeutet dies, dass die erste Zahl in dieser Zeile dem 43. Eintrag in diesem Vektor entspricht.\n\n10.3.1 Datenvisualisierung\nR verfÃ¼gt Ã¼ber einige leistungsstarke Funktionen zur Erstellung von Grafiken. Mit dem folgenden Code kÃ¶nnen wir eine einfache Darstellung der Anzahl der getauften MÃ¤dchen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) + \n  geom_point()\n\n\n\n\nIn diesem Code verwenden wir die Funktion ggplot(), um ein Diagramm zu erstellen. Wenn Sie diesen Codeabschnitt ausfÃ¼hren, wird ein Diagramm unterhalb des Codeabschnitts angezeigt. Das R Markdown-Dokument zeigt die Darstellung unterhalb des Codes an, mit dem sie erzeugt wurde.\nDer obige Befehl sieht ebenfalls wie eine mathematische Funktion aus. Diesmal benÃ¶tigt die Funktion jedoch mehrere Eingaben (Argumente), die durch Kommata getrennt sind.\nMit ggplot():\n\nDas erste Argument ist immer der Name des Datensatzes, den Sie zum Plotten verwenden mÃ¶chten.\nAls NÃ¤chstes geben Sie die Variablen aus dem Datensatz an, die den verschiedenen Ã¤sthetischen Elementen der Darstellung, wie der \\(x\\)- und der \\(y\\)-Achse, zugeordnet werden sollen.\n\nDiese Befehle erstellen ein leeres Diagramm mit den Variablen, die Sie den \\(x\\)- und \\(y\\)-Achsen zugewiesen haben. Als NÃ¤chstes mÃ¼ssen Sie ggplot() mitteilen, welche Art von Visualisierung Sie der leeren Vorlage hinzufÃ¼gen mÃ¶chten. Sie fÃ¼gen eine weitere Ebene zu ggplot() hinzu, indem Sie:\n\nein â€œ+â€ am Ende der Zeile hinzufÃ¼gen, um anzuzeigen, dass Sie eine Ebene hinzufÃ¼gen\ndann das geometrische Objekt angeben, das zur Erstellung des Plots verwendet werden soll.\n\nDa wir ein Streudiagramm erstellen wollen, verwenden wir geom_point(). Damit wird ggplot() mitgeteilt, dass jeder Datenpunkt durch einen Punkt im Diagramm dargestellt werden soll. Wenn Sie das obige Diagramm mit einem Liniendiagramm anstelle eines Streudiagramms darstellen wollten, wÃ¼rden Sie geom_point() durch geom_line() ersetzen. Dies weist ggplot() an, eine Linie von jeder Beobachtung zur nÃ¤chsten Beobachtung zu zeichnen (sequenziell).\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) +\n  geom_line()\n\n\n\n\nVerwenden Sie das Diagramm, um die folgende Frage zu beantworten:\n\n\nGibt es einen offensichtlichen Trend in der Zahl der getauften MÃ¤dchen im Laufe der Jahre? Wie wÃ¼rden Sie ihn beschreiben? Um sicherzustellen, dass Ihr Bericht umfassend ist, sollten Sie den Code, der zur Erstellung der Grafik erforderlich ist, sowie Ihre schriftliche Interpretation beifÃ¼gen.\n\n\nSie fragen sich vielleicht, woher Sie die Syntax fÃ¼r die Funktion ggplot() kennen sollen. Zum GlÃ¼ck dokumentiert R alle seine Funktionen ausfÃ¼hrlich. Um zu erfahren, was eine Funktion tut und wie man sie benutzt (z. B. die Argumente der Funktion), geben Sie einfach ein Fragezeichen gefolgt von dem Namen der Funktion, die Sie interessiert, in die Konsole ein. Geben Sie Folgendes in Ihre Konsole ein:\n\n?ggplot\n\nBeachten Sie, dass die Hilfedatei in den Vordergrund rÃ¼ckt und die Darstellung im unteren rechten Bereich ersetzt. Sie kÃ¶nnen zwischen den Registerkarten hin- und herschalten, indem Sie auf ihre Namen klicken.\n\n\n10.3.2 R als groÃŸer Taschenrechner\nNehmen wir nun an, wir mÃ¶chten die Gesamtzahl der Taufen darstellen. Um dies zu berechnen, kÃ¶nnten wir R als einen groÃŸen Taschenrechner verwenden. Dazu kÃ¶nnen wir mathematische AusdrÃ¼cke wie die folgende Berechnung in die Konsole eintippen.\n\n5218 + 4683\n\n[1] 9901\n\n\nDiese Berechnung wÃ¼rde uns die Gesamtzahl der Taufen im Jahr 1629 liefern. Wir kÃ¶nnten diese Berechnung dann fÃ¼r jedes Jahr einmal wiederholen. Das wÃ¼rde wahrscheinlich eine Weile dauern, aber zum GlÃ¼ck gibt es einen schnelleren Weg! Wenn wir den Vektor der Taufen fÃ¼r Jungen zu dem der MÃ¤dchen addieren, kann R jede dieser Summen gleichzeitig berechnen.\n\narbuthnot$boys + arbuthnot$girls\n\n [1]  9901  9315  8524  9584  9997  9855 10034  9522  9160 10311 10150 10850\n[13] 10670 10370  9410  8104  7966  7163  7332  6544  5825  5612  6071  6128\n[25]  6155  6620  7004  7050  6685  6170  5990  6971  8855 10019 10292 11722\n[37]  9972  8997 10938 11633 12335 11997 12510 12563 11895 11851 11775 12399\n[49] 12626 12601 12288 12847 13355 13653 14735 14702 14730 14694 14951 14588\n[61] 14771 15211 15054 14918 15159 13632 13976 14861 15829 16052 15363 14639\n[73] 15616 15687 15448 11851 16145 15369 16066 15862 15220 14928\n\n\nWas Sie sehen, ist eine Liste von 82 Zahlen. Diese Zahlen erscheinen als Liste, weil wir mit Vektoren und nicht mit einem Dataframe arbeiten. Jede Zahl steht fÃ¼r die Summe der Anzahl der Jungen und MÃ¤dchen, die in diesem Jahr getauft wurden. Sie kÃ¶nnen einen Blick auf die ersten Zeilen der Spalten boys und girls werfen, um zu sehen, ob die Berechnung richtig ist.\n\n\n10.3.3 HinzufÃ¼gen einer neuen Variable zum Dataframe\nWir mÃ¶chten diesen neuen Vektor der Gesamtzahl der Taufen verwenden, um einige Diagramme zu erstellen, daher mÃ¶chten wir ihn als permanente Spalte in unserem Dataframe speichern. Dies kÃ¶nnen wir mit dem folgenden Code tun:\n\narbuthnot <- arbuthnot %>%\n  mutate(total = boys + girls)\n\nDieser Code besteht aus vielen neuen Teilen, die wir nun aufschlÃ¼sseln wollen. In der ersten Zeile tun wir zwei Dinge: (1) wir fÃ¼gen eine neue Spalte total zu diesem aktualisierten Dataframe hinzu, und (2) wir Ã¼berschreiben das vorhandenen Dataframe mit einem aktualisierten Dataframe, das die neue Spalte total enthÃ¤lt. Wir kÃ¶nnen diese beiden Schritte mit dem Operator piping (%>%) miteinander verknÃ¼pfen. Der Pipe-Operator nimmt die Ausgabe des vorherigen Ausdrucks und leitet sie in das erste Argument des nÃ¤chsten Ausdrucks ein.\nUm unsere Analogie mit mathematischen Funktionen fortzusetzen, ist x %>% f(y) gleichbedeutend mit f(x, y). Die Verbindung von arbuthnot und mutate(total = boys + girls) mit dem Pipe-Operator ist dasselbe wie die Eingabe von mutate(arbuthnot, total = boys + girls), wobei arbuthnot das erste Argument der Funktion mutate() wird.\n\nEine Anmerkung zum Piping: Beachten Sie, dass wir diese beiden Codezeilen wie folgt lesen kÃ¶nnen:\nâ€œNehmen Sie den Datensatzâ€arbuthnotâ€ und pipen Sie ihn in die Funktion â€œmutateâ€. VerÃ¤ndern Sie (mutate) den arbuthnot-Datensatz, indem Sie eine neue Variable namens total erstellen, die die Summe der Variablen namens boys und girls ist. Weisen Sie dann den resultierenden Datensatz dem Objekt mit dem Namen arbuthnot zu, d.Â h. Ã¼berschreiben Sie den alten arbuthnot-Datensatz mit dem neuen, der die neue Variable enthÃ¤lt.â€\nDies ist gleichbedeutend mit dem Durchgehen jeder Zeile und dem Aufsummieren der Anzahl der Jungen und MÃ¤dchen fÃ¼r dieses Jahr und dem Aufzeichnen dieses Wertes in einer neuen Spalte mit dem Namen total.\n\n\nWo ist die neue Variable? Wenn Sie Ã„nderungen an Variablen in Ihrem Datensatz vornehmen, rufen Sie ihn erneut durch die Eingabe des Datensatznamens. Die neue Variable wird am Ende des Datensatzes hinzugefÃ¼gt.\n\nSie werden sehen, dass es jetzt eine neue Spalte namens total gibt, die an das Dataframe angeheftet wurde. Das spezielle Symbol <- fÃ¼hrt eine Zuweisung durch, indem es die Ausgabe der Piping-Operationen nimmt und sie in einem Objekt in Ihrer Umgebung speichert. In diesem Fall haben Sie bereits ein Objekt mit dem Namen arbuthnot in Ihrer Umgebung, also aktualisiert dieser Befehl diesen Datensatz mit der neuen mutierten Spalte.\nMit dem folgenden Code kÃ¶nnen Sie ein Liniendiagramm der Gesamtzahl der Taufen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = total)) + \n  geom_line()\n\n\n\n\nIn Ã¤hnlicher Weise kann man, wenn man die Gesamtzahl der Taufen fÃ¼r Jungen und MÃ¤dchen im Jahr 1629 kennt, das VerhÃ¤ltnis zwischen der Zahl der Jungen und der Zahl der getauften MÃ¤dchen mit dem folgenden Code berechnen:\n\n5218 / 4683\n\n[1] 1.114243\n\n\nAlternativ kÃ¶nnten Sie dieses VerhÃ¤ltnis fÃ¼r jedes Jahr berechnen, indem Sie auf die vollstÃ¤ndigen Spalten boys und girls einwirken und diese Berechnungen dann in einer neuen Variablen mit dem Namen boy_to_girl_ratio speichern:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_to_girl_ratio = boys / girls)\n\nSie kÃ¶nnen auch den Anteil der Neugeborenen im Jahr 1629, die Jungen sind, mit dem folgenden Code berechnen:\n\n5218 / (5218 + 4683)\n\n[1] 0.5270175\n\n\nSie kÃ¶nnen diesen Wert auch fÃ¼r alle Jahre gleichzeitig berechnen und ihn als neue Variable mit dem Namen boy_ratio zum Datensatz hinzufÃ¼gen:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_ratio = boys / total)\n\nBeachte, dass wir nicht durch boys + girls dividieren, sondern die Variable total verwenden, die wir zuvor in unseren Berechnungen erstellt haben!\n\n\nErstellen Sie nun eine Grafik des Anteils der geborenen Jungen Ã¼ber die Zeit. Was sehen Sie?\n\n\n\nTipp: Wenn Sie die Pfeiltasten nach oben und unten in der Konsole benutzen, kÃ¶nnen Sie durch Ihre vorherigen Befehle blÃ¤ttern, Ihre sogenannte Befehlshistorie. Sie kÃ¶nnen auch auf Ihre Befehlshistorie zugreifen, indem Sie auf die Registerkarte â€œHistoryâ€ in der oberen rechten Leiste klicken. Dies kann Ihnen in Zukunft viel Tipparbeit ersparen.\n\nZusÃ¤tzlich zu den einfachen mathematischen Operatoren wie Subtraktion und Division kÃ¶nnen Sie R auffordern, Vergleiche durchzufÃ¼hren, z. B. grÃ¶ÃŸer als, >, kleiner als, <, und Gleichheit, ==. Mit dem folgenden Code kÃ¶nnen wir unter anderem eine neue Variable namens more_boys erstellen, die uns sagt, ob die Anzahl der Geburten von Jungen die der MÃ¤dchen in jedem Jahr Ã¼bersteigt:\n\narbuthnot <- arbuthnot %>%\n  mutate(more_boys = boys > girls)\n\nDieser Befehl fÃ¼gt dem Dataframe arbuthnot eine neue Variable hinzu, die entweder den Wert TRUE enthÃ¤lt, wenn es in diesem Jahr mehr Jungen als MÃ¤dchen gab, oder FALSE, wenn dies nicht der Fall war (die Antwort mag Sie Ã¼berraschen). Diese Variable enthÃ¤lt eine andere Art von Daten als die, die wir bisher kennengelernt haben. Alle anderen Spalten im Dataframe arbuthnot haben numerische Werte (das Jahr, die Anzahl der Jungen und MÃ¤dchen). Hier haben wir R gebeten, logische Daten zu erstellen, also Daten, deren Werte entweder TRUE oder FALSE sind. Im Allgemeinen werden bei der Datenanalyse viele verschiedene Datentypen verwendet, und ein Grund fÃ¼r die Verwendung von R ist, dass es in der Lage ist, viele dieser Datentypen darzustellen und mit ihnen zu rechnen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#mehr-Ã¼bungen",
    "href": "25-lab-01-intro-to-r.html#mehr-Ã¼bungen",
    "title": "10Â  Lab 01: EinfÃ¼hrung in R und RStudio",
    "section": "10.4 Mehr Ãœbungen",
    "text": "10.4 Mehr Ãœbungen\nAuf den vorangegangenen Seiten haben Sie einige der Anzeigen und vorlÃ¤ufigen Analysen von Arbuthnots Taufdaten nachgebildet. Ihre Aufgabe besteht darin, diese Schritte zu wiederholen, allerdings fÃ¼r die heutigen Geburtsdaten in den Vereinigten Staaten. Die Daten sind in einem Datenrahmen mit dem Namen present gespeichert.\nUm die Minimal- und Maximalwerte der Spalten zu ermitteln, kÃ¶nnen Sie die Funktionen min() und max() innerhalb eines summarize()-Aufrufs verwenden, Ã¼ber den Sie im Verlaufe des Kurses mehr erfahren werden.\nHier ist ein Beispiel dafÃ¼r, wie man die minimale und maximale Anzahl der Geburten von Jungen in einem Jahr ermitteln kann:\n\narbuthnot %>%\n  summarize(min = min(boys),\n            max = max(boys)\n            )\n\n\n\n  \n\n\n\nBeantworten Sie die folgenden Fragen mit dem Datensatz present:\n\n\nWelche Jahre sind in diesem Datensatz enthalten? Welche Dimensionen hat das Dataframe? Wie lauten die Namen der Variablen (Spalten)?\nWie lassen sich diese ZÃ¤hlungen mit denen von Arbuthnot vergleichen? Sind sie von Ã¤hnlicher GrÃ¶ÃŸenordnung?\nErstellen Sie ein Diagramm, das den Anteil der geborenen Jungen im Laufe der Zeit darstellt. Was sehen Sie? Trifft Arbuthnots Beobachtung, dass Jungen in grÃ¶ÃŸerem Umfang als MÃ¤dchen geboren werden, in den Vereinigten Staaten zu? FÃ¼gen Sie die Grafik in Ihre Antwort ein. Hinweis: Sie sollten in der Lage sein, Ihren Code aus der obigen Aufgabe wiederzuverwenden, ersetzen Sie einfach den Namen des Dataframes.\nIn welchem Jahr gab es die hÃ¶chste Gesamtzahl an Geburten in den Vereinigten Staaten? Tipp: Berechnen Sie zunÃ¤chst die Gesamtzahlen und speichern Sie sie als neue Variable. Sortieren Sie dann Ihren Datensatz in absteigender Reihenfolge nach der Spalte total. Sie kÃ¶nnen dies interaktiv in der Datenanzeige tun, indem Sie auf die Pfeile neben den Variablennamen klicken. Um das sortierte Ergebnis in Ihren Bericht aufzunehmen, mÃ¼ssen Sie zwei neue Funktionen verwenden. Zuerst verwenden wir arrange(), um die Variable zu sortieren. Dann kÃ¶nnen wir die Daten mit einer anderen Funktion, desc(), in absteigender Reihenfolge anordnen. Der Beispielcode ist unten angegeben.\n\n\n\npresent %>%\n  arrange(desc(total))\n\nDiese Daten stammen aus Berichten der Centers for Disease Control. Sie kÃ¶nnen mehr Ã¼ber sie erfahren, indem Sie die Hilfedatei mit dem Befehl ?present aufrufen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "href": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "title": "10Â  Lab 01: EinfÃ¼hrung in R und RStudio",
    "section": "10.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio",
    "text": "10.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio\nDas war eine kurze EinfÃ¼hrung in R und RStudio, aber wir werden Ihnen im weiteren Verlauf des Kurses weitere Funktionen und ein umfassenderes GefÃ¼hl fÃ¼r die Sprache vermitteln.\nIn diesem Kurs werden wir die R-Pakete aus dem tidyverse verwenden. Das Buch [R For Data Science] (https://r4ds.hadley.nz/) von Wickham et al.Â ist eine fantastische Quelle fÃ¼r die Datenanalyse in R mit tidyverse. Wenn Sie nach R-Code suchen, stellen Sie sicher, dass Sie auch diese Paketnamen in Ihre Suchanfrage aufnehmen. Suchen Sie zum Beispiel nicht nach â€œscatterplot in Râ€, sondern nach â€œscatterplot in R with the tidyverseâ€.\nDiese Unterlagen kÃ¶nnen sich im Laufe des Semesters als nÃ¼tzlich erweisen:\n\nRMarkdown Cheatsheet\nCheatsheet zur Datentransformation\nCheatsheet zur Datenvisualisierung\n\nBeachten Sie, dass einige der Codes auf diesen Cheatsheets fÃ¼r diesen Kurs zu fortgeschritten sein kÃ¶nnten. Der GroÃŸteil davon wird jedoch im Laufe des Semesters nÃ¼tzlich sein."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-vorlesung",
    "href": "04-einlesen.html#die-umfrage-aus-der-vorlesung",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.8 Die Umfrage aus der Vorlesung",
    "text": "4.8 Die Umfrage aus der Vorlesung\nLesen Sie die Datei â€˜Umfrage_2023_kurz.csvâ€™ ein (sie ist auf ILIAS zu finden). Sie enthÃ¤lt die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage â€˜Haben Sie schon mal einen Statistikkurs besucht?â€™\n\nWie viele EintrÃ¤ge enthÃ¤lt der Datensatz?\nWie viele Variablen enthÃ¤lt der Datensatz?\nSind die Variablen numerisch oder kategorial? Wurden die Variablen auch so von R eingelesen?\nErklÃ¤ren Sie jede Variable. Welche Information enthÃ¤lt sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungefÃ¤hr)?"
  },
  {
    "objectID": "04-einlesen.html#lab-01",
    "href": "04-einlesen.html#lab-01",
    "title": "4Â  Daten in R einlesen und aus R speichern",
    "section": "4.9 Lab 01",
    "text": "4.9 Lab 01\nBearbeiten Sie selbstÃ¤ndig das Lab 01: EinfÃ¼hrung in R und RStudio in KapitelÂ 10."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "href": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.11 Mittelwert der Laufzeiten beim Cherrys Blossom Race",
    "text": "A.11 Mittelwert der Laufzeiten beim Cherrys Blossom Race\nBeim Cherrys Blossom Race laufen die Teilnehmer ein 10-Meilen-Rennen. Wie hoch ist die mittlere Laufzeit (mit 95%-Konfidenzintervall) im Jahr 2017? Der Datensatz run17 enthÃ¤lt die Daten.\n\nFiltern Sie zuerst nach event == '10 Mile', da der Datensatz mehrere Rennen enthÃ¤lt (Hilfe lesen!).\nZiehen Sie eine Zufallsstichprobe von 100 LÃ¤ufern und rechnen Sie die Laufzeit net_sec in Minuten um.\nÃœberprÃ¼fen Sie die Anforderungen an die Daten. Welches Modell dÃ¼rfen Sie nutzen?\nBerechnen Sie die PunktschÃ¤tzung und das Konfidenzintervall."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "href": "100-aufgabensammlung.html#mittelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.12 Mittelwert der Laufzeiten beim Cherrys Blossom Race â€“ mit infer",
    "text": "A.12 Mittelwert der Laufzeiten beim Cherrys Blossom Race â€“ mit infer\nLÃ¶sen Sie die obige Aufgabe mit dem Paket infer."
  },
  {
    "objectID": "100-aufgabensammlung.html#lineare-regression",
    "href": "100-aufgabensammlung.html#lineare-regression",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.6 Lineare Regression",
    "text": "A.6 Lineare Regression\nWir arbeiten mit den Possum-Daten aus dem Paket openintro.\n\nLaden Sie das Paket und den Datensatz. ZusÃ¤tzlich werden sie tidyverse und broom benÃ¶tigen.\nWir wollen die KopflÃ¤ngen der Tiere mithilfe der KÃ¶rperlÃ¤nge vorhersagen (wie in der Vorlesung). Passen Sie das Modell an.\nPlotten Sie den Residualplot. Gibt es auffÃ¤llige Muster im Plot?\nSehen Sie sich die Parameter des Models und den Determinationskoeffizienten an. Interpretieren Sie beides.\nNun mÃ¶chten wir die KopflÃ¤ngen nur mithilfe des Geschlechts der Tiere vorhersagen. Wiederholen Sie die vorherigen Schritte.\nVergleichen Sie die beiden Modelle. Welches ist besser? BegrÃ¼nden Sie?\nWerden die KopflÃ¤ngen der weiblichen oder der mÃ¤nnlichen Tiere besser vorhergesagt? Beantworten Sie diese Frage grafisch mit einem Residualplot. FÃ¤rben Sie die Residuen sinnvoll ein.\nSchwierig: Passen Sie ein Modell mit beiden PrÃ¤diktoren an. Tipp: Sie kÃ¶nnen die PrÃ¤diktoren mit einem Plus verbinden, nach folgendem Schema: lm(Zielvariable ~ PrÃ¤diktor1 + PrÃ¤diktor2, data = Datensatz)\nVergleichen Sie alle drei Modelle. Welches ist besser?"
  },
  {
    "objectID": "100-aufgabensammlung.html#chronische-krankheiten",
    "href": "100-aufgabensammlung.html#chronische-krankheiten",
    "title": "Appendix A â€” Aufgabensammlung",
    "section": "A.9 Chronische Krankheiten",
    "text": "A.9 Chronische Krankheiten\nIm Jahr 2013 berichtete die Pew Research Foundation, dass â€œ45% der Erwachsenen in den USA angeben, mit einer oder mehreren chronischen Krankheiten zu lebenâ€. Dieser Wert basierte jedoch auf einer Stichprobe, so dass er mÃ¶glicherweise keine perfekte SchÃ¤tzung fÃ¼r den interessierenden Parameter der Grundgesamtheit darstellt. Die Studie gab den Standardfehler mit 1.2% an, und die Normalverteilung kann kann in diesem Fall als Modell verwendet werden (Pew Research Center 2013)..\n\nBerechnen Sie ein 90%-Konfidenzintervall fÃ¼r den Anteil der Erwachsenen in den USA, die mit einer oder mehreren chronischen Krankheiten leben.\nStellen Sie das Konfidenzintervall grafisch dar.\nInterpretieren Sie das Konfidenzintervall im Zusammenhang mit der Studie."
  }
]